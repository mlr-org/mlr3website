---
sidebar: false
toc: false
---

# Tuners

```{r, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(mlr3website)
library(htmltools)
library(mlr3misc)
library(data.table)
library(mlr3tuning)
library(mlr3hyperband)
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")

content = as.data.table(mlr_tuners, objects = TRUE)[, .(key, label, packages, properties, param_classes, object)]

# add links
content[, key := link_keys(key, prefix = "mlr_tuners")]
content[, packages := link_pkgs(packages)]

# remove content
content[, properties := map(properties, function(x) setdiff(x, "dependencies"))]

# add line breaks to cells
cols = c("param_classes", "properties", "packages")
content[, (cols) := map(.SD, function(col) map_chr(col, function(x) paste0(x, collapse = "<br/>"))), .SDcols = cols]

content[, object := NULL]
setnames(content, c("Key", "Label", "Packages", "Properties", "Classes"))
```

Popular black-box optimization techniques are implemented in the `r ref_pkg("bbotk")` package.
The corresponding connectors to for tuning hyperparameters of learners or pipelines reside as `r ref("Tuner")` objects in package `r ref_pkg("mlr3tuning")`.
Additionally, packages `r ref_pkg("mlr3hyperband")` and `r ref_pkg("mlr-org/mlr3mbo")` provide some modern and sophisticated approaches.

All tuners operator on box-constrained tuning spaces which have to be defined by the user.
Some popular spaces from literature are readily available as [tuning spaces](tuning_spaces.html).

```{r}
#| column: page
DT::datatable(
  content,
  style = "bootstrap",
  escape = FALSE,
  options = list(paging = FALSE, scrollX = TRUE, info = FALSE),
  rownames = FALSE)
```

## Example Usage

Tune the hyperparameters of a `r ref("mlr_learners_classif.rpart", text = "classification tree")` on the `r ref("mlr_tasks_penguins", text = "Palmer Penguins")` data set with `r ref("mlr_tuners_random_search", text = "random search")`.

```{r, echo=TRUE}
library(mlr3verse)

# retrieve task
task = tsk("penguins")

# load learner and set search space
learner = lrn("classif.rpart",
  cp = to_tune(1e-04, 1e-1, logscale = TRUE),
  minsplit = to_tune(2, 128, logscale = TRUE)
)

# load tuner and set batch size
tuner = tnr("random_search", batch_size = 10)

# hyperparameter tuning on the palmer penguins data set
instance = tune(
  method = tuner,
  task = task,
  learner = learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  term_evals = 50
)

# best performing hyperparameter configuration
instance$result

# surface plot
autoplot(instance, type = "surface")

# fit final model on complete data set
learner$param_set$values = instance$result_learner_param_vals
learner$train(task)

print(learner)
```
