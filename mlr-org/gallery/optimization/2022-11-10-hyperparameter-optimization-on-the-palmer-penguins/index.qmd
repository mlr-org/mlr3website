---
title: "Hyperparameter Optimization on the Palmer Penguins Data Set"
description: |
  Optimize the hyperparameters of a classification tree with a few lines of code.
categories:
  - tuning
  - classification
  - optimization-gallery
author:
  - name: Marc Becker
    url: https://github.com/be-marc
date: 2022-11-10
bibliography: bibliography.bib
---

{{< include ../_setup.qmd >}}

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-001}
#| include: false
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")
options(datatable.print.nrows = 6)
future::plan("multisession")
```

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-002}
#| column: body-outset
#| fig-cap: Artwork by @horst_palmer_2022.
#| echo: false
knitr::include_graphics("penguins.png")
```

# Scope

In this post, we optimize the hyperparameters of a simple `r ref("mlr_learners_classif.rpart", "classification tree")` on the `r ref("mlr_tasks_penguins", text = "Palmer Penguins")` data set with only a few lines of code.

First, we introduce tuning spaces and show the importance of transformation functions.
Next, we execute the tuning and present the basic building blocks of tuning in mlr3.
Finally, we fit a classification tree with optimized hyperparameters on the full data set.

# Prerequistes

We load the `r ref_pkg("mlr3verse")` package which pulls the most important packages for this example.
Among other packages, it loads the hyperparameter optimization package of the mlr3 ecosystem `r ref_pkg("mlr3tuning")`.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-003}
#| message: false
library(mlr3verse)
```

In this example, we use the `r ref("mlr_tasks_penguins", text = "Palmer Penguins")` data set which classifies 344 penguins in three species.
The data set was collected from 3 islands in the Palmer Archipelago in Antarctica.
It includes the name of the island, the size (flipper length, body mass, and bill dimension), and the sex of the penguin.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-004}
tsk("penguins")
```

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-005}
#| column: body-outset
#| fig-cap: Flipper and bill length dimensions for Adelie, Chinstrap, and Gentoo Penguins at Palmer Station [@horst_palmer_2022].
#| code-fold: true
#| warning: false

library(palmerpenguins)
library(ggplot2)
ggplot(data = penguins, aes(x = flipper_length_mm, y = bill_length_mm)) +
  geom_point(aes(color = species, shape = species), size = 3, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, aes(color = species)) +
  theme_minimal() +
  scale_color_manual(values = c("darkorange","purple","cyan4")) +
  labs(x = "Flipper length (mm)", y = "Bill length (mm)",  color = "Penguin species", shape = "Penguin species") +
  theme(
    legend.position = c(0.85, 0.15),
    legend.background = element_rect(fill = "white", color = NA),
    text = element_text(size = 10))
```

# Learner

We use the `r ref("mlr_learners_classif.rpart", "rpart classification tree")`.
A learner stores all information about its hyperparameters in the slot `$param_set`.
Not all parameters are tunable.
We have to choose a subset of the hyperparameters we want to tune.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-006}
learner = lrn("classif.rpart")
as.data.table(learner$param_set)[, list(id, class, lower, upper, nlevels)]
```

# Tuning Space

The package `r ref_pkg("mlr3tuningspaces")` is a collection of search spaces for hyperparameter tuning from peer-reviewed articles.
We use the search space from the @bischl_hyperparameter_2021 article.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-007}
lts("classif.rpart.default")
```

The classification tree is mainly influenced by three hyperparameters:

* The complexity hyperparameter `cp` that controls when the learner considers introducing another branch.
* The `minsplit` hyperparameter that controls how many observations must be present in a leaf for another split to be attempted.
* The `minbucket` hyperparameter that the minimum number of observations in any terminal node.

We argument the learner with the search space in one go.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-008}
lts(lrn("classif.rpart"))
```

## Transformations

The column `logscale` indicates that the hyperparameters are tuned on the logarithmic scale.
The tuning algorithm proposes hyperparameter values that are transformed with the exponential function before they are passed to the learner.
For example, the `cp` parameter is bounded between 0 and 1.
The tuning algorithm searches between `log(1e-04)` and `log(1e-01)` but the learner gets the transformed values between `1e-04` and `1e-01`.
Using the log transformation emphasizes smaller `cp` values but also creates large values.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-009}
lts("classif.rpart.default")
```

# Tuning

The `r ref("tune()")` function controls and executes the tuning.
The `method` sets the optimization algorithm.
The mlr3 ecosystem offers various optimization algorithms e.g. `r ref("mlr_tuners_random_search" ,"Random Search")`, `r ref("mlr_tuners_gensa" ,"GenSA")`, and `r ref("mlr_tuners_hyperband" ,"Hyperband")`.
In this example, we will use a simple grid search with a grid resolution of 5.
Our three-dimensional grid consists of $5^3 = 125$ hyperparameter configurations.
The `r ref("Resampling", text = "resampling strategy")` and `r ref("Measure", text = "performance measure")` specify how the performance of a model is evaluated.
We choose a `r ref("mlr_resamplings_cv", "3-fold cross-validation")`  and use the `r ref("mlr_measures_classif.ce", "classification error")`.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-010}
instance = tune(
  method = "grid_search",
  task = tsk("penguins"),
  learner = lts(lrn("classif.rpart")),
  resampling = rsmp("cv", folds = 3),
  measure = msr("classif.ce"),
  resolution = 5
)
```

The `r ref("tune()")` function returns a tuning instance that includes an archive with all evaluated hyperparameter configurations.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-011}
as.data.table(instance$archive)[, list(minsplit, minbucket, cp, classif.ce, resample_result)]
```

The best configuration and the corresponding measured performance can be retrieved from the tuning instance.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-012}
instance$result
```

The `$result_learner_param_vals` field contains the best hyperparameter setting on the learner scale.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-013}
instance$result_learner_param_vals
```

# Final Model

The learner we use to make predictions on new data is called the final model.
The final model is trained on the full data set.
We add the optimized hyperparameters to the learner and train the learner on the full dataset.

```{r 2022-11-10-hyperparameter-optimization-on-the-palmer-penguins-014}
learner = lrn("classif.rpart")
learner$param_set$values = instance$result_learner_param_vals
learner$train(tsk("penguins"))
```

The trained model can now be used to predict new, external data.
