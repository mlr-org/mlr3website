---
title: "mlr3tuning - Runtime and Memory"
sidebar: false
toc: true
cache: false
lazy-cache: false
format:
  html:
    fig-width: 12
    fig-height: 9
---

{{< include ../_setup.qmd >}}

```{r}
#| include: false
library(data.table)
library(ggplot2)
library(gt)
library(DBI)

con = dbConnect(RSQLite::SQLite(), here::here("mlr-org/benchmarks/results.db"))
snapshot = setDT(dbReadTable(con, "mlr3tuning_snapshots"))
snapshot[, mlr3 := factor(mlr3)]
snapshot[, paradox := factor(paradox)]
snapshot[, mlr3tuning := factor(mlr3tuning)]
snapshot[, bbotk := factor(bbotk)]

plot_runtime = function(data) {
  ggplot(data, aes(x = mlr3tuning, y = median_runtime)) +
  geom_col(group = 1, fill = "#008080") +
  geom_errorbar(aes(ymin = pmax(median_runtime - mad_runtime, 0), ymax = median_runtime + mad_runtime), width = 0.5, position = position_dodge(0.9)) +
  geom_hline(aes(yintercept = model_time * evals / 1000), linetype = "dashed") +
  facet_wrap(~evals, scales = "free_y", labeller = labeller(evals = function(value) sprintf("%s Resampling Iterations", value))) +
  labs(x = "mlr3Version", y = "Runtime [s]") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

plot_memory = function(data) {
  ggplot(data, aes(x = mlr3tuning, y = median_memory)) +
  geom_col(group = 1, fill = "#ff6347") +
  geom_errorbar(aes(ymin = median_memory - mad_memory, ymax = median_memory + mad_memory), width = 0.5, position = position_dodge(0.9)) +
  geom_hline(aes(yintercept = 131), linetype = "dashed") +
  facet_wrap(~evals, scales = "free_y", labeller = labeller(evals = function(value) sprintf("%s Resampling Iterations", value))) +
  labs(x = "mlr3 Version", y = "Memory [MB]") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

create_table = function(data) {
  data = data[, -c("mad_memory", "mad_runtime")]

  data_1000 = data[task == "data_1000", -"task"]
  data_10000 = data[task == "data_10000", -c("task", "k", "total_model_time")]
  browser()
  data = merge(data_1000, data_10000, by = c("mlr3tuning", "bbotk", "mlr3", "paradox", "model_time", "evals"), suffixes = c("", "_10000"))

  setcolorder(data, c("mlr3tuning", "bbotk", "mlr3", "paradox", "model_time", "evals", "total_model_time", "median_runtime", "median_runtime_10000", "k", "median_memory", "median_memory_10000"))

  data %>%
    gt() %>%
    cols_label(
      mlr3tuning = "mlr3tuning Version",
      bbotk = "bbotk Version",
      mlr3 = "mlr3 Version",
      paradox = "paradox Version",
      model_time = "Model Time [ms]",
      evals = "Resampling Iterations",
      total_model_time = "Total Model Time [s]",
      median_runtime = "Median Runtime [s]",
      median_runtime_10000 = "Median Runtime 10,000 [s]",
      k = "K",
      median_memory = "Median Memory [MB]",
      median_memory_10000 = "Median Memory 10,000 [s]") %>%
    fmt_number(columns = c("k", "median_runtime", "median_runtime_10000"), n_sigfig = 2) %>%
    fmt_number(columns = c("median_memory", "median_memory_10000"), decimals = 0) %>%
    tab_style(
      style = list(
        cell_fill(color = "crimson"),
        cell_text(weight = "bold")
      ),
      locations = cells_body(
        columns = "k",
        rows = k > 3
      )
    )  %>%
    tab_row_group(
      label = "1000 Resampling Iterations",
      rows = evals == 1000
    ) %>%
    tab_row_group(
      label = "100 Resampling Iterations",
      rows = evals == 100
    ) %>%
    tab_row_group(
      label = "10 Resampling Iterations",
      rows = evals == 10
    )
  }
```

# Scope

This report analyzes the runtime and memory usage of the mlr3tuning package across different versions.

# Summary of Latest mlr3tuning Version

The benchmarks are comprehensive; therefore, we present a summary of the results for the latest mlr3tuning version.

# Tune {#tune}

```{r}
#| include: false
data_memory = setDT(dbReadTable(con, "mlr3tuning_tune_memory"))[, list(task, evals, renv_project, median_memory, mad_memory)]
data_memory[, renv_project := gsub("mlr3tuning/default/snapshots/", "", renv_project)]
data_memory = data_memory [snapshot, on = "renv_project"]
setorderv(data_memory, c("task", "evals", "mlr3tuning"), order = c(1, 1, -1))
data_memory = data_memory[, -c("renv_project")]

data_runtime = setDT(dbReadTable(con, "mlr3tuning_tune_runtime"))[, list(model_time, task, evals, renv_project, median_runtime, mad_runtime, k)]
data_runtime[, renv_project := gsub("mlr3tuning/default/snapshots/", "", renv_project)]
data_runtime = data_runtime[snapshot, on = "renv_project"]
setorderv(data_runtime, c("task", "model_time", "evals", "mlr3tuning"), order = c(1, 1, 1, -1))
data_runtime = data_runtime[, -c("renv_project")]
data_runtime[, median_runtime := median_runtime / 1000]
data_runtime[, mad_runtime := mad_runtime / 1000]
data_runtime[, total_model_time := model_time * evals / 1000]

data_runtime = merge(data_runtime, data_memory, by = c("task", "evals", "mlr3tuning", "bbotk", "mlr3", "paradox"), sort = FALSE)
```

The runtime and memory usage of the `resample()` function is measured for different mlr3 versions.
The models are trained for different amounts of time (1 ms, 10 ms, 100 ms, and 1000 ms) on the spam dataset with 1000 and 10,000 instances.
The resampling iterations (`evals`) are set to 1000, 100, and 10.

```{r}
#| eval: false
task = tsk("spam")

learner = lrn("classif.sleep",
  sleep_train = model_time / 2,
  sleep_predict = model_time / 2)

tune(
  tuner = tnr("random_search", batch_size = evals),
  task = task,
  learner = learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  terminator = trm("evals", n_evals = evals),
  store_benchmark_result = FALSE,
  store_models = FALSE
)
```

```{r}
#| include: false
.model_time = 1000
```

{{< include _benchmarks_mlr3tuning_section_1.qmd >}}

```{r}
#| include: false
.model_time = 100
```

{{< include _benchmarks_mlr3tuning_section_1.qmd >}}

```{r}
#| include: false
.model_time = 10
```

{{< include _benchmarks_mlr3tuning_section_1.qmd >}}

```{r}
#| include: false
.model_time = 1
```

{{< include _benchmarks_mlr3tuning_section_1.qmd >}}

## Memory

```{r}
#| echo: false
#| column: body-outset
#| fig-cap: |
#|  Memory usage of `tune()` depending on the mlr3tuning version and the number of resampling iterations.
#|  Error bars represent the median absolute deviation of the memory usage.
plot_memory(data_memory[task == "data_1000"])
```
