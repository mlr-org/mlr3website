{
  "hash": "8f1ca067201f0ba35e74fe496112afe9",
  "result": {
    "markdown": "---\ntitle: \"mlr loves OpenML\"\ndescription: |\n  Connecting mlr with OpenML\nauthor:\n  - name: Heidi Seibold\n    url: https://github.com/HeidiSeibold\ndate: 2016-09-09\nimage: mlr_loves_openml.png\ncategories: [\"R\", \"r-bloggers\"]\ntags: [\"OpenML\", \"rstats\"]\n\n---\n\n\n\n\n[OpenML](http://www.openml.org/) stands for Open Machine Learning and is an\nonline platform, which aims at supporting collaborative machine learning\nonline. It is an Open Science project that allows its users to share data, code\nand machine learning experiments.\n\nAt the time of writing this blog I am in Eindoven at an [OpenML\nworkshop](http://openml2016dev.openml.org/), where developers and scientists\nmeet to work on improving the project. Some of these people are R users and they (we)\nare developing an [R package](https://github.com/openml/openml-r) that\ncommunicates with the OpenML platform.\n\n![](mlr_loves_openml.png)\n\n## OpenML in R\n\nThe OpenML R package can list and download data sets and machine\nlearning tasks (prediction challenges).  In R one can run algorithms on the\nthese data sets/tasks and\nthen upload the results to OpenML. After successful uploading, the website shows how well the\nalgorithm performs.  To run the algorithm on a given task the OpenML R package\nbuilds on the [mlr](https://github.com/mlr-org/mlr) package. mlr understands\nwhat a task is and can run learners on that task. So all the OpenML package\nneeds to do is convert the OpenML objects to objects mlr understands and then\nmlr deals with the learning.\n\n## A small case study\n\nWe want to create a little study on the [OpenML\nwebsite](http://www.openml.org/), in which we compare different types of Support\nVector Machines.  The study gets an ID assigned to it, which in our case is 27.\nWe use the function ksvm (with different settings of the function argument type)\nfrom package kernlab, which is integrated in mlr (\"classif.ksvm\").\n\n![](openml_screenshot_study.png)\n\nFor details on installing and setting up the OpenML R package please see the\n[guide](https://github.com/openml/openml-r) on GitHub.\n\nLet's start conducting the study:\n\n- Load the packages and list all tasks which have between 100 and 500\n  observations.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(\"OpenML\")\nlibrary(\"mlr\")\nlibrary(\"farff\")\nlibrary(\"BBmisc\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndsize = c(100, 500)\ntaskinfo_all = listOMLTasks(number.of.instances = dsize)\n```\n:::\n\n\n- Select all supervised classification tasks that do 10-fold cross-validation\n  and choose only one task per data set. To keep the study simple and fast to compute,\n  select only the first three tasks.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntaskinfo_10cv = subset(taskinfo_all, task.type == \"Supervised Classification\" &\n                    estimation.procedure == \"10-fold Crossvalidation\" &\n                    evaluation.measures == \"predictive_accuracy\" &\n                    number.of.missing.values == 0 &\n                    number.of.classes %in% c(2, 4))\ntaskinfo = taskinfo_10cv[1:3, ]\n```\n:::\n\n\n- Create the learners we want to compare.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn.list = list(\n  makeLearner(\"classif.ksvm\", type = \"C-svc\"),\n  makeLearner(\"classif.ksvm\", type = \"kbb-svc\"),\n  makeLearner(\"classif.ksvm\", type = \"spoc-svc\")\n)\n```\n:::\n\n\n- Run the learners on the three tasks.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngrid = expand.grid(task.id = taskinfo$task.id,\n                   lrn.ind = seq_along(lrn.list))\n\nruns = lapply(seq_row(grid), function(i) {\n  message(i)\n  task = getOMLTask(grid$task.id[i])\n  ind = grid$lrn.ind[i]\n  runTaskMlr(task, lrn.list[[ind]])\n})\n```\n:::\n\n\n- And finally upload the runs to OpenML.  The upload function (uploadOMLRun)\n  returns the ID of the uploaded run object.  When uploading runs that are part\nof a certain study, tag it with study_ and the study ID. After uploading the runs appear\non the website and can be found using the tag or via the\n[study homepage](http://www.openml.org/index.php/s/27).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## please do not spam the OpenML server by uploading these\n## tasks. I already did that.\nrun.id = lapply(runs, uploadOMLRun, tags = \"study_27\")\n```\n:::\n\n\nTo show the results of our study, list the run evaluations and make a nice plot.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nevals = listOMLRunEvaluations(tag = \"study_27\")\n\nevals$task.id = as.factor(evals$task.id)\nevals$setup.id = as.factor(evals$setup.id)\n\nlibrary(\"ggplot2\")\nggplot(evals, aes(x = setup.id, y = predictive.accuracy,\n                  color = data.name, group = task.id)) +\n  geom_point() + geom_line()\n```\n:::\n\n\nNow you can go ahead and create a bigger study using the techniques you have learned.\n\n## Further infos\n\nIf you are interested in more, check out the OpenML\n[blog](https://medium.com/open-machine-learning), the\n[paper](https://www.researchgate.net/publication/263890323_OpenML_Networked_science_in_machine_learning)\nand the [GitHub repos](https://github.com/openml).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}