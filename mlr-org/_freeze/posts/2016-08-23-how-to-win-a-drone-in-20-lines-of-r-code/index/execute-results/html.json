{
  "hash": "0b8a2448084807b5a3f87d488a8b49d9",
  "result": {
    "markdown": "---\ntitle: \"How to win a drone in 20 lines of R code\"\ndescription: |\n  Showcasing model tuning using mlr.\nauthor:\n  - name: Janek Thomas\n    url: https://github.com/ja-thomas\ndate: 2016-08-23\ncategories: [\"R\", \"r-bloggers\"]\ntags: [\"kaggle\", \"xgboost\", \"rstats\"]\n\n---\n\n\n\n\nOr a less clickbaity title: __Model based optimization of machine learning models with [mlr](https://github.com/mlr-org/mlr) and [mlrMBO](https://github.com/mlr-org/mlrMBO)__.\n\nI recently participated in the [#TEFDataChallenge](http://www.tefdatachallenge.com/) a _datathon_ organized by Wayra.\nThe first price was a drone for every team member, which is a pretty awesome price.\n\nSo what exactly is a datathon?\n\n> At a datathon multiple teams consisting out of computer engineers, data scientists and experts from other fields come together to work on a case for 24 hours straight, where the purpose is to study and analyze data related to the case. Methods well known in AI will be used. A datathon is derived from a so-called hackathon, where in this case the focus is more on data rather than on innovation. Although with the upcoming field of big data bigger and more complicated problems can be solved, there is still a lack of real data scientists. Therefore a datathon is the solution: In a fun and challenging way people are triggered to come up with the best ideas! The Team with the most outstanding patterns or the best predictive models will win the datathon!\n\n[Source](http://datathon.xomnia.com/what-is-a-datathon)\n\nI already took part in some hackathons, but never in a datathon so this was a bit new for me. But\nonly 24 hours to create a prediction model as well as an interesting visualization seems quite hard.\n\nSince I signed a NDA, I won't talk about the data used in the challenge. Only so much (that's the information you can find on their website):\n\n> The aim is to build a prediction model for customer churn, a model to predict if a customer will or will not cancel a mobile contract.\n\nThis is a typical binary classification problem. Fortunately the data was already nicely preprocessed.\nNo missing values or data garbage, they even aggregated the data set already so that only one observation per costumer remained.\nThis makes the problem a bit easier: _find the best prediction model in a short amount of time_, but\nmost importantly: We don't want to spend hours coding it, so that we can use most of our time to\ncreate an awesome visualization and create/scrape additional features.\n\nTypically in these kind of challenges [stacking](https://en.wikipedia.org/wiki/Ensemble_learning#Stacking) results in the winning model. But this problematic in this case because\n\na) Stacking multiple models takes an extremely long time and/or huge computation power. We only had one\nEC2 instance.\n\nb) The judges wanted to have simple models, the simpler the model the better, while still having extremely good prediction accuracy.\n\nSo what to do when we cannot stack a hugely complected model ensemble? We use gradient boosting with trees.\nThis has multiple advantages, we have a (rather) simple model with good prediction accuracy, we can handle\ncategorical variables with large number of classes and we get variable importance measures which can be\nused in the visualization of the model. (We can also create [partial dependence plots](https://mlr-org.github.io/exploring-learner-predictions-with-partial-dependence/) to gain even more insights in the effects). We use [xgboost](https://github.com/dmlc/xgboost) which is currently the fastest implementation for gradient boosting with trees.\n\nHere is our learner definition with the param-set we want to optimize.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr)\nlrn = makeLearner(\"classif.xgboost\", eval_metric = \"auc\",\n  predict.type = \"prob\")\n\nps = makeParamSet(\n  makeIntegerParam(\"nrounds\", lower = 200, upper = 2500, default = 200),\n  makeNumericParam(\"eta\", lower = -7, upper = -5, default = -6,\n    trafo = function(x) 2^x),\n  makeIntegerParam(\"max_depth\", lower = 3, upper = 15, default = 3),\n  makeNumericParam(\"colsample_bytree\", lower = 0.3, upper = 1,\n   default = 0.6),\n  makeNumericParam(\"subsample\", lower = 0.3, upper = 1, default = 0.6)\n)\n```\n:::\n\n\nOverall we have 5 parameters (number of trees, learning rate, tree depth, bagging fraction and sub-sampling fraction) that we vary to find our optimal model.\nFor standard optimization techniques like grid search this is already a real problem because the numbers of points to search increases exponentially with every additional hyper-parameter.\n\nSince all hyper-parameter are numeric it would be possible to use evolutionary algorithms like [cmaes](https://en.wikipedia.org/wiki/CMA-ES).\nThe problem with that is, that these methods generally take a large number of function evaluation to find the optimal model, but we don't have too much time and (cross-validated) model fits are quite expensive.\n\nThis is basically the perfect situation for model based optimization. We fit a surrogate model over\nthe space of hyper-parameters and search promising points. Having only numeric hyper-parameter makes the optimization\neven nicer because we can use a Gaussian process as our surrogate model. In the figure you can see an example of model based optimization in 1 dimension. The upper figure shows evaluated points, the estimated model (dashed line) and its variance (gray area). The lower picture shows how interesting every possible point is for future exploration of the space.\nFor an in-depth introduction to model-based optimization you can read [Jones(1998)](http://www.ressources-actuarielles.net/EXT/ISFA/1226.nsf/0/f84f7ac703bf5862c12576d8002f5259/$FILE/Jones98.pdf).\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe use [mlrMBO](https://github.com/mlr-org/mlrMBO) as a general black-box optimization toolkit with is already nicely connected to mlr. The optimization definition looks like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlrMBO)\nlibrary(parallelMap)\ntask = makeClassifTask(data = data, target = \"churn\")\nmbo.ctrl = makeMBOControl(save.on.disk.at = c(0, 5, 10, 20, 50, 75, 85, 95))\nmbo.ctrl = setMBOControlTermination(mbo.ctrl, iters = 100)\nsurrogate.lrn = makeLearner(\"regr.km\", predict.type = \"se\")\nctrl = mlr:::makeTuneControlMBO(learner = surrogate.lrn,\n                                mbo.control = mbo.ctrl)\n\nparallelStartMulticore(cpus = 10L)\nres.mbo = tuneParams(lrn, task, cv10, par.set = ps, control = ctrl,\n  show.info = TRUE, measures = auc)\nparallelStop()\n```\n:::\n\n\nSome notes on this:\n\n- We save our model (actually the optimization path) at different iterations of the process, which is quite useful if anything crashes.\n- We do 100 sequential iterations after the initial design (for which we used the default setting).\n- We use kriging as our surrogate model. Actually we don't even need to specify this, since it is the default surrogate model of [mlrMBO](https://github.com/mlr-org/mlrMBO).\n- [parallelMap](https://github.com/berndbischl/parallelMap) is used to parallelize the cross-validation over all 10 available cores on the EC2 instance.\n\nThe resulting model was in the end the best model on the hidden test set and even beat a large stacking ensemble of\nmultiple boosting models, random forests and deep neural networks.\n\nOne other team used a quite similar approach, but instead of model based optimization they used [irace](http://iridia.ulb.ac.be/irace/) to tune a gradient boosting model. This can also be done in mlr quite easily:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nctrl = makeTuneControlIrace(n.instances = 200L)\nparallelStartMulticore(cpus = 10L)\nres.irace = tuneParams(lrn, task, cv10, par.set = ps, control = ctrl,\n  show.info = TRUE, measures = auc)\nparallelStop()\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}