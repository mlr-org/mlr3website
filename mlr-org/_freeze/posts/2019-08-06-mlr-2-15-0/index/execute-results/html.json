{
  "hash": "18de9971421647a689ed8449649066f6",
  "result": {
    "markdown": "---\ntitle: mlr-2.15.0\nauthors: [\"Patrick Schratz\"]\ndate: '2019-08-06'\nslug: mlr-2-15-0\ncategories:\n  - R\n  - r-bloggers\ntags:\n  - mlr\n  - release\ndescription: \"Summary of changes in mlr-2.15.0\"\n---\n\n\nWe just released _mlr_ v2.15.0 to CRAN.\nThis version includes some breaking changes and the usual bug fixes from the last three months.\n\nWe made good progress on the goal of cleaning up the [Github repo](https://github.com/mlr-org/mlr).\nWe processed nearly all open pull requests (around 40).\nIn the next months we will focus on cleaning up the issue tracker even though most of our time will go into improving the successor package [mlr3](https://github.com/mlr-org/mlr3) and its extension packages.\n\nUnless there are active contributions from the user side, we do not expect much feature additions for the next version(s) of _mlr_.\n\n# Changes to `benchmark()`\n\nThe `benchmark()` function does not store the tuning results (stored in the `$extract` slot) anymore by default.\nThis change was made to prevent BenchmarkResult (BMR) objects from getting huge in size (~ GB) when multiple models are compared with extensive tuning.\nUnless you want to do a analysis on the tuning effects, you do not need the tuning results to compare the performance of the algorithms.\nHuge BMR objects can cause various troubles.\nOne of them (which was the inital root for this change) appears when benchmarking is done on a HPC using multiple workers.\nEach worker has a limited amount of memory and expecting a huge BMR might limit the amount of workers that can be spawned.\nIn addition, loading the large resulting BMR into the global environment (or merging it using `mergeBenchmarkResults()`) for post-analysis will become a pain.\nTo save users from all of these troubles in the first place, we decided to change the default.\n\nTo store the tuning results, you have to actively set `keep.extract = TRUE` from now on.\nNot storing the tuning was actually already implicitly the default in `resample()` since the user had to set the `extract` argument manually to save certain results (tuning, feature importance).\nWith the new change the package became more consistent.\n\n# Changes to Filters\n\n## New ensemble filters\n\nWith this release it is possible to calculate ensemble filters with _mlr_ [\\@seijo-pardo2017].\n\"Ensemble filters\" are similar to ensemble models in the way that multiple filters are used to generate the ranking of features.\nMultiple aggregations functions are supported (`min()`, `mean()`, `median()`, \"Borda\") with the latter being the most used one in literature while writing this.\n\nTo our knowledge there is no other package/framework in R currently that supports ensemble filters in a similar way _mlr_ does.\nSince _mlr_ makes it possible to use filters from a [variety of different packages](https://mlr.mlr-org.com/articles/tutorial/filter_methods.html), the user is able to create powerful ensemble filters.\nNote however that currently you cannot tune the selection of simple filters since tuning a character vector param is not supported by _ParamHelpers_.\nSee [this discussion](https://github.com/berndbischl/ParamHelpers/pull/206) for more information.\n\nHere is a simple toy example how to create ensemble filters in _mlr_ from `?filterFeatures()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr)\n## Loading required package: ParamHelpers\n## Warning message: 'mlr' is in 'maintenance-only' mode since July 2019. Future development will only happen\n## in 'mlr3' (<https://mlr3.mlr-org.com>). Due to the focus on 'mlr3' there might be uncaught bugs meanwhile\n## in {mlr} - please consider switching.\nfilterFeatures(iris.task, method = \"E-min\",\n  base.methods = c(\"FSelectorRcpp_gain.ratio\", \"FSelectorRcpp_information.gain\"), abs = 2)\n## Supervised task: iris-example\n## Type: classif\n## Target: Species\n## Observations: 150\n## Features:\n##    numerics     factors     ordered functionals \n##           2           0           0           0 \n## Missings: FALSE\n## Has weights: FALSE\n## Has blocking: FALSE\n## Has coordinates: FALSE\n## Classes: 3\n##     setosa versicolor  virginica \n##         50         50         50 \n## Positive class: NA\n```\n:::\n\n\n## New return structure for filter values\n\nWith the added support for ensemble filters we also changes the return structure of calculated filter values.\n\nThe new makes it easier to apply post-analysis tasks like grouping and filtering.\nThe \"method\" of each row is now grouped into one column and the filter values are stored in a separate one.\nWe also added a default sorting of the results by the \"value\" of each \"method\".\n\nBelow is a comparison of the old and new output:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# new\ngenerateFilterValuesData(iris.task,\n  method = c(\"FSelectorRcpp_gain.ratio\", \"FSelectorRcpp_information.gain\"))\n## FilterValues:\n## Task: iris-example\n##            name    type                         filter     value\n## 1:  Petal.Width numeric       FSelectorRcpp_gain.ratio 0.8713692\n## 2: Petal.Length numeric       FSelectorRcpp_gain.ratio 0.8584937\n## 3: Sepal.Length numeric       FSelectorRcpp_gain.ratio 0.4196464\n## 4:  Sepal.Width numeric       FSelectorRcpp_gain.ratio 0.2472972\n## 5:  Petal.Width numeric FSelectorRcpp_information.gain 0.9554360\n## 6: Petal.Length numeric FSelectorRcpp_information.gain 0.9402853\n## 7: Sepal.Length numeric FSelectorRcpp_information.gain 0.4521286\n## 8:  Sepal.Width numeric FSelectorRcpp_information.gain 0.2672750\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# old\ngenerateFilterValuesData(iris.task,\n  method = c('gain.ratio','information.gain')\n## FilterValues:\n## Task: iris-example\n##           name    type gain.ratio information.gain\n## 1 Sepal.Length numeric  0.4196464        0.4521286\n## 2  Sepal.Width numeric  0.2472972        0.2672750\n## 3 Petal.Length numeric  0.8584937        0.9402853\n## 4  Petal.Width numeric  0.8713692        0.9554360\n```\n:::\n\n\n# Learners\n\nBesides the integration of new learners and some added options for integrated ones (check the [NEWS](https://mlr.mlr-org.com/news/index.html#learners---general) file), we fixed a bug that caused an incorrect aggregation of probabilities in certain cases.\nThis bug was around undetected for quite some time and was revealed due to a change in _data.table_'s `rbindlist()` function.\nThankfully [\\@danielhorn](https://github.com/danielhorn) reported this [issue](https://github.com/mlr-org/mlr/issues/2578) and we could fix it within a few days.\n\nAnother mentionable change is that the commonly used  `e1071::svm()` learner now only uses the formula interface internally if factors are present in the data.\nThis aims to prevent [\"stack overflow\" problems](https://github.com/mlr-org/mlr/issues/1738) that some user encountered with large datasets.\n\nWith [PR #1784](https://github.com/mlr-org/mlr/issues/1784) we added more support for estimating standard errors using the internal methods of the \"Random Forest\" algorithm.\nPlease check the [NEWS](https://mlr.mlr-org.com/news/index.html#learners---general) file for more detailed information about the implemented RF learners.\n\n# References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}