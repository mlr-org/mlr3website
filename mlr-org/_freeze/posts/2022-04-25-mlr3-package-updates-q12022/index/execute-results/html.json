{
  "hash": "aa37e33ced0efd591dad44600e2b66c3",
  "result": {
    "markdown": "---\ntitle: \"mlr3 package updates - q1/2022\"\ndescription: |\n  Quarterly mlr3 package updates. This posts gives an overview by listing the recent release notes of mlr3 packages from the last quarter.\nauthor:\n  - name: Sebastian Fischer\n    url: https://github.com/sebffischer\ndate: 2022-04-25\nimage: ../../images/logo_color.png\ncategories:\n    - R\n    - News\n---\n\n\n\n\nDue to the high amount of packages in the mlr3 ecosystem, it is hard to keep up with the latest changes across all packages. This posts gives an overview by listing the recent release notes of mlr3 packages from the last quarter. Note that only CRAN packages are listed here and the sort order is alphabetically.\n\n# [bbotk](https://github.com/mlr-org/bbotk)\n\n**Description: Black-Box Optimization Toolkit**\n\n## 0.5.2\n\n* refactor: The `$print()` method of `OptimInstance` omits unnecessary columns now.\n* fix: The `$clear()` method of `OptimInstance` raised an error.\n* fix: The `$clear()` method of `Archive` missed to reset the `$start_time` field.\n* feat: `Optimizer` and `Terminator` objects have the optional field `$label` now.\n* feat: `as.data.table()` functions for objects of class `Dictionary` have been extended with additional columns.\n* feat: Add a `as.data.table.DictionaryTerminator()` function.\n\n## 0.5.1\n\n* fix: The return of the `$.status()` method of `TerminatorRunTime` and `TerminatorClockTime` was not in a consistent unit.\n  The return is in seconds from now on.\n* fix: The number of evaluations was recorded as 0 in the log messages when the search space was empty.\n* feat: Add a `as.data.table.DictionaryOptimizer()` function.\n* feat: New `$help()` method which opens the manual page of an `Optimizer`.\n\n## 0.5.0\n\n* feat: Add `$nds_selection()` method to `Archive`.\n* feat: New `Codomain` class that allows extra parameters.\n* refactor: Objective values were automatically named.\n  From now on, only unnamed returns of `ObjectiveRFun` are named.\n* fix: `OptimInstance`, `Archive` and `Objective` objects  were not cloned properly.\n* refactor: The fields `$param_classes`, `$properties` and `$packages` of `Optimizer` objects are read-only now.\n* feat: The `branin()` function is exported now.\n\n# [mlr3](https://github.com/mlr-org/mlr3)\n\n**Description: Machine Learning in R - Next Generation**\n\n## 0.13.3\n\n* Most objects now have a new (optional) field `label`, i.e. `Task`,\n  `TaskGenerator`, `Learner`, `Resampling`, and `Measure`.\n* `as.data.table()` methods for objects of class `Dictonary` have been extended\n  with additional columns.\n* `as_task_classif.formula()` and `as_task_regr.formula()` now remove additional\n  atrributes attached to the data which caused some some learners to break.\n* Packages are now loaded prior to calling the `$train()` and `$predict()`\n  methods of a `Learner`. This ensures that package loading errors are properly\n  propagated and not affected by encapsulation (#771).\n\n## 0.13.2\n\n* Setting a fallback learner for a learner with encapsulation in its default\n  settings now automatically sets encapsulation to `\"evaluate\"` (#763).\n* `as_task_classif()` and `as_task_regr()` now support the construction of tasks\n  using the formula interface, e.g. `as_task_regr(mpg ~ ., data = mtcars)`\n  (#761).\n* The row role `\"validation\"` has been renamed to `\"holdout\"`.\n  In the next release, `mlr3` will start switching to the now more common terms\n  `\"train\"`/`\"validation\"` instead of `\"train\"`/`\"test\"` for the sets created\n  during resampling.\n\n\n## 0.13.1\n\n* Improved performance for many operations on `ResampleResult` and\n  `BenchmarkResult`.\n* `resample()` and `benchmark()` got a new argument `clone` to control which\n  objects to clone before performing computations.\n* Tasks are checked for infinite values during the conversion from `data.frame`\n  to `Task` in `as_task_classif()` and `as_task_regr()`. A warning is signaled\n  if any column contains infinite values.\n\n# [mlr3filters](https://github.com/mlr-org/mlr3filters)\n\n**Description: Filter-based feature selection for mlr3**\n\n## 0.5.0\n\n* Add references to benchmark paper and praznik paper (#104)\n* New filter `FilterSelectedFeatures` which makes use of embedded feature selection methods of learners.\n  See the help page for more details (#102)\n* Allow `NA` as task type.\n  This makes it possible to use other tasks than `\"regr\"` or `\"classif\"` for certain filters, e.g. `FilterVariance` (#106)\n\n# [mlr3fselect](https://github.com/mlr-org/mlr3fselect)\n\n**Description: Wrapper feature selection for mlr3**\n\n## 0.7.0\n\n* feat: Allow to pass `FSelector` objects as `method` in `fselect()` and `auto_fselector()`.\n* feat: Added `$label` to `FSelector`s.\n* docs: New examples with `fselect()` function.\n* feat: `$help()` method which opens manual page of a `FSelector`.\n* feat: Added a `as.data.table.DictionaryFSelector` function.\n* feat: Added `min_features` parameter to `FSelectorSequential`.\n\n## 0.6.1\n\n* Add `store_models` flag to `fselect()`.\n* Remove `store_x_domain` flag.\n\n# [mlr3hyperband](https://github.com/mlr-org/mlr3hyperband)\n\n**Description: Hyperband for 'mlr3'**\n\n## 0.4.0\n\n* feat: New `adjust_minimum_budget` flag in  `OptimizerSuccessiveHalving`. The\n  minimum budget is adjusted in the base stage to use the maximum budget in last\n  stage.\n* feat: New `repetitions` parameter to specify the exact number of repetitions.\n  Replaced the `repeats` parameter.\n\n## 0.3.0\n\n* feat: `TunerHyperband` evaluates configurations of same budget across\n  brackets in parallel now.\n* feat: New `repeats` parameter to repeat runs of successive halving and\n  hyperband until termination.\n* fix: Bug where maximization measures were minimized.\n\n# [mlr3proba](https://github.com/mlr-org/mlr3proba)\n\n**Description: Probabilistic Supervised Learning for 'mlr3'**\n\n## 0.4.9\n\n* Fixed bug in surv.logloss causing IPCW weighting to not be applied correctly\n\n## 0.4.8\n\n* Bug fixes in AUC measures\n\n## 0.4.7\n\n* Add right-censored log loss\n* Fix bug in {rpart} where model was being discarded when set to be kept. Parameter `model` now called `keep_model`.\n\n## 0.4.6\n\n* Patch for upstream breakages\n* Add `TaskSurv$kaplan` method\n* {survivalmodels} now imported (previously suggested)\n\n## 0.4.5\n\n* Improved reduction from survival matrix predictions to ranking predictions\n* Fixed cindex bug when all predictions equal\n* Fix for valgrind\n\n## 0.4.4\n\n* Minor change to how distributions are created to better support improper distributions\n* Fixed bug in `simsurv` task that made it impossible to predict the target\n\n## 0.4.3\n\n* Massive speed-up in distrcompositor PipeOp/pipeline\n* More informative error given if `$distr` called for a learner that does not support this return type\n* Fix massive bottleneck in scoring rule measures\n* Add Density coercions `as_task_dens` and `as_prediction_dens`\n* Measures now use parameter sets like learners. This streamlines the interface but unfortunately means ids can no longer be set dynamically.\n* Add parameters `t_max` and `p_max` to Graf, Schmid and Integrated Log-loss as an alternative to `times`. `t_max` is equivalent to `times = seq(t_max)` and `p_max` is the proportion of censoring to integrate up to in the dataset.\n* Fix bug in Rcpp code that was causing erroneous values for calculating the cindex in datasets greater than 20,000 observations.\n\n# [mlr3spatial](https://github.com/mlr-org/mlr3spatial)\n\n**Description: Support for Spatial Objects Within the 'mlr3' Ecosystem**\n\n## 0.1.2\n\n* refactor: stars objects are directly converted to terra objects now.\n\n## 0.1.1\n\n* fix: compatibility to `terra` update.\n\n# [mlr3spatiotempcv](https://github.com/mlr-org/mlr3spatiotempcv)\n\n**Description: Spatiotemporal resampling methods for mlr3**\n\n## 1.0.1\n\n* Fixed a issue which caused coordinates to appear in the feature set when a data.frame was supplied (#166, \\@be-marc)\n* Add `autoplot()` support for `\"groups\"` column role in `rsmp(\"cv\")`\n\n# [mlr3tuning](https://github.com/mlr-org/mlr3tuning)\n\n**Description: Tuning for 'mlr3'**\n\n## 0.13.0\n\n* feat: Allow to pass `Tuner` objects as `method` in `tune()` and `auto_tuner()`.\n* docs: Link `Tuner` to help page of `bbotk::Optimizer`.\n* feat: `Tuner` objects have the optional field `$label` now.\n* feat: `as.data.table()` functions for objects of class `Dictionary` have been extended with additional columns.\n\n## 0.12.1\n\n* feat: Add a `as.data.table.DictionaryTuner` function.\n* feat: New `$help()` method which opens the manual page of an `Tuner`.\n\n##  0.12.0\n\n* feat: `as_search_space()` function to create search spaces from `Learner` and `ParamSet` objects.\n  Allow to pass `TuningSpace` objects as `search_space` in `TuningInstanceSingleCrit` and `TuningInstanceMultiCrit`.\n* feat: The `mlr3::HotstartStack` can now be removed after tuning with the `keep_hotstart_stack` flag.\n* feat: The `Archive` stores errors and warnings of the learners.\n* feat: When no measure is provided, the default measure is used in `auto_tuner()` and `tune_nested()`.\n\n##  0.11.0\n\n* fix: `$assign_result()` method in `TuningInstanceSingleCrit` when search space is empty.\n* feat: Default measure is used when no measure is supplied to `TuningInstanceSingleCrit`.\n\n##  0.10.0\n\n* Fixes bug in `TuningInstanceMultiCrit$assign_result()`.\n* Hotstarting of learners with previously fitted models.\n* Remove deep clones to speed up tuning.\n* Add `store_models` flag to `auto_tuner()`.\n* Add `\"noisy\"` property to `ObjectiveTuning`.\n\n# [mlr3tuningspaces](https://github.com/mlr-org/mlr3tuningspaces)\n\n**Description: Search Spaces for Hyperparameter Tuning**\n\n## 0.2.0\n\n* feat: Add a `as.data.table.TuningSpace()` function.\n* feat: `TuningSpace` objects have the optional field `$label` now.\n* feat: New `$help()` method which opens the manual page of a `TuningSpace`.\n* feat: Add search space for `glmnet` and `kknn` to default collection.\n* feat: New `as_search_space()` function to create search spaces from `TuningSpace` objects.\n\n## 0.1.1\n\n* fix: The `subsample` hyperparameter is tuned on a logarithmic scale now.\n  The lower bound of `alpha` is reduced from `1e-4` to `1e-3`.\n  The tuning range of the `lambda` hyperparameter was 0.1 to 1.\n  From now on, `lambda` is tuned from `1e-3` to `1e3` on a logarithmic scale.\n\n## 0.1.0\n\n* refactor: update citations.\n* feat: Add `mtry.ratio` hyperparameter to tuning spaces of the ranger learner.\n* feat: Add `$print()` method to `TuningSpace` objects.\n\n# [mlr3verse](https://github.com/mlr-org/mlr3verse)\n\n**Description: Easily Install and Load the 'mlr3' Package Family**\n\n## 0.2.4\n\n* Updated reexports.\n\n# [mlr3viz](https://github.com/mlr-org/mlr3viz)\n\n**Description: Visualizations for 'mlr3'**\n\n## 0.5.8\n\n* Compatibility fixes.\n\n# [paradox](https://github.com/mlr-org/paradox)\n\n## 0.9.0\n\n* Added `default_values()` function to extract default values from `ParamSet`\n  objects.\n\n## 0.8.0\n\n* Parameters now have a new (optional) field `description`.\n* Improved printing of parameters in documentation (#355).\n* A warning is now signaled if the package `ParamHelpers` is also loaded.\n* Fixed some links.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}