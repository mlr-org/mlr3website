{
  "hash": "a30a9554dc85d47f18391cd6c98c00f3",
  "result": {
    "markdown": "---\ntitle: \"Announcing mlr3spatial\"\ndescription: |\n  We are happy to announce that mlr3spatial has been released on CRAN in November 2021.\n  [mlr3spatial](https://mlr3spatial.mlr-org.com/) simplifies the handling of spatial objects in the [mlr3](https://github.com/mlr-org) ecosystem.\n  Before [mlr3spatial](https://mlr3spatial.mlr-org.com/), the user had to extract tabular data from spatial objects to train a model or predict spatial data.\nauthor:\n  - name: Marc Becker\n    url: https://github.com/be-marc\n  - name: Patrick Schratz\n    url: https://github.com/pat-s\ndate: 2021-12-01\ncategories:\n    - R\n    - CRAN\nimage: ../../images/mlr3spatial.png\nimage-width: 70%\n---\n\n\n\ns\nWe are happy to announce that [mlr3spatial](https://mlr3spatial.mlr-org.com/) has been released on [CRAN](https://cran.r-project.org/web/packages/mlr3spatial/index.html) in November 2021.\n[mlr3spatial](https://mlr3spatial.mlr-org.com/) simplifies the handling of spatial objects in the [mlr3](https://github.com/mlr-org) ecosystem.\nBefore [mlr3spatial](https://mlr3spatial.mlr-org.com/), the user had to extract tabular data from spatial objects to train a model or predict spatial data.\n\nNow, mlr3 [Tasks](https://mlr3.mlr-org.com/reference/Task.html) can directly read from spatial objects via specialized [Data Backends](https://mlr3.mlr-org.com/reference/DataBackend.html).\nSuch tasks can be used to train a model or to perform resampling just like any other `mlr3` task.\nWe support spatial raster objects created by the [terra](https://CRAN.R-project.org/package=terra), [raster](https://CRAN.R-project.org/package=raster) and [stars](https://CRAN.R-project.org/package=stars) packages with [`DataBackendRaster`](https://mlr3spatial.mlr-org.com/reference/DataBackendRaster.html).\nAdditionally, vector data created with the [sf](https://CRAN.R-project.org/package=sf) package is handled with [`DataBackendVector`](https://mlr3spatial.mlr-org.com/reference/DataBackendVector.html).\n\nThe `predict_raster()` function creates spatial rasters and features with predictions from mlr3 learners.\nWe only have to pass a task with a spatial data backend which provides the data and spatial reference.\nTo avoid memory issues with large raster files, prediction is done in chunks.\nFor this, the raster map is divided into multiple horizontal strips.\nThe vertical extension of these strips is controlled by the `chunksize` parameter.\nThe actual memory usage per core is a multiple of the specified chunk size.\nWe choose a default chunk size of 200 Megabytes which should work on most consumer grade machines.\nIf more memory is available, a larger chunk size accelerates the prediction process.\n\nOne after the other, the raster chunks are loaded into memory and the prediction is written to disk.\nFinally, the complete raster is available on disk.\nThe learner can also make use of future-based parallelization to accelerate the predictions.\nThe vignette on [“Benchmarking parallel predictions”](https://mlr3spatial.mlr-org.com/articles/benchmark.html) showcases the parallelization capabilities of [mlr3spatial](https://mlr3spatial.mlr-org.com/).\n\n## Use Case - Landsat7 data as {stars} object\n\n### Data Preparation\n\n\n\n\n::: {.cell}\n\n:::\n\n\nFirst, the TIFF files is read via `stars::read_stars()` and put into a `DataBackendRaster`.\nThe DataBackend is then used to create a regression task with the response being `layer.1`.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n<TaskRegr:backend> (122848 x 6)\n* Target: band1\n* Properties: -\n* Features (5):\n  - dbl (5): band2, band3, band4, band5, band6\n```\n:::\n:::\n\n\nFor large raster files with millions of values it helps to predict in parallel.\nTo enable this, set `learner$parallel_predict = TRUE` and initiate a parallel plan via {future}, e.g. via `plan(\"multisession\")`.\nSince this is only an example, parallelization is not enabled here.\nHere we will use a simple regression tree as an example learner.\nIn practice you might want to use a different learner - you can find an overview of available learners [here](https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html).\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerRegrRpart:regr.rpart>: Regression Tree\n* Model: rpart\n* Parameters: xval=0\n* Packages: mlr3, rpart\n* Predict Types:  [response]\n* Feature Types: logical, integer, numeric, factor, ordered\n* Properties: importance, missings, selected_features, weights\n```\n:::\n:::\n\n\n### Prediction\n\nFor prediction `predict_spatial()` is used.\nIt will return a raster file which contains the predictions.\nUsers can select which R spatial format the returned raster should have.\nNote that by default `mlr3spatial` operates with `SpatRaster` objects from package `terra`.\nIf a different output format is requested (e.g. `\"stars\"`), coercion is happening in the background which might take some time.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nINFO  [18:48:29.071] [mlr3] Start raster prediction\nINFO  [18:48:29.242] [mlr3] Prediction is executed with a chunksize of 200 Megabytes, 1 chunk(s) in total, 122848 values per chunk\nINFO  [18:48:30.147] [mlr3] Chunk 1 of 1 finished\nINFO  [18:48:30.183] [mlr3] Finished raster prediction in 1 seconds\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nstars object with 2 dimensions and 1 attribute\nattribute(s):\n            Min.  1st Qu.   Median     Mean 3rd Qu.     Max.\ncadmium  62.3629 70.30233 77.01695 79.05135 89.2809 118.1429\ndimension(s):\n  from  to  offset delta                     refsys point values x/y\nx    1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [x]\ny    1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [y]\n```\n:::\n:::\n\n\n### Visualization\n\nFinally we can plot the predictions.\nThe color vector is extracted from the \"viridis\" color palette via `dput(viridis::viridis_pal()(5))` and provided to the S3 `plot()` call, which makes use of the S3 plot method within the `stars` package in this scenario.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](announcing-mlr3spatial_files/figure-html/announcing-mlr3spatial-007-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "announcing-mlr3spatial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}