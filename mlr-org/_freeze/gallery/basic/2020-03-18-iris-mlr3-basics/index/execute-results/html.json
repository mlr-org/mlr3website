{
  "hash": "51de80b3afa7f5de683a3d30c041215f",
  "result": {
    "markdown": "---\ntitle: mlr3 Basics on \"Iris\" - Hello World!\nslug: mlr3-basics-iris\ncategories:\n  - classification\ndescription: |\n  Learn the basic operations train, predict, score, resample, and benchmark.\nauthor:\n  - name: Bernd Bischl\ndate: 03-18-2020\naliases:\n  - ../../../gallery/2020-03-18-iris-mlr3-basics/index.html\n---\n\n\n\n\n## Goals and Prerequisites\n\nThis use case shows how to use the basic [mlr3](https://mlr3.mlr-org.com) package on the iris [`Task`](https://mlr3.mlr-org.com/reference/Task.html), so it's our \"Hello World\" example.\nIt assumes no prior knowledge in ML or [mlr3](https://mlr3.mlr-org.com).\nYou can find most of the content here also in the [mlr3book](https://mlr3book.mlr-org.com/) in a more detailed way.\nHence we will not make a lot of general comments, but keep it hands-on and short.\n\nThe following operations are shown:\n\n* Creating [`Tasks`](https://mlr3.mlr-org.com/reference/Task.html) and [`Learners`](https://mlr3.mlr-org.com/reference/Learner.html)\n* Training and predicting\n* [`Resampling`](https://mlr3.mlr-org.com/reference/Resampling.html) / [`cross-validation`](https://mlr3.mlr-org.com/reference/mlr_resamplings_cv.html)\n* Installing more [`Learners`](https://mlr3.mlr-org.com/reference/Learner.html)\n* [`Benchmarking`](https://mlr3.mlr-org.com/reference/benchmark.html) to compare multiple `Learners`\n\n## Loading basic packages\n\nWe load the [mlr3verse](https://mlr3verse.mlr-org.com) package which pulls in the most important packages for this example.\nThe [mlr3learners](https://mlr3learners.mlr-org.com) package loads additional [`learners`](https://mlr3.mlr-org.com/reference/Learner.html).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlibrary(mlr3learners)\n\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n```\n:::\n\n\n## Creating tasks and learners\n\nLet's work on the canonical, simple iris data set, and try out some ML algorithms.\nWe will start by using a decision tree with default settings.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# creates mlr3 task from scratch, from a data.frame\n# 'target' names the column in the dataset we want to learn to predict\ntask = as_task_classif(iris, target = \"Species\")\n# in this case we could also take the iris example from mlr3's dictionary of shipped example tasks\n# 2 equivalent calls to create a task. The second is just sugar for the user.\ntask = mlr_tasks$get(\"iris\")\ntask = tsk(\"iris\")\nprint(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskClassif:iris> (150 x 5): Iris Flowers\n* Target: Species\n* Properties: multiclass\n* Features (4):\n  - dbl (4): Petal.Length, Petal.Width, Sepal.Length, Sepal.Width\n```\n:::\n\n```{.r .cell-code}\n# create learner from dictionary of mlr3learners\n# 2 equivalent calls:\nlearner_1 = mlr_learners$get(\"classif.rpart\")\nlearner_1 = lrn(\"classif.rpart\")\nprint(learner_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerClassifRpart:classif.rpart>: Classification Tree\n* Model: -\n* Parameters: xval=0\n* Packages: mlr3, rpart\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, factor, ordered\n* Properties: importance, missings, multiclass, selected_features, twoclass, weights\n```\n:::\n:::\n\n\n## Train and predict\n\nNow the usual ML operations: Train on some observations, predict on others.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# train learner on subset of task\nlearner_1$train(task, row_ids = 1:120)\n# this is what the decision tree looks like\nprint(learner_1$model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nn= 120 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 120 70 setosa (0.41666667 0.41666667 0.16666667)  \n  2) Petal.Length< 2.45 50  0 setosa (1.00000000 0.00000000 0.00000000) *\n  3) Petal.Length>=2.45 70 20 versicolor (0.00000000 0.71428571 0.28571429)  \n    6) Petal.Length< 4.95 49  1 versicolor (0.00000000 0.97959184 0.02040816) *\n    7) Petal.Length>=4.95 21  2 virginica (0.00000000 0.09523810 0.90476190) *\n```\n:::\n\n```{.r .cell-code}\n# predict using observations from task\nprediction = learner_1$predict(task, row_ids = 121:150)\n# predict using \"new\" observations from an external data.frame\nprediction = learner_1$predict_newdata(newdata = iris[121:150, ])\nprint(prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionClassif> for 30 observations:\n    row_ids     truth   response\n          1 virginica  virginica\n          2 virginica versicolor\n          3 virginica  virginica\n---                             \n         28 virginica  virginica\n         29 virginica  virginica\n         30 virginica  virginica\n```\n:::\n:::\n\n\n## Evaluation\n\nLet's score our [`Prediction`](https://mlr3.mlr-org.com/reference/Prediction.html) object with some metrics.\nAnd take a deeper look by inspecting the confusion matrix.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(as.data.table(mlr_measures))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              key                          label task_type          packages predict_type task_properties\n1:            aic   Akaika Information Criterion      <NA>              mlr3         <NA>                \n2:            bic Bayesian Information Criterion      <NA>              mlr3         <NA>                \n3:    classif.acc        Classification Accuracy   classif mlr3,mlr3measures     response                \n4:    classif.auc       Area Under the ROC Curve   classif mlr3,mlr3measures         prob        twoclass\n5:   classif.bacc              Balanced Accuracy   classif mlr3,mlr3measures     response                \n6: classif.bbrier             Binary Brier Score   classif mlr3,mlr3measures         prob        twoclass\n```\n:::\n\n```{.r .cell-code}\nscores = prediction$score(msr(\"classif.acc\"))\nprint(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.acc \n  0.8333333 \n```\n:::\n\n```{.r .cell-code}\nscores = prediction$score(msrs(c(\"classif.acc\", \"classif.ce\")))\nprint(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.acc  classif.ce \n  0.8333333   0.1666667 \n```\n:::\n\n```{.r .cell-code}\ncm = prediction$confusion\nprint(cm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            truth\nresponse     setosa versicolor virginica\n  setosa          0          0         0\n  versicolor      0          0         5\n  virginica       0          0        25\n```\n:::\n:::\n\n\n## Changing hyperpars\n\nThe [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) contains information about all parameters that can be configured, including data type, constraints, defaults, etc.\nWe can change the hyperparameters either during construction of later through an active binding.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nas.data.table(learner_1$param_set)[, .(id, class, lower, upper, nlevels)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                id    class lower upper nlevels\n 1:             cp ParamDbl     0     1     Inf\n 2:     keep_model ParamLgl    NA    NA       2\n 3:     maxcompete ParamInt     0   Inf     Inf\n 4:       maxdepth ParamInt     1    30      30\n 5:   maxsurrogate ParamInt     0   Inf     Inf\n 6:      minbucket ParamInt     1   Inf     Inf\n 7:       minsplit ParamInt     1   Inf     Inf\n 8: surrogatestyle ParamInt     0     1       2\n 9:   usesurrogate ParamInt     0     2       3\n10:           xval ParamInt     0   Inf     Inf\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner_2 = lrn(\"classif.rpart\", predict_type = \"prob\", minsplit = 50)\nlearner_2$param_set$values$minsplit = 50\n```\n:::\n\n\n## Resampling\n\n[`Resampling`](https://mlr3.mlr-org.com/reference/Resampling.html) simply repeats the train-predict-score loop and collects all results in a nice [`data.table::data.table()`](https://www.rdocumentation.org/packages/data.table/topics/data.table).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncv10 = rsmp(\"cv\", folds = 10)\nrr = resample(task, learner_1, cv10)\nprint(rr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ResampleResult> of 10 iterations\n* Task: iris\n* Learner: classif.rpart\n* Warnings: 0 in 0 iterations\n* Errors: 0 in 0 iterations\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrr$score(msrs(c(\"classif.acc\", \"classif.ce\")))[, .(iteration, task_id, learner_id, resampling_id, classif.ce)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    iteration task_id    learner_id resampling_id classif.ce\n 1:         1    iris classif.rpart            cv 0.06666667\n 2:         2    iris classif.rpart            cv 0.00000000\n 3:         3    iris classif.rpart            cv 0.06666667\n 4:         4    iris classif.rpart            cv 0.06666667\n 5:         5    iris classif.rpart            cv 0.20000000\n 6:         6    iris classif.rpart            cv 0.06666667\n 7:         7    iris classif.rpart            cv 0.06666667\n 8:         8    iris classif.rpart            cv 0.00000000\n 9:         9    iris classif.rpart            cv 0.00000000\n10:        10    iris classif.rpart            cv 0.20000000\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# get all predictions nicely concatenated in a table\nprediction = rr$prediction()\nas.data.table(prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     row_ids      truth   response\n  1:       5     setosa     setosa\n  2:       7     setosa     setosa\n  3:      26     setosa     setosa\n  4:      34     setosa     setosa\n  5:      55 versicolor versicolor\n ---                              \n146:     100 versicolor versicolor\n147:     113  virginica  virginica\n148:     124  virginica  virginica\n149:     136  virginica  virginica\n150:     139  virginica versicolor\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncm = prediction$confusion\nprint(cm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            truth\nresponse     setosa versicolor virginica\n  setosa         50          0         0\n  versicolor      0         45         6\n  virginica       0          5        44\n```\n:::\n:::\n\n\n## Populating the learner dictionary\n\n[mlr3learners](https://mlr3learners.mlr-org.com) ships out with a dozen different popular [`Learners`](https://mlr3.mlr-org.com/reference/Learner.html).\nWe can list them from the dictionary.\nIf we want more, we can install an extension package, [mlr3extralearners](https://mlr3extralearners.mlr-org.com), from GitHub.\nNote how after loading `mlr3extralearners` the dictionary increases in size.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(as.data.table(mlr_learners)[, c(\"key\", \"packages\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   key                 packages\n1:   classif.cv_glmnet mlr3,mlr3learners,glmnet\n2:       classif.debug                     mlr3\n3: classif.featureless                     mlr3\n4:      classif.glmnet mlr3,mlr3learners,glmnet\n5:        classif.kknn   mlr3,mlr3learners,kknn\n6:         classif.lda   mlr3,mlr3learners,MASS\n```\n:::\n\n```{.r .cell-code}\nlibrary(mlr3extralearners)\nprint(as.data.table(mlr_learners)[, c(\"key\", \"packages\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    key                                                packages\n  1: classif.AdaBoostM1                            mlr3,mlr3extralearners,RWeka\n  2:        classif.C50                              mlr3,mlr3extralearners,C50\n  3:        classif.IBk                            mlr3,mlr3extralearners,RWeka\n  4:        classif.J48                            mlr3,mlr3extralearners,RWeka\n  5:       classif.JRip                            mlr3,mlr3extralearners,RWeka\n ---                                                                           \n130:     surv.penalized       mlr3,mlr3proba,mlr3extralearners,penalized,pracma\n131:        surv.ranger                 mlr3,mlr3proba,mlr3extralearners,ranger\n132:         surv.rfsrc mlr3,mlr3proba,mlr3extralearners,randomForestSRC,pracma\n133:           surv.svm            mlr3,mlr3proba,mlr3extralearners,survivalsvm\n134:       surv.xgboost                mlr3,mlr3proba,mlr3extralearners,xgboost\n```\n:::\n:::\n\n\n## Benchmarking multiple learners\n\nThe [`benchmark`](https://mlr3.mlr-org.com/reference/benchmark.html) function can conveniently compare `r ref(\"Learner\", \"Learners\") on the same dataset(s).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearners = list(learner_1, learner_2, lrn(\"classif.randomForest\"))\ngrid = benchmark_grid(task, learners, cv10)\nbmr = benchmark(grid)\nprint(bmr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<BenchmarkResult> of 30 rows with 3 resampling runs\n nr task_id           learner_id resampling_id iters warnings errors\n  1    iris        classif.rpart            cv    10        0      0\n  2    iris        classif.rpart            cv    10        0      0\n  3    iris classif.randomForest            cv    10        0      0\n```\n:::\n\n```{.r .cell-code}\nprint(bmr$aggregate(measures = msrs(c(\"classif.acc\", \"classif.ce\"))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nr      resample_result task_id           learner_id resampling_id iters classif.acc classif.ce\n1:  1 <ResampleResult[21]>    iris        classif.rpart            cv    10   0.9266667 0.07333333\n2:  2 <ResampleResult[21]>    iris        classif.rpart            cv    10   0.9266667 0.07333333\n3:  3 <ResampleResult[21]>    iris classif.randomForest            cv    10   0.9533333 0.04666667\n```\n:::\n:::\n\n\n## Conclusion\n\nWe left out a lot of details and other features.\nIf you want to know more, read the [mlr3book](https://mlr3book.mlr-org.com/) and the documentation of the mentioned packages.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}