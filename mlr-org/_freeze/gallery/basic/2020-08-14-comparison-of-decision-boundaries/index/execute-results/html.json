{
  "hash": "4e54cd13ef7ff761d0479cc169b323cb",
  "result": {
    "markdown": "---\ntitle: Comparison of Decision Boundaries of Classification Learners\ncategories:\n  - classification\n  - visualization\nauthor:\n  - name: Michel Lang\ndescription: |\n  Visualize the decision boundaries of multiple classification learners on some artificial data sets.\ndate: 08-14-2020\nimage: thumbnail.png\n---\n\n\n\n\nThe visualization of decision boundaries helps to understand what the pros and cons of individual classification learners are.\nThis posts demonstrates how to create such plots.\n\nWe load the [mlr3](https://mlr3.mlr-org.com) package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(\"mlr3\")\n```\n:::\n\n\nWe initialize the random number generator with a fixed seed for reproducibility, and decrease the verbosity of the logger to keep the output clearly represented.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(7832)\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n```\n:::\n\n\n## Artificial Data Sets\n\nThe three artificial data sets are generated by [`task generators`](https://mlr3.mlr-org.com/reference/TaskGenerator.html) (implemented in [mlr3](https://mlr3.mlr-org.com)):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nN <- 200\ntasks <- list(\n  tgen(\"xor\")$generate(N),\n  tgen(\"moons\")$generate(N),\n  tgen(\"circle\")$generate(N)\n)\n```\n:::\n\n\n### XOR\n\nPoints are distributed on a 2-dimensional cube with corners $(\\pm 1, \\pm 1)$.\nClass is `\"red\"` if $x$ and $y$ have the same sign, and `\"black\"` otherwise.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(tgen(\"xor\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2020-08-14-comparison-of-decision-boundaries-004-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Circle\n\nTwo circles with same center but different radii.\nPoints in the smaller circle are `\"black\"`, points only in the larger circle are `\"red\"`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(tgen(\"circle\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2020-08-14-comparison-of-decision-boundaries-005-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Moons\nTwo interleaving half circles (\"moons\").\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(tgen(\"moons\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2020-08-14-comparison-of-decision-boundaries-006-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Learners\n\nWe consider the following learners:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(\"mlr3learners\")\n\nlearners <- list(\n  # k-nearest neighbours classifier\n  lrn(\"classif.kknn\", id = \"kkn\", predict_type = \"prob\", k = 3),\n\n  # linear svm\n  lrn(\"classif.svm\", id = \"lin. svm\", predict_type = \"prob\", kernel = \"linear\"),\n\n  # radial-basis function svm\n  lrn(\"classif.svm\",\n    id = \"rbf svm\", predict_type = \"prob\", kernel = \"radial\",\n    gamma = 2, cost = 1, type = \"C-classification\"\n  ),\n\n  # naive bayes\n  lrn(\"classif.naive_bayes\", id = \"naive bayes\", predict_type = \"prob\"),\n\n  # single decision tree\n  lrn(\"classif.rpart\", id = \"tree\", predict_type = \"prob\", cp = 0, maxdepth = 5),\n\n  # random forest\n  lrn(\"classif.ranger\", id = \"random forest\", predict_type = \"prob\")\n)\n```\n:::\n\nThe hyperparameters are chosen in a way that the decision boundaries look \"typical\" for the respective classifier.\nOf course, with different hyperparameters, results may look very different.\n\n## Fitting the Models\n\nTo apply each learner on each task, we first build an exhaustive grid design of experiments with [`benchmark_grid()`](https://mlr3.mlr-org.com/reference/benchmark_grid.html) and then pass it to [`benchmark()`](https://mlr3.mlr-org.com/reference/benchmark.html) to do the actual work.\nA simple holdout resampling is used here:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndesign <- benchmark_grid(\n  tasks = tasks,\n  learners = learners,\n  resamplings = rsmp(\"holdout\")\n)\n\nbmr <- benchmark(design, store_models = TRUE)\n```\n:::\n\n\nA quick look into the performance values:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nperf <- bmr$aggregate(msr(\"classif.acc\"))[, c(\"task_id\", \"learner_id\", \"classif.acc\")]\nperf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       task_id    learner_id classif.acc\n 1:    xor_200           kkn   0.9402985\n 2:    xor_200      lin. svm   0.5223881\n 3:    xor_200       rbf svm   0.9701493\n 4:    xor_200   naive bayes   0.4328358\n 5:    xor_200          tree   0.9402985\n 6:    xor_200 random forest   1.0000000\n 7:  moons_200           kkn   1.0000000\n 8:  moons_200      lin. svm   0.8805970\n 9:  moons_200       rbf svm   1.0000000\n10:  moons_200   naive bayes   0.8955224\n11:  moons_200          tree   0.8955224\n12:  moons_200 random forest   0.9552239\n13: circle_200           kkn   0.8805970\n14: circle_200      lin. svm   0.4925373\n15: circle_200       rbf svm   0.8955224\n16: circle_200   naive bayes   0.7014925\n17: circle_200          tree   0.7462687\n18: circle_200 random forest   0.7761194\n```\n:::\n:::\n\n\n\n## Plotting\n\nTo generate the plots, we iterate over the individual [`ResampleResult`](https://mlr3.mlr-org.com/reference/ResampleResult.html) objects stored in the [`BenchmarkResult`](https://mlr3.mlr-org.com/reference/BenchmarkResult.html), and in each iteration we store the plot of the learner prediction generated by the [mlr3viz](https://mlr3viz.mlr-org.com) package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(\"mlr3viz\")\n\nn <- bmr$n_resample_results\nplots <- vector(\"list\", n)\nfor (i in seq_len(n)) {\n  rr <- bmr$resample_result(i)\n  plots[[i]] <- autoplot(rr, type = \"prediction\")\n}\n```\n:::\n\n\nWe now have a list of plots.\nEach one can be printed individually:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprint(plots[[1]])\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2020-08-14-comparison-of-decision-boundaries-011-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nNote that only observations from the test data is plotted as points.\n\nTo get a nice annotated overview, we arranged all plots together in a single pdf file.\nThe number in the upper right is the respective accuracy on the test set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npdf(file = \"plot_learner_prediction.pdf\", width = 20, height = 6)\nntasks <- length(tasks)\nnlearners <- length(learners)\nm <- msr(\"classif.acc\")\n\n# for each plot\nfor (i in seq_along(plots)) {\n  plots[[i]] <- plots[[i]] +\n    # remove legend\n    ggplot2::theme(legend.position = \"none\") +\n    # remove labs\n    ggplot2::xlab(\"\") + ggplot2::ylab(\"\") +\n    # add accuracy score as annotation\n    ggplot2::annotate(\"text\",\n      label = sprintf(\"%.2f\", bmr$resample_result(i)$aggregate(m)),\n      x = Inf, y = Inf, vjust = 2, hjust = 1.5\n    )\n}\n\n# for each plot of the first column\nfor (i in seq_len(ntasks)) {\n  ii <- (i - 1) * nlearners + 1L\n  plots[[ii]] <- plots[[ii]] + ggplot2::ylab(sub(\"_[0-9]+$\", \"\", tasks[[i]]$id))\n}\n\n# for each plot of the first row\nfor (i in seq_len(nlearners)) {\n  plots[[i]] <- plots[[i]] + ggplot2::ggtitle(learners[[i]]$id)\n}\n\ngridExtra::grid.arrange(grobs = plots, nrow = length(tasks))\ndev.off()\n```\n:::\n\n\nAs you can see, the decision boundaries look very different.\nSome are linear, others are parallel to the axis, and yet others are highly non-linear.\nThe boundaries are partly very smooth with a slow transition of probabilities, others are very abrupt.\nAll these properties are important during model selection, and should be considered for your problem at hand.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}