{
  "hash": "136450dcbfa69a40760c0eac5764b070",
  "result": {
    "markdown": "---\ntitle: Encode Factor Levels for xgboost\ncategories:\n  - classification\n  - mlr3pipelines\n  - factor encoding\nauthor:\n  - name: Michel Lang\ndate: 01-31-2020\ndescription: |\n  Encode factor variables in a task.\naliases:\n  - ../../../gallery/2020-01-31-encode-factors-for-xgboost/index.html\n---\n\n\n\n\n\n\nThe package [xgboost](https://cran.r-project.org/package=xgboost) unfortunately does not support handling of categorical features.\nTherefore, it is required to manually convert factor columns to numerical dummy features.\nWe show how to use [mlr3pipelines](https://mlr3pipelines.mlr-org.com) to augment the [`xgboost learner`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.xgboost.html) with an automatic factor encoding.\n\nWe load the [mlr3verse](https://mlr3verse.mlr-org.com) package which pulls in the most important packages for this example.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: mlr3\n```\n:::\n:::\n\n\nWe initialize the random number generator with a fixed seed for reproducibility, and decrease the verbosity of the logger to keep the output clearly represented.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(7832)\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n```\n:::\n\n\n## Construct the Base Objects\n\nFirst, we take an example task with factors ([`german_credit`](https://mlr3.mlr-org.com/reference/mlr_tasks_german_credit.html)) and create the [`xgboost learner`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.xgboost.html):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3learners)\n\ntask = tsk(\"german_credit\")\nprint(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskClassif:german_credit> (1000 x 21): German Credit\n* Target: credit_risk\n* Properties: twoclass\n* Features (20):\n  - fct (14): credit_history, employment_duration, foreign_worker, housing, job, other_debtors,\n    other_installment_plans, people_liable, personal_status_sex, property, purpose, savings, status,\n    telephone\n  - int (3): age, amount, duration\n  - ord (3): installment_rate, number_credits, present_residence\n```\n:::\n\n```{.r .cell-code}\nlearner = lrn(\"classif.xgboost\", nrounds = 100)\nprint(learner)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerClassifXgboost:classif.xgboost>\n* Model: -\n* Parameters: nrounds=100, nthread=1, verbose=0, early_stopping_set=none\n* Packages: mlr3, mlr3learners, xgboost\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric\n* Properties: hotstart_forward, importance, missings, multiclass, twoclass, weights\n```\n:::\n:::\n\n\nWe now compare the feature types of the task and the supported feature types:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunique(task$feature_types$type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"integer\" \"factor\"  \"ordered\"\n```\n:::\n\n```{.r .cell-code}\nlearner$feature_types\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"logical\" \"integer\" \"numeric\"\n```\n:::\n\n```{.r .cell-code}\nsetdiff(task$feature_types$type, learner$feature_types)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"  \"ordered\"\n```\n:::\n:::\n\n\nIn this example, we have to convert factors and ordered factors to numeric columns to apply the xgboost learner.\nBecause xgboost is based on decision trees (at least in its default settings), it is perfectly fine to convert the ordered factors to integer.\nUnordered factors must still be encoded though.\n\n# Construct Operators\n\nThe factor encoder's man page can be found under [`mlr_pipeops_encode`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_encode.html).\nHere, we decide to use \"treatment\" encoding (first factor level serves as baseline, and there will be a new binary column for each additional level).\nWe restrict the operator to factor columns using the respective [`Selector`](https://mlr3pipelines.mlr-org.com/reference/Selector.html) `selector_type()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfencoder = po(\"encode\", method = \"treatment\", affect_columns = selector_type(\"factor\"))\n```\n:::\n\n\nWe can manually trigger the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) to test the operator on our task:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfencoder$train(list(task))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$output\n<TaskClassif:german_credit> (1000 x 50): German Credit\n* Target: credit_risk\n* Properties: twoclass\n* Features (49):\n  - dbl (43): credit_history.all.credits.at.this.bank.paid.back.duly,\n    credit_history.critical.account.other.credits.elsewhere,\n    credit_history.existing.credits.paid.back.duly.till.now,\n    credit_history.no.credits.taken.all.credits.paid.back.duly, employment_duration....7.yrs,\n    employment_duration...1.yr, employment_duration.1..........4.yrs, employment_duration.4..........7.yrs,\n    foreign_worker.yes, housing.own, housing.rent, job.manager.self.empl.highly.qualif..employee,\n    job.skilled.employee.official, job.unskilled...resident, other_debtors.co.applicant,\n    other_debtors.guarantor, other_installment_plans.none, other_installment_plans.stores,\n    people_liable.3.or.more, personal_status_sex.female...non.single.or.male...single,\n    personal_status_sex.female...single, personal_status_sex.male...married.widowed,\n    property.building.soc..savings.agr....life.insurance, property.car.or.other, property.real.estate,\n    purpose.business, purpose.car..new., purpose.car..used., purpose.domestic.appliances,\n    purpose.education, purpose.furniture.equipment, purpose.radio.television, purpose.repairs,\n    purpose.retraining, purpose.vacation, savings........1000.DM, savings.......100.DM,\n    savings.100..........500.DM, savings.500..........1000.DM,\n    status........200.DM...salary.for.at.least.1.year, status.......0.DM, status.0.........200.DM,\n    telephone.yes..under.customer.name.\n  - int (3): age, amount, duration\n  - ord (3): installment_rate, number_credits, present_residence\n```\n:::\n:::\n\n\nThe ordered factor remained untouched, all other factors have been converted to numeric columns.\nTo also convert the ordered variables `installment_rate`, `number_credits`, and `present_residence`, we construct the [`colapply`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_colapply.html) operator with the converter `as.integer()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nord_to_int = po(\"colapply\", applicator = as.integer, affect_columns = selector_type(\"ordered\"))\n```\n:::\n\n\nApplied on the original task, it changes factor columns to `integer`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nord_to_int$train(list(task))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$output\n<TaskClassif:german_credit> (1000 x 21): German Credit\n* Target: credit_risk\n* Properties: twoclass\n* Features (20):\n  - fct (14): credit_history, employment_duration, foreign_worker, housing, job, other_debtors,\n    other_installment_plans, people_liable, personal_status_sex, property, purpose, savings, status,\n    telephone\n  - int (6): age, amount, duration, installment_rate, number_credits, present_residence\n```\n:::\n:::\n\n\n## Construct Pipeline\n\nFinally, we construct a linear pipeline consisting of\n\n1. the factor encoder `fencoder`,\n2. the ordered factor converter `ord_to_int`, and\n3. the xgboost base learner.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngraph = fencoder %>>% ord_to_int %>>% learner\nprint(graph)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGraph with 3 PipeOps:\n              ID         State        sccssors prdcssors\n          encode        <list>        colapply          \n        colapply        <list> classif.xgboost    encode\n classif.xgboost <<UNTRAINED>>                  colapply\n```\n:::\n:::\n\n\nThe pipeline is wrapped in a [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) so that it behaves like a regular learner:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngraph_learner = as_learner(graph)\n```\n:::\n\n\nWe can now apply the new learner on the task, here with a 3-fold cross validation:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrr = resample(task, graph_learner, rsmp(\"cv\", folds = 3))\nrr$aggregate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n 0.2620435 \n```\n:::\n:::\n\n\nSuccess! We augmented xgboost with handling of factors and ordered factors.\nIf we combine this learner with a tuner from [mlr3tuning](https://mlr3tuning.mlr-org.com), we get a universal and competitive learner.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}