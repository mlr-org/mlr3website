{
  "hash": "12ce3c5282db1abd13d3fb975e439af8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Encoding and Scaling\ncategories:\n  - feature preprocessing\n  - encoding\n  - scaling\nauthor:\n  - name: Giuseppe Casalicchio\n  - name: Essential Data Science Training GmbH\n    url: https://www.essentialds.de\ndescription: |\n  Create a pipeline to do feature preprocessing (one-hot-encoding, Yeo-Johnson transformation) for the german credit task.\ndate: \"\"\nparams:\n  showsolution: true\n  base64encode: true\nlisting: false\nsearch: false\nformat:\n  html:\n    filters:\n      - ../../b64_solution.lua\n---\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n```{=html}\n<script>\nconst correctHash = \"590df6ddab26846343e04fff0e1d96e5614b4fa0263c86ede0cca0190e6aa6f2\";   // value injected by knitr\n\n/* ---------- reusable helper ---------- */\nfunction b64DecodeUtf8(b64) {\n  // 1) atob  -> binary-string   (bytes 0…255)\n  // 2) map   -> Uint8Array      (array of bytes)\n  // 3) TextDecoder('utf-8')     -> real JS string\n  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n  return new TextDecoder('utf-8').decode(bytes);\n}\n\nasync function sha256(txt) {\n  const buf = await crypto.subtle.digest('SHA-256',\n                 new TextEncoder().encode(txt));\n  return Array.from(new Uint8Array(buf))\n              .map(b => b.toString(16).padStart(2, '0')).join('');\n}\n\nasync function unlockOne(btn) {\n  const pass = prompt(\"Password:\");\n  if (!pass) return;\n  if (await sha256(pass) !== correctHash) {\n    alert(\"Wrong password\"); return;\n  }\n\n  /* --- decode only the solution that belongs to THIS button --- */\n  const wrapper = btn.parentElement;             // .b64-wrapper\n  wrapper.querySelectorAll('.hidden-solution').forEach(div => {\n    div.innerHTML = b64DecodeUtf8(div.dataset.encoded);\n    div.classList.remove('hidden-solution');\n    div.style.display = 'block';\n  });\n\n  /* Remove the button so the user can’t click it again */\n  btn.remove();\n}\n</script>\n\n<noscript>\n<div style=\"border: 1px solid #ccc; padding: 1em; margin-top: 1em; background: #f9f9f9;\">\n    <strong>JavaScript is required to unlock solutions.</strong><br>\n    Please enable JavaScript and reload the page,<br>\n    or download the source files from\n    <a href=\"https://github.com/mlr-org/mlr3website/\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>\n    and run the code locally.\n  </div>\n</noscript>\n```\n\n\n\n\n# Goal\n\nLearn how to do preprocessing steps directly on a mlr3 `Task` object and how to combine a preprocessing with a learner to create a simple linear ML pipeline that first applies the preprocessing and then trains a learner.\n\n# German Credit Data\n\n## Description\n\n- Data from 1973 to 1975 from a large regional bank in southern Germany classifying credits described by a set of attributes to good or bad credit risks.\n- Stratified sample of 1000 credits (300 bad ones and 700 good ones).\n- Customers with good credit risks perfectly complied with the conditions of the contract while customers with bad credit risks did not comply with the contract as required.\n- Available in `tsk(\"german_credit\")`.\n\n## Data Dictionary\n\nn = 1,000 observations of credits\n\n- `credit_risk`: Has the credit contract been complied with (good) or not (bad)?\n- `age`: Age of debtor in years\n- `amount`: Credit amount in DM\n- `credit_history`: History of compliance with previous or concurrent credit contracts\n- `duration`: Credit duration in months\n- `employment_duration`: Duration of debtor's employment with current employer\n- `foreign_worker`: Whether the debtor is a foreign worker\n- `housing`: Type of housing the debtor lives in\n- `installment_rate`: Credit installments as a percentage of debtor's disposable income\n- `job`: Quality of debtor's job\n- `number_credits`: Number of credits including the current one the debtor has (or had) at this bank\n- `other_debtors`: Whether there is another debtor or a guarantor for the credit\n- `other_installment_plans`: Installment plans from providers other than the credit-giving bank\n- `people_liable`: Number of persons who financially depend on the debtor\n- `personal_status_sex`: Combined information on sex and marital status\n- `present_residence`: Length of time (in years) the debtor lives in the present residence\n- `property`: The debtor's most valuable property\n- `purpose`: Purpose for which the credit is needed\n- `savings`: Debtor's saving\n- `status`: Status of the debtor's checking account with the bank\n- `telephone`: Whether there is a telephone landline registered on the debtor's name\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3)\nlibrary(mlr3learners)\nlibrary(xgboost)\ntask = tsk(\"german_credit\")\n```\n:::\n\n\n<details>\n  <summary>**Recap: mlr3 Tasks**</summary> \n\nAn `mlr3` `Task` encapsulates data with meta-information, such as the name of the target variable and the type of the learning problem (in our example this would be a **classification** task, where the target is a factor label with relatively few distinct values).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<TaskClassif:german_credit> (1000 x 21): German Credit\n* Target: credit_risk\n* Properties: twoclass\n* Features (20):\n  - fct (14): credit_history, employment_duration, foreign_worker, housing, job, other_debtors,\n    other_installment_plans, people_liable, personal_status_sex, property, purpose, savings, status,\n    telephone\n  - int (3): age, amount, duration\n  - ord (3): installment_rate, number_credits, present_residence\n```\n\n\n:::\n:::\n\n\nWe get a short summary of the task: It has 1000 observations and 21 columns of which 20 are features. 17 features are categorical (i.e., factors) and 3 features are integer.\n\nBy using the `$data()` method, we get access to the data (in the form of a `data.table`):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstr(task$data())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'data.table' and 'data.frame':\t1000 obs. of  21 variables:\n $ credit_risk            : Factor w/ 2 levels \"good\",\"bad\": 1 2 1 1 2 1 1 1 1 2 ...\n $ age                    : int  67 22 49 45 53 35 53 35 61 28 ...\n $ amount                 : int  1169 5951 2096 7882 4870 9055 2835 6948 3059 5234 ...\n $ credit_history         : Factor w/ 5 levels \"delay in paying off in the past\",..: 5 3 5 3 4 3 3 3 3 5 ...\n $ duration               : int  6 48 12 42 24 36 24 36 12 30 ...\n $ employment_duration    : Factor w/ 5 levels \"unemployed\",\"< 1 yr\",..: 5 3 4 4 3 3 5 3 4 1 ...\n $ foreign_worker         : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ housing                : Factor w/ 3 levels \"for free\",\"rent\",..: 2 2 2 3 3 3 2 1 2 2 ...\n $ installment_rate       : Ord.factor w/ 4 levels \">= 35\"<\"25 <= ... < 35\"<..: 4 2 2 2 3 2 3 2 2 4 ...\n $ job                    : Factor w/ 4 levels \"unemployed/unskilled - non-resident\",..: 3 3 2 3 3 2 3 4 2 4 ...\n $ number_credits         : Ord.factor w/ 4 levels \"1\"<\"2-3\"<\"4-5\"<..: 2 1 1 1 2 1 1 1 1 2 ...\n $ other_debtors          : Factor w/ 3 levels \"none\",\"co-applicant\",..: 1 1 1 3 1 1 1 1 1 1 ...\n $ other_installment_plans: Factor w/ 3 levels \"bank\",\"stores\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ people_liable          : Factor w/ 2 levels \"0 to 2\",\"3 or more\": 1 1 2 2 2 2 1 1 1 1 ...\n $ personal_status_sex    : Factor w/ 4 levels \"male : divorced/separated\",..: 3 2 3 3 3 3 3 3 1 4 ...\n $ present_residence      : Ord.factor w/ 4 levels \"< 1 yr\"<\"1 <= ... < 4 yrs\"<..: 4 2 3 4 4 4 4 2 4 2 ...\n $ property               : Factor w/ 4 levels \"unknown / no property\",..: 1 1 1 2 4 4 2 3 1 3 ...\n $ purpose                : Factor w/ 11 levels \"others\",\"car (new)\",..: 4 4 7 3 1 7 3 2 4 1 ...\n $ savings                : Factor w/ 5 levels \"unknown/no savings account\",..: 5 1 1 1 1 5 3 1 4 1 ...\n $ status                 : Factor w/ 4 levels \"no checking account\",..: 1 2 4 1 1 4 4 2 4 2 ...\n $ telephone              : Factor w/ 2 levels \"no\",\"yes (under customer name)\": 2 1 1 1 1 2 1 2 1 1 ...\n - attr(*, \".internal.selfref\")=<externalptr> \n```\n\n\n:::\n:::\n\n\nNote that a `mlr3` `Task` object comes with plenty of functionality in the form of fields, methods and active bindings, see `?Task`, e.g., to get a summary of all feature names, you can use:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask$feature_names\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"age\"                     \"amount\"                  \"credit_history\"          \"duration\"               \n [5] \"employment_duration\"     \"foreign_worker\"          \"housing\"                 \"installment_rate\"       \n [9] \"job\"                     \"number_credits\"          \"other_debtors\"           \"other_installment_plans\"\n[13] \"people_liable\"           \"personal_status_sex\"     \"present_residence\"       \"property\"               \n[17] \"purpose\"                 \"savings\"                 \"status\"                  \"telephone\"              \n```\n\n\n:::\n:::\n\n\nTo obtain information about the types of features of the task (similarly like in the data dictionary above), we can inspect the active binding fields of the task object (see, `?Task`):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask$feature_types\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <id>\n                         id    type\n                     <char>  <char>\n 1:                     age integer\n 2:                  amount integer\n 3:          credit_history  factor\n 4:                duration integer\n 5:     employment_duration  factor\n 6:          foreign_worker  factor\n 7:                 housing  factor\n 8:        installment_rate ordered\n 9:                     job  factor\n10:          number_credits ordered\n11:           other_debtors  factor\n12: other_installment_plans  factor\n13:           people_liable  factor\n14:     personal_status_sex  factor\n15:       present_residence ordered\n16:                property  factor\n17:                 purpose  factor\n18:                 savings  factor\n19:                  status  factor\n20:               telephone  factor\n                         id    type\n```\n\n\n:::\n:::\n\n\n</details>\n\n# 1 Preprocess a Task (with One-Hot Encoding)\n\nUse the one-hot encoding `PipeOp` to convert all categorical features from the `german_credit` task into a preprocessed task containing 0-1 indicator variables for each category level instead of categorical features.\n\n\n<details>\n  <summary>**Hint 1:**</summary>\n  \n  Load the `mlr3pipelines` package and get an overview of possible `PipeOp` that can be used for different preprocessing steps by printing `mlr_pipeops` or the first two columns of the corresponding table `as.data.table(mlr_pipeops)[,1:2]`. Look for a **factor encoding** and pass the corresponding `key` for factor encoding to the `po()` function (see also the help page `?PipeOpEncode`). Then, use the `$train()` method of the `PipeOp` object which expects a **list** containing the task to be converted as input and produces a **list** containing the converted task.\n\n</details>\n\n<details>\n  <summary>**Hint 2:**</summary>\n  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3pipelines)\n# Create a PipeOp object that applies one-hot encoding\npoe = po(...) \n# Apply a created PipeOp to e.g. preprocess an input\nencoded_task = poe$train(input = ...)$output\nstr(...$data())\n```\n:::\n\n\n</details>\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3pipelines)\npoe = po(\"encode\", method = \"one-hot\")\n# Use the $help() method to open a help page of any PipeOp object\n# poe$help()\nencoded_task = poe$train(input = list(task))$output\nstr(encoded_task$data())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'data.table' and 'data.frame':\t1000 obs. of  73 variables:\n $ credit_risk                                               : Factor w/ 2 levels \"good\",\"bad\": 1 2 1 1 2 1 1 1 1 2 ...\n $ age                                                       : int  67 22 49 45 53 35 53 35 61 28 ...\n $ amount                                                    : int  1169 5951 2096 7882 4870 9055 2835 6948 3059 5234 ...\n $ duration                                                  : int  6 48 12 42 24 36 24 36 12 30 ...\n $ credit_history.delay.in.paying.off.in.the.past            : num  0 0 0 0 0 0 0 0 0 0 ...\n $ credit_history.critical.account.other.credits.elsewhere   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ credit_history.no.credits.taken.all.credits.paid.back.duly: num  0 1 0 1 0 1 1 1 1 0 ...\n $ credit_history.existing.credits.paid.back.duly.till.now   : num  0 0 0 0 1 0 0 0 0 0 ...\n $ credit_history.all.credits.at.this.bank.paid.back.duly    : num  1 0 1 0 0 0 0 0 0 1 ...\n $ employment_duration.unemployed                            : num  0 0 0 0 0 0 0 0 0 1 ...\n $ employment_duration...1.yr                                : num  0 0 0 0 0 0 0 0 0 0 ...\n $ employment_duration.1..........4.yrs                      : num  0 1 0 0 1 1 0 1 0 0 ...\n $ employment_duration.4..........7.yrs                      : num  0 0 1 1 0 0 0 0 1 0 ...\n $ employment_duration....7.yrs                              : num  1 0 0 0 0 0 1 0 0 0 ...\n $ foreign_worker.no                                         : num  1 1 1 1 1 1 1 1 1 1 ...\n $ foreign_worker.yes                                        : num  0 0 0 0 0 0 0 0 0 0 ...\n $ housing.for.free                                          : num  0 0 0 0 0 0 0 1 0 0 ...\n $ housing.rent                                              : num  1 1 1 0 0 0 1 0 1 1 ...\n $ housing.own                                               : num  0 0 0 1 1 1 0 0 0 0 ...\n $ installment_rate....35                                    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ installment_rate.25..........35                           : num  0 1 1 1 0 1 0 1 1 0 ...\n $ installment_rate.20..........25                           : num  0 0 0 0 1 0 1 0 0 0 ...\n $ installment_rate...20                                     : num  1 0 0 0 0 0 0 0 0 1 ...\n $ job.unemployed.unskilled...non.resident                   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ job.unskilled...resident                                  : num  0 0 1 0 0 1 0 0 1 0 ...\n $ job.skilled.employee.official                             : num  1 1 0 1 1 0 1 0 0 0 ...\n $ job.manager.self.empl.highly.qualif..employee             : num  0 0 0 0 0 0 0 1 0 1 ...\n $ number_credits.1                                          : num  0 1 1 1 0 1 1 1 1 0 ...\n $ number_credits.2.3                                        : num  1 0 0 0 1 0 0 0 0 1 ...\n $ number_credits.4.5                                        : num  0 0 0 0 0 0 0 0 0 0 ...\n $ number_credits....6                                       : num  0 0 0 0 0 0 0 0 0 0 ...\n $ other_debtors.none                                        : num  1 1 1 0 1 1 1 1 1 1 ...\n $ other_debtors.co.applicant                                : num  0 0 0 0 0 0 0 0 0 0 ...\n $ other_debtors.guarantor                                   : num  0 0 0 1 0 0 0 0 0 0 ...\n $ other_installment_plans.bank                              : num  0 0 0 0 0 0 0 0 0 0 ...\n $ other_installment_plans.stores                            : num  0 0 0 0 0 0 0 0 0 0 ...\n $ other_installment_plans.none                              : num  1 1 1 1 1 1 1 1 1 1 ...\n $ people_liable.0.to.2                                      : num  1 1 0 0 0 0 1 1 1 1 ...\n $ people_liable.3.or.more                                   : num  0 0 1 1 1 1 0 0 0 0 ...\n $ personal_status_sex.male...divorced.separated             : num  0 0 0 0 0 0 0 0 1 0 ...\n $ personal_status_sex.female...non.single.or.male...single  : num  0 1 0 0 0 0 0 0 0 0 ...\n $ personal_status_sex.male...married.widowed                : num  1 0 1 1 1 1 1 1 0 0 ...\n $ personal_status_sex.female...single                       : num  0 0 0 0 0 0 0 0 0 1 ...\n $ present_residence...1.yr                                  : num  0 0 0 0 0 0 0 0 0 0 ...\n $ present_residence.1..........4.yrs                        : num  0 1 0 0 0 0 0 1 0 1 ...\n $ present_residence.4..........7.yrs                        : num  0 0 1 0 0 0 0 0 0 0 ...\n $ present_residence....7.yrs                                : num  1 0 0 1 1 1 1 0 1 0 ...\n $ property.unknown...no.property                            : num  1 1 1 0 0 0 0 0 1 0 ...\n $ property.car.or.other                                     : num  0 0 0 1 0 0 1 0 0 0 ...\n $ property.building.soc..savings.agr....life.insurance      : num  0 0 0 0 0 0 0 1 0 1 ...\n $ property.real.estate                                      : num  0 0 0 0 1 1 0 0 0 0 ...\n $ purpose.others                                            : num  0 0 0 0 1 0 0 0 0 1 ...\n $ purpose.car..new.                                         : num  0 0 0 0 0 0 0 1 0 0 ...\n $ purpose.car..used.                                        : num  0 0 0 1 0 0 1 0 0 0 ...\n $ purpose.furniture.equipment                               : num  1 1 0 0 0 0 0 0 1 0 ...\n $ purpose.radio.television                                  : num  0 0 0 0 0 0 0 0 0 0 ...\n $ purpose.domestic.appliances                               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ purpose.repairs                                           : num  0 0 1 0 0 1 0 0 0 0 ...\n $ purpose.education                                         : num  0 0 0 0 0 0 0 0 0 0 ...\n $ purpose.vacation                                          : num  0 0 0 0 0 0 0 0 0 0 ...\n $ purpose.retraining                                        : num  0 0 0 0 0 0 0 0 0 0 ...\n $ purpose.business                                          : num  0 0 0 0 0 0 0 0 0 0 ...\n $ savings.unknown.no.savings.account                        : num  0 1 1 1 1 0 0 1 0 1 ...\n $ savings.......100.DM                                      : num  0 0 0 0 0 0 0 0 0 0 ...\n $ savings.100..........500.DM                               : num  0 0 0 0 0 0 1 0 0 0 ...\n $ savings.500..........1000.DM                              : num  0 0 0 0 0 0 0 0 1 0 ...\n $ savings........1000.DM                                    : num  1 0 0 0 0 1 0 0 0 0 ...\n $ status.no.checking.account                                : num  1 0 0 1 1 0 0 0 0 0 ...\n $ status.......0.DM                                         : num  0 1 0 0 0 0 0 1 0 1 ...\n $ status.0.........200.DM                                   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ status........200.DM...salary.for.at.least.1.year         : num  0 0 1 0 0 1 1 0 1 0 ...\n $ telephone.no                                              : num  0 1 1 1 1 0 1 0 1 1 ...\n $ telephone.yes..under.customer.name.                       : num  1 0 0 0 0 1 0 1 0 0 ...\n - attr(*, \".internal.selfref\")=<externalptr> \n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\n\n# 2 Create a Simple ML Pipeline (with One-Hot Encoding)\n\nSome learners cannot handle categorical features such as the the `xgboost` learner (which gives an error message when applied to a task containing categorical features):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlrnxg = lrn(\"classif.xgboost\")\nlrnxg$train(task)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <TaskClassif:german_credit> has the following unsupported feature types: factor, ordered\n```\n\n\n:::\n\n```{.r .cell-code}\nlrnxg$predict(task)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: <TaskClassif:german_credit> has the following unsupported feature types: factor, ordered\n```\n\n\n:::\n:::\n\n\nCombine the `xgboost` learner with a preprocessing step that applies one-hot encoding to create a ML pipeline that first converts all categorical features to 0-1 indicator variables and then applies the `xgboost` learner.\nTrain the ML pipeline on the `german_credit` task and make predictions on the training data.\n\n<details>\n  <summary>**Hint 1:**</summary>\n  You can create a `Graph` that combines a `PipeOp` object with a learner object (or further `PipeOp` objects) by concatenating them using the `%>>%` operator. The `Graph` contains all information of a sequential ML pipeline.\n  Convert the `Graph` into a `GraphLearner` to be able to run the whole ML pipeline like a usual learner object with which we can train, predict, resample, and benchmark the `GraphLearner` as we have learned. See also the help page `?GraphLearner`.\n\n</details>\n\n<details>\n  <summary>**Hint 2:**</summary>\n  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlrnxg = lrn(\"classif.xgboost\")\npoe = po(...)\ngraph = ...\n\nglrn = as_learner(...) \n...$train(...)\n...$predict(...)\n```\n:::\n\n\n</details>\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlrnxg = lrn(\"classif.xgboost\")\npoe = po(\"encode\", method = \"one-hot\")\ngraph = poe %>>% lrnxg\n\nglrn = as_learner(graph) # Alternative: glrn = GraphLearner$new(graph) \nglrn$train(task)\nglrn$predict(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<PredictionClassif> for 1000 observations:\n row_ids truth response\n       1  good     good\n       2   bad      bad\n       3  good     good\n     ---   ---      ---\n     998  good     good\n     999   bad      bad\n    1000  good     good\n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\n\n# 3 Feature Transformation for Decision Trees\n\nThe structure of a decision tree is insensitive to monotonic transformations of the features (and scaling is a monotonic transformation). \nThis means that although the scaled features are different to non-scaled features, the decision tree will have the same structure (the values of the split points for numeric feature might be different as the numeric features will have a different scale, but the structure of the decision tree will stay the same).\n\n## 3.1 Preprocessing\nUse the `PipeOp` to scale all numeric features from the `german_credit` task and create a preprocessed task the scaled numeric features. Do this for standard scaling (i.e., normalization by centering and scaling) and for Yeo-Johnson transformation (i.e., a power transformation to make data more Gaussian-like). You can look up the corresponding keys by inspecting the table `as.data.table(mlr_pipeops)[,1:2]`. Create the preprocessed tasks `task_scaled` and `task_yeojohnson` and check the values of the numeric features. You may have to first install the `bestNormalize` package for the Yeo-Johnson transformation.\n\n<details>\n  <summary>**Hint:**</summary>\n  Proceed as in Exercise 1, but use `scale` and `yeojohnson` instead of `encode` as keys in the `po()` function. If installing the `bestNormalize` package does not work, you can also select a different scaling approach such as `scalemaxabs` or `scalerange`. Yeo-Johnson transformation is a generalization of the Box-Cox transformation that can be applied to both positive and negative values, while Box-Cox transformation is only applicable to non-negative values.\n</details>\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3pipelines)\npos = po(\"scale\")\npoyj = po(\"yeojohnson\")\n\ntask_scaled = pos$train(list(task))$output\ntask_yeojohnson = poyj$train(list(task))$output\n\nnumfeat = task$feature_types$id[task$feature_types$type == \"integer\"]\ntask_scaled$data(cols = numfeat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             age     amount   duration\n           <num>      <num>      <num>\n   1:  2.7650729 -0.7447588 -1.2358595\n   2: -1.1908081  0.9493418  2.2470700\n   3:  1.1827205 -0.4163541 -0.7382981\n   4:  0.8310866  1.6334296  1.7495086\n   5:  1.5343544  0.5663801  0.2568246\n  ---                                 \n 996: -0.3996319 -0.5438899 -0.7382981\n 997:  0.3915443  0.2075085  0.7543859\n 998:  0.2157274 -0.8740659 -0.7382981\n 999: -1.1028996 -0.5052749  1.9982893\n1000: -0.7512658  0.4622259  1.9982893\n```\n\n\n:::\n\n```{.r .cell-code}\ntask_yeojohnson$data(cols = numfeat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             age     amount   duration\n           <num>      <num>      <num>\n   1:  1.9653300 -0.9322346 -1.7965202\n   2: -1.6066782  1.1562267  1.7637040\n   3:  1.2108915 -0.1577534 -0.6941824\n   4:  0.9766181  1.4952627  1.5158469\n   5:  1.4152773  0.9106005  0.5006594\n  ---                                 \n 996: -0.2191578 -0.4045645 -0.6941824\n 997:  0.6299244  0.6208442  0.9006672\n 998:  0.4702861 -1.4440956 -0.6941824\n 999: -1.4092818 -0.3244830  1.6436559\n1000: -0.7417516  0.8336566  1.6436559\n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\n## 3.2 Visual Comparison\nCreate two ML pipelines, one that combines the `classif.rpart` learner with the standard scaling and another one that combines `classif.rpart` learner with the Yeo-Johnson scaling. Then use the `classif.rpart` learner and the two ML pipelines on the `german_credit` task to fit 3 different decision trees (one trained on the raw task and the other two trained on the scaled and Yeo-Johnson transformed task). Visualize the decision tree structure using the `rpart.plot` function from the `rpart.plot` package.\n\n\n<details>\n  <summary>**Hint:**</summary>\n  Proceed as in Exercise 2 to create two `GraphLearner`s, one with `po(\"scale\")` and the other one with `po(\"yeojohnson\")`. Then, train the `classif.rpart` learner and the two `GraphLearner`s on the `german_credit` task. Apply the `rpart.plot` function to the trained model objects to compare the structure of the decision trees.\n  Note: While for the `classif.rpart` learner, the model object is directly contained in the `$model` slot of the learner after training, the `$model` slot of the two `GraphLearners` is a list and you have to access the trained model via `$model$classif.rpart$model`.\n</details>\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\nThe solution shows that the decision tree structure is exactly the same (although the split points of the numeric features such as `amount` and `duration` are different due to the transformed features):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3pipelines)\nlibrary(mlr3learners)\nlibrary(xgboost)\nrp = lrn(\"classif.rpart\")\nrpscale = as_learner(pos %>>% rp)\nrpyeojohnson = as_learner(poyj %>>% rp)\n\nrp$train(task)\nrpscale$train(task)\nrpyeojohnson$train(task)\n\nlibrary(rpart.plot)\nrpart.plot(rp$model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nrpart.plot(rpscale$model$classif.rpart$model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-2.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nrpart.plot(rpyeojohnson$model$classif.rpart$model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-3.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Alternative solution using the transformed tasks:\nrp = lrn(\"classif.rpart\")\n\nlibrary(rpart.plot)\nrp$train(task)\nrpart.plot(rp$model)\n\nrp$train(task_scaled)\nrpart.plot(rp$model)\n\nrp$train(task_yeojohnson)\nrpart.plot(rp$model)\n```\n:::\n\n\n:::\n\n:::\n\n\n# 4 Benchmark k-NN and Decison Tree with Scaling and Yeo-Johnson Transformation\n\nIn the previous exercise we saw that scaling does not affect a decision tree structure.\nThat is scaling numeric features of a decision tree will not have any (strong) effect on the performance.\nHowever, for some learners, scaling numeric features is important, especially if they are based on computing distances such as the k-NN learner (because scaling will convert all numeric features into a comparable scale).\n\nIn this exercise we want to conduct a benchmark that illustrates these claims.\nConsider the k-NN learner without scaling `lrn(\"classif.kknn\", scale = FALSE)` and the decision tree `lrn(\"classif.rpart\")`.\nCombine these two learners once with `po(\"scale\")` (for normalization, i.e., subtracting the mean and dividing by the standard deviation) and once with `po(\"yeojohnson\")` for Yeo-Johnson transformation of the numeric features.\nThen, setup a benchmark to compare their performance (including the non-scaled k-NN `lrn(\"classif.kknn\", scale = FALSE)` and decision tree `lrn(\"classif.rpart\")`) using 10-fold cross-validation.\nIn total, you will benchmark 6 learners, the 4 ML pipelines and the 2 learners. \nFor reproducibility, use the seed `set.seed(2023)`.\n\n\n<details>\n  <summary>**Hint:**</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3pipelines)\n\nset.seed(2023)\nlrns = list(\n  lrn(\"classif.kknn\", scale = FALSE),\n  po(\"scale\") %>>% ...,\n  po(\"yeojohnson\") %>>% ..,\n  lrn(\"classif.rpart\"),\n  ... %>>% lrn(...),\n  ... %>>% ...\n)\n\ndesign = benchmark_grid(...)\nbmr = benchmark(...)\nbmr$aggregate()\nautoplot(bmr)\n```\n:::\n\n\n</details>\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3pipelines)\npos = po(\"scale\")\npoyj = po(\"yeojohnson\")\n\nset.seed(2023)\nlrns = list(\n  lrn(\"classif.kknn\", scale = FALSE),\n  pos %>>% lrn(\"classif.kknn\", scale = FALSE),\n  poyj %>>% lrn(\"classif.kknn\", scale = FALSE),\n  lrn(\"classif.rpart\"),\n  pos %>>% lrn(\"classif.rpart\"),\n  poyj %>>% lrn(\"classif.rpart\")\n)\n\ncv = rsmp(\"cv\", folds = 10)\ndesign = benchmark_grid(list(task), lrns, cv)\nbmr = benchmark(design)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [15:24:06.514] [mlr3] Running benchmark with 60 resampling iterations\nINFO  [15:24:07.244] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/10)\nINFO  [15:24:07.868] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/10)\nINFO  [15:24:08.560] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/10)\nINFO  [15:24:09.318] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 4/10)\nINFO  [15:24:10.101] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 5/10)\nINFO  [15:24:10.901] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 6/10)\nINFO  [15:24:11.723] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 7/10)\nINFO  [15:24:12.789] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 8/10)\nINFO  [15:24:13.143] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 9/10)\nINFO  [15:24:13.524] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 10/10)\nINFO  [15:24:14.113] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 1/10)\nINFO  [15:24:14.384] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 2/10)\nINFO  [15:24:14.662] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 3/10)\nINFO  [15:24:14.930] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 4/10)\nINFO  [15:24:15.249] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 5/10)\nINFO  [15:24:15.509] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 6/10)\nINFO  [15:24:15.626] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 7/10)\nINFO  [15:24:16.178] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 8/10)\nINFO  [15:24:16.433] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 9/10)\nINFO  [15:24:17.069] [mlr3] Applying learner 'scale.classif.kknn' on task 'german_credit' (iter 10/10)\nINFO  [15:24:17.290] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 1/10)\nINFO  [15:24:17.544] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 2/10)\nINFO  [15:24:17.858] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 3/10)\nINFO  [15:24:18.185] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 4/10)\nINFO  [15:24:18.656] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 5/10)\nINFO  [15:24:19.019] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 6/10)\nINFO  [15:24:19.666] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 7/10)\nINFO  [15:24:20.046] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 8/10)\nINFO  [15:24:20.455] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 9/10)\nINFO  [15:24:21.028] [mlr3] Applying learner 'yeojohnson.classif.kknn' on task 'german_credit' (iter 10/10)\nINFO  [15:24:21.372] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 1/10)\nINFO  [15:24:21.648] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 2/10)\nINFO  [15:24:22.231] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 3/10)\nINFO  [15:24:22.445] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 4/10)\nINFO  [15:24:22.720] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 5/10)\nINFO  [15:24:22.926] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 6/10)\nINFO  [15:24:23.141] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 7/10)\nINFO  [15:24:23.378] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 8/10)\nINFO  [15:24:23.615] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 9/10)\nINFO  [15:24:23.896] [mlr3] Applying learner 'classif.rpart' on task 'german_credit' (iter 10/10)\nINFO  [15:24:24.106] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 1/10)\nINFO  [15:24:24.330] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 2/10)\nINFO  [15:24:24.885] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 3/10)\nINFO  [15:24:25.149] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 4/10)\nINFO  [15:24:25.767] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 5/10)\nINFO  [15:24:25.995] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 6/10)\nINFO  [15:24:26.241] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 7/10)\nINFO  [15:24:26.493] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 8/10)\nINFO  [15:24:26.767] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 9/10)\nINFO  [15:24:27.076] [mlr3] Applying learner 'scale.classif.rpart' on task 'german_credit' (iter 10/10)\nINFO  [15:24:27.311] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 1/10)\nINFO  [15:24:27.548] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 2/10)\nINFO  [15:24:27.807] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 3/10)\nINFO  [15:24:28.051] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 4/10)\nINFO  [15:24:28.345] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 5/10)\nINFO  [15:24:28.577] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 6/10)\nINFO  [15:24:28.815] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 7/10)\nINFO  [15:24:29.062] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 8/10)\nINFO  [15:24:29.309] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 9/10)\nINFO  [15:24:29.606] [mlr3] Applying learner 'yeojohnson.classif.rpart' on task 'german_credit' (iter 10/10)\nINFO  [15:24:29.774] [mlr3] Finished benchmark\n```\n\n\n:::\n\n```{.r .cell-code}\nbmr$aggregate()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      nr       task_id               learner_id resampling_id iters classif.ce\n   <int>        <char>                   <char>        <char> <int>      <num>\n1:     1 german_credit             classif.kknn            cv    10      0.364\n2:     2 german_credit       scale.classif.kknn            cv    10      0.285\n3:     3 german_credit  yeojohnson.classif.kknn            cv    10      0.293\n4:     4 german_credit            classif.rpart            cv    10      0.260\n5:     5 german_credit      scale.classif.rpart            cv    10      0.260\n6:     6 german_credit yeojohnson.classif.rpart            cv    10      0.260\nHidden columns: resample_result\n```\n\n\n:::\n\n```{.r .cell-code}\nautoplot(bmr)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n\n:::\n\n\n# Summary\n\nWe learned how to apply preprocessing steps such as factor encoding, standard scaling, or Yeo-Johnson transformation directly on a task. Furthermore, we have also seen how to create a `GraphLearner` which applies a ML pipeline on a task that first does all preprocessing steps defined in the `Graph` and then trains a learner on the preprocessed task.\nWe also saw that scaling is important for the k-NN learner but not for a decision tree as neither the decision tree structure nor the performance of the decision tree changes.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}