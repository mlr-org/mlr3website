{
  "hash": "e7528b1177c1d8bfab5f07ee4df3317b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Deep dive into Bayesian Optimization\ncategories:\n  - Bayesian Optimization\n  - Hyperparameter Optimization\nauthor:\n  - name: Giuseppe Casalicchio\n  - name: Essential Data Science Training GmbH\n    url: https://www.essentialds.de\ndescription: |\n  Use Bayesian optimization (BO) using `bbotk` and `mlr3mbo` for general black box optimization problems, and more specifically, hyperparameter optimization (HPO).\ndate: \"\"\nparams:\n  showsolution: true\n  base64encode: true\nlisting: false\nsearch: false\nformat:\n  html:\n    filters:\n      - ../../b64_solution.lua\n---\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n```{=html}\n<script>\nconst correctHash = \"54b947c39cf237109b63d401e547398aef79e4bbd57b05a0bfe5f8064d0c1607\";   // value injected by knitr\n\n/* ---------- reusable helper ---------- */\nfunction b64DecodeUtf8(b64) {\n  // 1) atob  -> binary-string   (bytes 0…255)\n  // 2) map   -> Uint8Array      (array of bytes)\n  // 3) TextDecoder('utf-8')     -> real JS string\n  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n  return new TextDecoder('utf-8').decode(bytes);\n}\n\nasync function sha256(txt) {\n  const buf = await crypto.subtle.digest('SHA-256',\n                 new TextEncoder().encode(txt));\n  return Array.from(new Uint8Array(buf))\n              .map(b => b.toString(16).padStart(2, '0')).join('');\n}\n\nasync function unlockOne(btn) {\n  const pass = prompt(\"Password:\");\n  if (!pass) return;\n  if (await sha256(pass) !== correctHash) {\n    alert(\"Wrong password\"); return;\n  }\n\n  /* --- decode only the solution that belongs to THIS button --- */\n  const wrapper = btn.parentElement;             // .b64-wrapper\n  wrapper.querySelectorAll('.hidden-solution').forEach(div => {\n    div.innerHTML = b64DecodeUtf8(div.dataset.encoded);\n    div.classList.remove('hidden-solution');\n    div.style.display = 'block';\n  });\n\n  /* Remove the button so the user can’t click it again */\n  btn.remove();\n}\n</script>\n\n<noscript>\n<div style=\"border: 1px solid #ccc; padding: 1em; margin-top: 1em; background: #f9f9f9;\">\n    <strong>JavaScript is required to unlock solutions.</strong><br>\n    Please enable JavaScript and reload the page,<br>\n    or download the source files from\n    <a href=\"https://github.com/mlr-org/mlr3website/\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>\n    and run the code locally.\n  </div>\n</noscript>\n```\n\n\n\n\n\n# Goal\n\nAfter this exercise, you should be able to navigate the building blocks of Bayesian optimization (BO) using `bbotk` and `mlr3mbo` for general black box optimization problems, and more specifically, hyperparameter optimization (HPO).\n\n# Introduction\n\nThis section is a deep dive into Bayesian optimization (BO), also known as Model Based Optimization (MBO). BO is more complex than other tuning methods, so we will motivate theory and methodology first.\n\n**Black Box Optimization**\n\nIn hyperparameter optimization, learners are passed a hyperparameter configuration and evaluated on a given task via a resampling technique to estimate its generalization performance with the goal to find the optimal hyperparameter configuration. In general, this is a black box optimization problem, which considers the optimization of a function whose mathematical structure is unknown or unexploitable. The only thing we can observe is the generalization performance of the function given a hyperparameter configuration. As evaluating the performance of a learner can take a lot of time, HPO is an expensive black box optimization problem.\n\n**Bayesian Optimization**\n\nThere is many ways of doing black box optimization, grid and random search being examples for simple strategies. Bayesian optimization are a class of black box optimization algorithms that rely on a ‘surrogate model’ trained on observed hyperparameter evaluations to model the black box function. This surrogate model tries to capture the unknown function between hyperparameter configuations and estimated generalization performance using (the very low number of) observed function evaluations. During each iteration, BO algorithms employ an ‘acquisition function’ to determine the next candidate point for evaluation. This function measures the expected ‘utility’ of each point within the search space based on the prediction of the surrogate model. The algorithm then selects the candidate point with the best acquisition function value and evaluates the black box function at that point to then update the surrogate model. This iterative process continues until a termination criterion is met, such as reaching a pre-specified maximum number of evaluations or achieving a desired level of performance. BO is a powerful method that often results in good optimization performance, especially if the cost of the black box evaluation becomes expensive and the optimization budget is tight.\n\nIn the rest of this section, we will first provide an introduction to black box optimization with the bbotk package and then introduce the building blocks of BO algorithms and examine their interplay and interaction during the optimization process before we assemble these building blocks in a ready to use black box optimizer with `mlr3mbo`.\n\n# Prerequisites\n\nLet's load the packages required for this exercise:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(bbotk)\nlibrary(mlr3verse)\nlibrary(mlr3mbo)\nset.seed(123)\n```\n:::\n\n\n\nBefore we apply BO to hyperparamter optimization (HPO), we try to optimize the following simple sinusoidal function:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsinus_1D = function(xs) 2 * xs$x1 * sin(14 * xs$x1) * sin(xs$x2) * xs$x2\n```\n:::\n\n\n\n# 1 Building Blocks of BO\n\nBayesian optimization (BO) usually follows this process:\n\n1. Generate and evaluate an initial design\n2. Loop:\n\n    + 2.1. Fit a surrogate model on the archive of all observations made so far to model the unknown black box function.\n    + 2.2. Optimize an acquisition function to determine which points of the search space are promising candidate(s) that should be evaluated next.\n    + 2.3. Evaluate the next candidate(s) and update the archive of all observations made so far.\n    + 2.4. Check if a given termination criterion is met, if not go back to 2.1.\n\nThe acquisition function relies on the mean and standard deviation prediction of the surrogate model and requires no evaluation of the true black box function, making it comparably cheap to optimize. A good acquisition function will balance exploiting knowledge about regions where we observed that performance is good and the surrogate model has low uncertainty with exploring regions where it has not yet evaluated points and as a result the uncertainty of the surrogate model is high.\n\nBO is a highly modular algorithm: as long as the above structure is in place, then the surrogate models, acquisition functions, and acquisition function optimizers are all interchangeable to a certain extent. The design of `mlr3mbo` reflects this modularity, with the base class for `OptimizerMbo` holding all the key elements: the BO algorithm loop structure (`loop_function`), surrogate model (`Surrogate`), acquisition function (`AcqFunction`), and acquisition function optimizer (`AcqOptimizer`). Let's explore the interplay and interaction of these building blocks during optimization.\n\n## 1.1 Initial design\n\nThe initial set of points that is evaluated before a surrogate model can be fit is referred to as the initial design. `mlr3mbo` allows you to either construct this manually or let a `loop_function` do this for you. We will demonstrate the first method here.\n\nTo construct an initial design, we will use one of the four design generators available in `paradox`. Let's try grid search first, assuming an initial design of nine points on a domain of two numeric variables ranging from 0 to 1:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndomain = ps(x1 = p_dbl(0, 1), x2 = p_dbl(0, 1))\ngenerate_design_grid(domain, resolution = 3)$data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      x1    x2\n   <num> <num>\n1:   0.0   0.0\n2:   0.0   0.5\n3:   0.0   1.0\n4:   0.5   0.0\n5:   0.5   0.5\n6:   0.5   1.0\n7:   1.0   0.0\n8:   1.0   0.5\n9:   1.0   1.0\n```\n\n\n:::\n:::\n\n\n\nAs you can see, this is more or less a simple `data.table` that encodes the set of hyperparameter configurations we want to evaluate first, before any of the real BO magic starts.\n\n**Task: Construct a more refined initial design, using `paradox` to implement a Sobol design with 30 points, which has better coverage properties than grid or random search. If you are interested in why the Sobol design has favorable properties, you can take a look at the original paper by Niederreiter ([1988](https://doi.org/10.1016/0022-314X(88)90025-X)).**\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsobol_design = generate_design_sobol(domain, n = 30)$data\nhead(sobol_design)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          x1        x2\n       <num>     <num>\n1: 0.6209494 0.3531295\n2: 0.1209494 0.8531295\n3: 0.8709494 0.6031295\n4: 0.3709494 0.1031295\n5: 0.2459494 0.4781295\n6: 0.7459494 0.9781295\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n\n## 1.2 Generate data from initial design\n\nTo generate training data for our surrogate model, we need a few more things:\n\n- An `Objective` function that wraps the actual mapping from a domain (all possible function inputs) to a codomain (all possible function outputs). Objective functions can be created using different classes, all of which inherit from `Objective`. Here, we will use `ObjectiveRFun`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# We have already defined our domain, but will do here again:\ndomain = ps(x1 = p_dbl(0, 1), x2 = p_dbl(0, 1))\n# Our codomain:\ncodomain = ps(y = p_dbl(tags = \"minimize\"))\n# Our objective: \nobjective = ObjectiveRFun$new(sinus_1D, domain = domain, codomain = codomain)\n```\n:::\n\n\n\nFurther:\n\n- `OptimInstanceSingleCrit` to construct an optimization instance that describes the optimization problem and stores the results\n- `Optimizer` which is used to construct and configure optimization algorithms.\nOptimization Instance\n\nLet's define our optimization instance and evaluate it on our initial Sobol design:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance = OptimInstanceSingleCrit$new(objective,\n  terminator = trm(\"evals\", n_evals = 20))\ninstance$eval_batch(sobol_design)\n```\n:::\n\n\n**Task: Extract the training archive data from the tuning instance to find the data that we will now use to train our surrogate model with in the first iteration.**\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance$archive$data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            x1         x2             y  x_domain           timestamp batch_nr\n         <num>      <num>         <num>    <list>              <POSc>    <int>\n 1: 0.62094945 0.35312951  1.013097e-01 <list[2]> 2025-04-30 17:41:10        1\n 2: 0.12094945 0.85312951  1.543031e-01 <list[2]> 2025-04-30 17:41:10        1\n 3: 0.87094945 0.60312951 -2.172027e-01 <list[2]> 2025-04-30 17:41:10        1\n 4: 0.37094945 0.10312951 -6.983243e-03 <list[2]> 2025-04-30 17:41:10        1\n 5: 0.24594945 0.47812951 -3.215570e-02 <list[2]> 2025-04-30 17:41:10        1\n 6: 0.74594945 0.97812951 -1.030447e+00 <list[2]> 2025-04-30 17:41:10        1\n 7: 0.49594945 0.72812951  2.947207e-01 <list[2]> 2025-04-30 17:41:10        1\n 8: 0.99594945 0.22812951  1.008424e-01 <list[2]> 2025-04-30 17:41:10        1\n 9: 0.43344945 0.29062951 -1.539541e-02 <list[2]> 2025-04-30 17:41:10        1\n10: 0.93344945 0.79062951  5.047592e-01 <list[2]> 2025-04-30 17:41:10        1\n11: 0.18344945 0.54062951  5.537398e-02 <list[2]> 2025-04-30 17:41:10        1\n12: 0.68344945 0.04062951 -3.226290e-04 <list[2]> 2025-04-30 17:41:10        1\n13: 0.05844944 0.16562951  2.330285e-03 <list[2]> 2025-04-30 17:41:10        1\n14: 0.55844945 0.66562951  4.588228e-01 <list[2]> 2025-04-30 17:41:10        1\n15: 0.80844945 0.41562951 -2.573356e-01 <list[2]> 2025-04-30 17:41:10        1\n16: 0.30844945 0.91562951 -4.135623e-01 <list[2]> 2025-04-30 17:41:10        1\n17: 0.27719945 0.38437951 -5.383438e-02 <list[2]> 2025-04-30 17:41:10        1\n18: 0.77719945 0.88437951 -1.056347e+00 <list[2]> 2025-04-30 17:41:10        1\n19: 0.52719945 0.13437951  1.689707e-02 <list[2]> 2025-04-30 17:41:10        1\n20: 0.02719944 0.63437951  7.601496e-03 <list[2]> 2025-04-30 17:41:10        1\n21: 0.40219945 0.75937951 -2.553108e-01 <list[2]> 2025-04-30 17:41:10        1\n22: 0.90219945 0.25937951  7.727777e-03 <list[2]> 2025-04-30 17:41:10        1\n23: 0.65219945 0.50937951  9.388572e-02 <list[2]> 2025-04-30 17:41:10        1\n24: 0.15219945 0.00937951  2.268884e-05 <list[2]> 2025-04-30 17:41:10        1\n25: 0.33969945 0.57187951 -2.100820e-01 <list[2]> 2025-04-30 17:41:10        1\n26: 0.83969945 0.07187951 -6.282605e-03 <list[2]> 2025-04-30 17:41:10        1\n27: 0.08969945 0.32187951  1.736873e-02 <list[2]> 2025-04-30 17:41:10        1\n28: 0.58969945 0.82187951  6.534136e-01 <list[2]> 2025-04-30 17:41:10        1\n29: 0.46469945 0.19687951  7.902051e-03 <list[2]> 2025-04-30 17:41:10        1\n30: 0.96469945 0.69687951  6.966081e-01 <list[2]> 2025-04-30 17:41:10        1\n            x1         x2             y  x_domain           timestamp batch_nr\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n## 1.3 Train surrogate model\n\nA surrogate model wraps a regression learner that models the unknown black box function based on observed data. In `mlr3mbo`, the `SurrogateLearner` is a higher-level `R6` class inheriting from the base Surrogate class, designed to construct and manage the surrogate model, including automatic construction of the `TaskRegr` that the learner should be trained on at each iteration of the BO loop.\n\nAny regression learner in `mlr3` can be used. However, most acquisition functions depend on both mean and standard deviation predictions from the surrogate model, the latter of which requires the `\"se\"` `predict_type` to be supported. Therefore not all learners are suitable for all scenarios. Typical choices  are random forests or Gaussian processes `(lrn(\"regr.km\"))`, which we will use here. You can learn more about Gaussian processes in Williams and Rasmussen ([2006](https://gaussianprocess.org/gpml/chapters/RW.pdf)). \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn_gp = lrn(\"regr.km\", covtype = \"matern5_2\", optim.method = \"BFGS\",\n  control = list(trace = FALSE))\n```\n:::\n\n\n\nThe Matérn covariance function is a kernel used in Gaussian processes to model the smoothness of the random function, offering a flexible class of smoothness parameters. The BFGS algorithm is a type of quasi-Newton method used for optimization, particularly effective in maximizing the likelihood in Gaussian process models by efficiently finding parameter estimates.\n\nA `SurrogateLearner` can be constructed by passing a `LearnerRegr` object to the sugar function `srlrn()`, alongside the archive of the instance:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsurrogate = srlrn(lrn_gp, archive = instance$archive)\n```\n:::\n\n\n\nInternally, the regression learner is fit on a `TaskRegr` where features are the variables of the domain and the target is the codomain, the data is from the archive of the `OptimInstance` that is to be optimized.\n\n**Task: Update the surrogate model, which essentially fits the gaussian process. Then, inspect the trained random forest model that is contained within the surrogate:**\n\n<details>\n<summary>**Hint 1:**</summary>\n\nFitting the surrogate model will require calling one of the methods of `surrogate`. See `?surrogate` for help.\n\n</details>\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrequireNamespace(\"DiceKriging\")\nlibrary(DiceKriging)\n\nsurrogate$update()\nsurrogate$learner$model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nDiceKriging::km(design = data, response = truth, covtype = \"matern5_2\", \n    optim.method = \"BFGS\", control = pv$control)\n\nTrend  coeff.:\n               Estimate\n (Intercept)    -0.0103\n\nCovar. type  : matern5_2 \nCovar. coeff.:\n               Estimate\n   theta(x1)     0.1145\n   theta(x2)     0.6372\n\nVariance estimate: 0.1653614\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n\n## 1.4 Define an acquisition function\n\nRoughly speaking, an acquisition function relies on the prediction of a surrogate model and quantifies the perceived ‘utility’ of each point of the search space if it were to be evaluated in the next iteration.\n\nA popular example is the **expected improvement**, which tells us how much we can expect a candidate point to improve over the best function value observed so far (the ‘incumbent’), given the performance prediction of the surrogate model. Calculating the expected improvement requires mean and standard deviation predictions from the model.\n\nIn `mlr3mbo`, acquisition functions are stored in the `mlr_acqfunctions` dictionary and can be constructed with `acqf()`, passing the key of the method you want to use and our surrogate learner. In our running example, we will use the expected improvement to choose the next candidate for evaluation. \n\n**Task: Construct an aquisition function object using expected improvement. Then, update the aquisition function object.**\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrequireNamespace(\"DiceKriging\")\nlibrary(DiceKriging)\n\nacq_function = acqf(\"ei\", surrogate = surrogate)\nacq_function$update()\n```\n:::\n\n\n\nThe best y-value the acquisition function has seen so far:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nacq_function$y_best\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.056347\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n## 1.5 Optimize acquisition function\n\nWhy would we need to optimize the acquisition function? Well, the acquisition function can tell us how \"promising\" an arbitrary hyperparameter configuration is. If we want to find the \"most promising\" hyperparameter configuration, we again need to optimize the acquisition function. Consequently the optimization problem of the acquisition function is handled as a black box optimization problem itself, but it is a much cheaper one than the original.\n\nAn acquisition function optimizer of class `AcqOptimizer` is used to optimize the acquisition function by efficiently searching the space of potential candidates within a limited computational budget. Widely used approaches for optimizing acquisition functions include derivative-free global optimization methods, such as the DIRECT algorithm. Consequently the optimization problem of the acquisition function can be handled as a black box optimization problem itself, but a much cheaper one than the original.\n\n`AcqOptimizer` objects are constructed with `acqo()`, which takes as input an `Optimizer`, a Terminator, and the acquisition function. Optimizers are stored in the `mlr_optimizers` dictionary and can be constructed with the sugar function `opt()`. Let's select an optimizer first:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noptimizer = opt(\"nloptr\", algorithm = \"NLOPT_GN_ORIG_DIRECT\")\n```\n:::\n\n\n\n**Task: Construct an acquisition function optimizer using the optimizer above, a termination criterion of your choice and the acquisition function from the previous exercise. Then, call $optimize() on the optimizer to suggest the next candidate hyperparameter configuration.**\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nacq_optimizer = acqo(\n  optimizer = optimizer,\n  terminator = trm(\"evals\", n_evals = 200),\n  acq_function = acq_function\n)\n\ncandidate = acq_optimizer$optimize()\ncandidate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         x1        x2     acq_ei  x_domain .already_evaluated\n      <num>     <num>      <num>    <list>             <lgcl>\n1: 0.777854 0.9999238 0.07737823 <list[2]>              FALSE\n```\n\n\n:::\n:::\n\n\n\nThis is the next hyperparameter configuration we would want to evaluate. This restarts the loop: add it to the archive, train surrogate model, optimize the acquisition function with the new surrogate model, get the next candidate, etc. We would do this until some termination criterion is met.\n\n:::\n\n:::\n\n# 2  Automating BO with `OptimizerMbo`\n\nWe have now shown how to run a single iteration of the BO algorithm loop manually. In practice, one would use `OptimizerMbo` to put all these pieces together to automate the process. To determine the behavior of the BO algorithm on a global level, we need a **loop function**. We use the Efficient Global Optimization (EGO) algorithm, aka `bayesopt_ego` provided by `mlr_loop_functions`. You do not need to pass any of these building blocks to each other manually as the `opt()` constructor will do this for you:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nloop_function = mlr_loop_functions$get(\"bayesopt_ego\")\n\nsurrogate = srlrn(lrn(\"regr.km\",\n                      covtype = \"matern5_2\",\n                      optim.method = \"BFGS\",\n                      control = list(trace = FALSE)))\n\nacq_function = acqf(\"ei\")\n\nacq_optimizer = acqo(opt(\"nloptr\",\n                         algorithm = \"NLOPT_GN_ORIG_DIRECT\"),\n                         terminator = trm(\"evals\", n_evals = 100))\n\noptimizer = opt(\"mbo\",\n  loop_function = loop_function,\n  surrogate = surrogate,\n  acq_function = acq_function,\n  acq_optimizer = acq_optimizer)\n```\n:::\n\n\n\n**Task: Use the MBO optimizer constructed above to solve the optimization problem. To do so, define an optimization instance (as in 1.2) and an initial design (as in 1.1). Then, evaluate the optimization instance on the initial design (as in 1.2). Then, call `optimizer$optimize()` on the instance.**\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance = OptimInstanceSingleCrit$new(objective,\n  terminator = trm(\"evals\", n_evals = 100))\nsobol_design = generate_design_sobol(domain, n = 100)$data\ninstance$eval_batch(sobol_design)\noptimizer$optimize(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          x1        x2  x_domain          y\n       <num>     <num>    <list>      <num>\n1: 0.8061805 0.8231794 <list[2]> -0.9323896\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n\n# 3 BO for HPO with `TunerMbo`\n\n`mlr3mbo` can be used for HPO by making use of `TunerMbo`, which is a wrapper around `OptimizerMbo` and works in the exact same way. As an example, we want to tune the cost and gamma parameters of `lrn(\"classif.svm\")` with a radial kernel on `tsk(\"sonar\")` with three-fold CV. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn_svm = lrn(\"classif.svm\", kernel = \"radial\",\n  type = \"C-classification\",\n  cost  = to_tune(1e-5, 1e5, logscale = TRUE),\n  gamma = to_tune(1e-5, 1e5, logscale = TRUE)\n)\n\ntuner = tnr(\"mbo\",\n  loop_function = bayesopt_ego,\n  surrogate = surrogate,\n  acq_function = acq_function,\n  acq_optimizer = acq_optimizer)\n```\n:::\n\n\n\n**Task: Run the tuner on the lrn_svm for the sonar task and 3-fold CV. Use misclassification error as performance measure. What is the best HP configuration?**\n\n<details>\n<summary>**Hint 1:**</summary>\n\nSee `?mlr3tuning::tune` for help.\n\n</details>\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance = tune(tuner,\n                tsk(\"sonar\"),\n                lrn_svm,\n                rsmp(\"cv\", folds = 3),\n                msr(\"classif.ce\"), 25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:41:13.396] [mlr3] Running benchmark with 24 resampling iterations\nINFO  [17:41:13.519] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:13.628] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:13.729] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:13.829] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:13.929] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:14.045] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:14.148] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:14.250] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:14.351] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:14.451] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:14.482] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:14.525] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:14.567] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:14.608] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:14.650] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:14.691] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:14.734] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:14.774] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:14.835] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:14.877] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:14.888] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:14.930] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:14.971] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:15.012] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:15.028] [mlr3] Finished benchmark\nINFO  [17:41:16.007] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:16.038] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:16.066] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:16.094] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:16.103] [mlr3] Finished benchmark\nINFO  [17:41:17.117] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:17.148] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:17.193] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:17.239] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:17.246] [mlr3] Finished benchmark\nINFO  [17:41:18.293] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:18.324] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:18.352] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:18.381] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:18.387] [mlr3] Finished benchmark\nINFO  [17:41:19.474] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:19.512] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:19.563] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:19.604] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:19.612] [mlr3] Finished benchmark\nINFO  [17:41:20.732] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:20.763] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:20.792] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:20.820] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:20.828] [mlr3] Finished benchmark\nINFO  [17:41:22.025] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:22.055] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:22.083] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:22.111] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:22.118] [mlr3] Finished benchmark\nINFO  [17:41:23.018] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:23.048] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:23.076] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:23.107] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:23.116] [mlr3] Finished benchmark\nINFO  [17:41:24.074] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:24.113] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:24.141] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:24.170] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:24.177] [mlr3] Finished benchmark\nINFO  [17:41:25.124] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:25.173] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:25.202] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:25.230] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:25.237] [mlr3] Finished benchmark\nINFO  [17:41:26.221] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:26.252] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:26.281] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:26.309] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:26.316] [mlr3] Finished benchmark\nINFO  [17:41:27.291] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:27.322] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:27.351] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:27.379] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:27.386] [mlr3] Finished benchmark\nINFO  [17:41:28.410] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:28.441] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:28.469] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:28.497] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:28.505] [mlr3] Finished benchmark\nINFO  [17:41:29.530] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:29.561] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:29.590] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:29.618] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:29.628] [mlr3] Finished benchmark\nINFO  [17:41:30.701] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:30.733] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:30.762] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:30.791] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:30.798] [mlr3] Finished benchmark\nINFO  [17:41:31.839] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:31.871] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:31.901] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:31.930] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:31.936] [mlr3] Finished benchmark\nINFO  [17:41:33.038] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:33.070] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:33.098] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:33.127] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:33.134] [mlr3] Finished benchmark\nINFO  [17:41:34.325] [mlr3] Running benchmark with 3 resampling iterations\nINFO  [17:41:34.356] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 1/3)\nINFO  [17:41:34.385] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 2/3)\nINFO  [17:41:34.413] [mlr3] Applying learner 'classif.svm' on task 'sonar' (iter 3/3)\nINFO  [17:41:34.419] [mlr3] Finished benchmark\n```\n\n\n:::\n\n```{.r .cell-code}\ninstance$result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       cost     gamma learner_param_vals  x_domain classif.ce\n      <num>     <num>             <list>    <list>      <num>\n1: 3.838227 -3.839397          <list[4]> <list[2]>  0.1058661\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n# Summary\n\nWe have learned how Bayesian Optimization can be used to solve black box optimization problems, and HPO problems specifically. Rather than simply spending a compute budget on evaluating arbitrary configurations, we optimize an acquisition function based on a surrogate model that maps hyperparameter configurations to their estimated generalization performance, to iteratively suggest new candidates.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}