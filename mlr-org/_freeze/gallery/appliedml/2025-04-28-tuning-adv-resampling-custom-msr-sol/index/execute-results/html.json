{
  "hash": "010b06e11b19c1d49c413a420cf9ebaf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Advanced Resampling with Custom Measure Solution\ncategories:\n  - resampling\n  - startified resampling\n  - grouping\nauthor:\n  - name: Giuseppe Casalicchio\n  - name: Essential Data Science Training GmbH\n    url: https://www.essentialds.de\ndescription: |\n  Use stratified resampling to evaluate the german credit set and blocking for BreastCancer set. Define custom measures in mlr3 and use them to evaluate a model on the mtcars task.\ndate: \"\"\nparams:\n  showsolution: true\n  base64encode: true\nlisting: false\nsearch: false\nformat:\n  html:\n    filters:\n      - ../../b64_solution.lua\n---\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n```{=html}\n<script>\nconst correctHash = \"442d03f74a06c5dd5941642aaac91b31d024c3223824f3193c3dde9d5d62ee47\";   // value injected by knitr\n\n/* ---------- reusable helper ---------- */\nfunction b64DecodeUtf8(b64) {\n  // 1) atob  -> binary-string   (bytes 0…255)\n  // 2) map   -> Uint8Array      (array of bytes)\n  // 3) TextDecoder('utf-8')     -> real JS string\n  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n  return new TextDecoder('utf-8').decode(bytes);\n}\n\nasync function sha256(txt) {\n  const buf = await crypto.subtle.digest('SHA-256',\n                 new TextEncoder().encode(txt));\n  return Array.from(new Uint8Array(buf))\n              .map(b => b.toString(16).padStart(2, '0')).join('');\n}\n\nasync function unlockOne(btn) {\n  const pass = prompt(\"Password:\");\n  if (!pass) return;\n  if (await sha256(pass) !== correctHash) {\n    alert(\"Wrong password\"); return;\n  }\n\n  /* --- decode only the solution that belongs to THIS button --- */\n  const wrapper = btn.parentElement;             // .b64-wrapper\n  wrapper.querySelectorAll('.hidden-solution').forEach(div => {\n    div.innerHTML = b64DecodeUtf8(div.dataset.encoded);\n    div.classList.remove('hidden-solution');\n    div.style.display = 'block';\n  });\n\n  /* Remove the button so the user can’t click it again */\n  btn.remove();\n}\n</script>\n\n<noscript>\n<div style=\"border: 1px solid #ccc; padding: 1em; margin-top: 1em; background: #f9f9f9;\">\n    <strong>JavaScript is required to unlock solutions.</strong><br>\n    Please enable JavaScript and reload the page,<br>\n    or download the source files from\n    <a href=\"https://github.com/mlr-org/mlr3website/\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>\n    and run the code locally.\n  </div>\n</noscript>\n```\n\n\n\n\n# Goal\n\nAfter this exercise, you should be able to control the resampling process when using `mlr3` in order to account for data specificities, such as class imbalances in classification settings or grouping phenomena. Further, you will have learned how to construct and utilize custom measures for performance evaluation within `mlr3`.\n\n# Prerequisites\n\nWe load the most important packages and use a fixed seed for reproducibility.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlibrary(mlbench)\nlibrary(data.table)\nset.seed(7832)\n```\n:::\n\n\n# 1 Stratified Resampling\n\nIn classification tasks, the ratio of the target class distribution should be similar in each train/test split, which is achieved by stratification. This is particularly useful in the case of imbalanced classes and small data sets.\n\nStratification can also be performed with respect to explanatory categorical variables to ensure that all subgroups are represented in all training and test sets.\n\nIn `mlr3`, each `task` has a slot `$col_roles`.\nThis slot shows general roles certain features will have throughout different stages of the machine learning process.\nAt least, the `$col_roles` slot shows which variables will be used as `feature` and as `target`.\nHowever, the `$col_roles` slot can be more diverse and some variables might even serve multiple roles.\nFor example, `task$col_roles$stratum` specify the variable used for stratification.\nIn this exercise, we will illustrate this using the `german_credit` data:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask_gc = tsk(\"german_credit\")\ntask_gc$col_roles\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$feature\n [1] \"age\"                     \"amount\"                  \"credit_history\"          \"duration\"               \n [5] \"employment_duration\"     \"foreign_worker\"          \"housing\"                 \"installment_rate\"       \n [9] \"job\"                     \"number_credits\"          \"other_debtors\"           \"other_installment_plans\"\n[13] \"people_liable\"           \"personal_status_sex\"     \"present_residence\"       \"property\"               \n[17] \"purpose\"                 \"savings\"                 \"status\"                  \"telephone\"              \n\n$target\n[1] \"credit_risk\"\n\n$name\ncharacter(0)\n\n$order\ncharacter(0)\n\n$stratum\ncharacter(0)\n\n$group\ncharacter(0)\n\n$weight\ncharacter(0)\n\n$offset\ncharacter(0)\n\n$always_included\ncharacter(0)\n```\n\n\n:::\n:::\n\n\n## 1.1 Set stratification variable\n\nModify the `task_gc` object such that the target variable `credit_risk` is used to for stratification.\n\n<details>\n<summary>**Hint 1**</summary>\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask_gc$col_roles$... = \"credit_risk\"\n```\n:::\n\n</details>\n\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask_gc$col_roles$stratum = \"credit_risk\"\n```\n:::\n\n\nAfter the specification of `task$col_roles$stratum`, the active binding `task$strata` will show the number of observations in each group and the corresponding row ids:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask_gc$strata\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       N                row_id\n   <int>                <list>\n1:   700       1,3,4,6,7,8,...\n2:   300  2, 5,10,11,12,14,...\n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\n## 1.2 Create resampling procedure\n\nNext, specify a 3-fold cross validation and instantiate the resampling on the task.\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncv3 = rsmp(\"cv\", folds = 3)\ncv3$instantiate(task_gc)\ncv3$instance\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      row_id  fold\n       <int> <int>\n   1:      7     1\n   2:      8     1\n   3:      9     1\n   4:     17     1\n   5:     22     1\n  ---             \n 996:    959     3\n 997:    967     3\n 998:    980     3\n 999:    984     3\n1000:    999     3\n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\n## 1.3 Sanity check\n\nAs a sanity check, the target class distribution should be similar within each CV fold. Compute and check the target class distribution in form of a ratio within each fold.\n\n<details>\n<summary>**Hint 1**</summary>\nFirst, merge the data with the corresponding cv fold. Second, aggregate for each fold.\n</details>\n\n<details>\n<summary>**Hint 2**</summary>\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndt <- merge(cv3$..., transform(..., row_id = seq_len(...)), by = ...)\naggregate(..., data = ..., FUN = function(x) ...)\n```\n:::\n\n</details>\n\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\nWith `base R`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndt <- merge(cv3$instance, transform(task_gc$data(), row_id = seq_len(nrow(task_gc$data()))), by = \"row_id\")\naggregate(credit_risk ~ fold, data = dt, FUN = function(x) sum(x == \"bad\") / sum(x == \"good\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  fold credit_risk\n1    1   0.4273504\n2    2   0.4291845\n3    3   0.4291845\n```\n\n\n:::\n\n```{.r .cell-code}\nwith(dt, sum(credit_risk == \"bad\") / sum(credit_risk == \"good\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4285714\n```\n\n\n:::\n:::\n\n\nWith `data.table`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndt = merge(cv3$instance, task_gc$data()[, row_id := .I], by = \"row_id\")\ndt[, .(class_ratio = sum(credit_risk == \"bad\") /\n  sum(credit_risk == \"good\")), by = fold]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    fold class_ratio\n   <int>       <num>\n1:     2   0.4291845\n2:     3   0.4291845\n3:     1   0.4273504\n```\n\n\n:::\n:::\n\n\nIndeed, we can see that the target class is distributed similarly within each CV fold, matching the overall class distribution:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndt[, .(class_ratio = sum(credit_risk == \"bad\") / sum(credit_risk == \"good\"))]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   class_ratio\n         <num>\n1:   0.4285714\n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\n# 2 Block Resampling\n\nAn additional concern when specifying resampling is respecting the natural grouping of the data. Blocking refers to the situation where subsets of observations belong together and must not be separated during resampling. Hence, for one train/test set pair the entire block is either in the training set or in the test set.\n\nIn the following example, wel will consider the `BreastCancer` data set from the `mlbench` package:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(BreastCancer, package = \"mlbench\")\ntask_bc = as_task_classif(BreastCancer, target = \"Class\", positive = \"malignant\")\n```\n:::\n\n\nIn this data set, several observations have the same `Id` (sample code number), which implies these are samples taken from the same patient at different times.\n\n## 2.1 Count groups\n\nLet's count how many observation actually have the same `Id` more than once.\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsum(table(BreastCancer$Id) > 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 46\n```\n\n\n:::\n:::\n\n\nThere are 46 `Id`s with more than one observation (row).\n\n:::\n\n:::\n\nThe model trained on this data set will be used to predict cancer status of new patients. Hence, we have to make sure that each Id occurs exactly in one fold, so that all observations with the same Id should be either used for training or for evaluating the model. This way, we get less biased performance estimates via k-fold cross validation. This can be achieved by block cross validation.\n\n## 2.2 Set up block resampling\n\nSimilarly to stratified resampling, block resampling uses `task$col_roles$group` to specify the name of a grouping variable included in the feature set. Now, set the column `Id` as grouping variable in the `task` object. \n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask_bc$col_roles$group = \"Id\"\n```\n:::\n\n\n:::\n\n:::\n\n## 2.3 Instantiate resampling\n\nNext, set up a 5-fold CV and instantiate it on the task.\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncv5 = rsmp(\"cv\", folds = 5)\ncv5$instantiate(task_bc)\ncv5$instance\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <fold>\n      row_id  fold\n      <char> <int>\n  1: 1015425     1\n  2: 1041801     1\n  3: 1049815     1\n  4: 1059552     1\n  5: 1084584     1\n ---              \n641: 1371920     5\n642:  536708     5\n643:  566346     5\n644:  603148     5\n645:  888820     5\n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\n## 2.4 Sanity check\n\nIf the specified blocking groups are respected, each `Id` appears only in exactly one fold. To inspect if blocking was successful when generating the folds, count how often each `Id` appears in a specific fold and print the `Id`s that appear in more than one fold.\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\nWith `base R`:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndt <- aggregate(fold ~ Id,\n                 data = merge(task_bc$data(),\n                              cv5$instance,\n                              by.x = \"Id\",\n                              by.y = \"row_id\"),\n                 FUN = function(x) length(unique(x)))\ndt[dt$fold > 1,]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] Id   fold\n<0 Zeilen> (oder row.names mit Länge 0)\n```\n\n\n:::\n:::\n\n\nWith `data.table`:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndt = merge(task_bc$data(), cv5$instance, by.x = \"Id\", by.y = \"row_id\")\ndt = dt[, .(unique_folds = length(unique(fold))), by = Id]\ndt[unique_folds > 1, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <Id>\nEmpty data.table (0 rows and 2 cols): Id,unique_folds\n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\nAs expected, the table is empty as there are no Id’s present in more than one fold.\n\n# 3 Custom Performance Measures\n\nMany domain applications require custom measures for performance evaluations not supported in `mlr3`. You can inspect all available measures by calling `as.data.table(mlr_measures)`. Luckily, you can design your own measures for evaluating model performance. To do so, we simply create a new `R6` class that inherits either from `MeasureRegr` (for a regression measure) or `MeasureClassif` (for a classification measure). Let's see how this works in practice. Let us consider a regression measure that scores a prediction as 1 if the difference between the true and predicted values is less than one standard deviation of the truth, or scores the prediction as 0 otherwise. In maths this would be defined as $f(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}(|y_i - \\hat{y}_i| < \\sigma_y)$, where $\\sigma_y$ is the standard deviation of the truth and $\\mathbb{I}$ is the indicator function. In this case, we need the following code to construct a corresponding measure class:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nMeasureRegrThresholdAcc = R6::R6Class(\"MeasureRegrThresholdAcc\",\n  inherit = mlr3::MeasureRegr, # regression measure\n  public = list(\n    initialize = function() { # initialize class\n      super$initialize(\n        id = \"thresh_acc\", # unique ID\n        packages = character(), # no package dependencies\n        properties = character(), # no special properties\n        predict_type = \"response\", # measures response prediction\n        range = c(0, 1), # results in values between (0, 1)\n        minimize = FALSE # larger values are better\n      )\n    }\n  ),\n\n  private = list(\n    # define score as private method\n    .score = function(prediction, ...) {\n      # define loss\n      threshold_acc = function(truth, response) {\n        mean(ifelse(abs(truth - response) < sd(truth), 1, 0))\n      }\n      # call loss function\n      threshold_acc(prediction$truth, prediction$response)\n    }\n  )\n)\n```\n:::\n\n\n1. In the first two lines we name the class, here `MeasureRegrThresholdAcc`, and then state this is a regression measure that inherits from `MeasureRegr`.\n2. We initialize the class by stating its unique ID is `\"thresh_acc\"`, that it does not require any external packages (`packages = character()`) and that it has no special properties (`properties = character()`).\n3. We then pass specific details of the loss function which are: it measures the quality of a `\"response\"` type prediction, its values range between `(0, 1)`, and that the loss is optimized as its maximum (`minimize = FALSE`).\n4. Finally, we define the score itself as a private method called `.score` where we pass the predictions to the function we defined just above. The private method is a function assigned to the R6 class `MeasureRegrThresholdAcc`, such that one can (internally) call `object$.score(prediction,...)` for an object of class `MeasureRegrThresholdAcc`. The method is \"private\" as it is not intended to be visible for the end user. \n\nOnce you have defined your custom measure, you can add it to the `mlr3measures` dictionary like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmlr3::mlr_measures$add(\"regr.thresh_acc\", MeasureRegrThresholdAcc)\n```\n:::\n\n\n## 3.1 MSE-MAE\n\nDefine you own risk measure for regression, the maximum of MSE and MAE: $f(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^n \\max((y_i - \\hat{y}_i)^2,|y_i - \\hat{y}_i|)$, using the code skeleton supplied above.\n\n<details>\n<summary>**Hint 1:**</summary>\n\nYou need to change the code chunk containing the `MeasureRegrThresholdAcc` class definition in at least 7 lines.\n\n</details>\n\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nMeasureRegrMaxMseMae = R6::R6Class(\"MeasureRegrMaxMseMae\",\n  inherit = mlr3::MeasureRegr, # regression measure\n  public = list(\n    initialize = function() { # initialize class\n      super$initialize(\n        id = \"max_mse_mae\", # unique ID\n        packages = character(), # no package dependencies\n        properties = character(), # no special properties\n        predict_type = \"response\", # measures response prediction\n        range = c(0, Inf), # results in values between (0, 1)\n        minimize = TRUE # smaller values are better\n      )\n    }\n  ),\n\n  private = list(\n    # define score as private method\n    .score = function(prediction, ...) {\n      # define loss\n      max_mse_mae = function(truth, response) {\n        mean(max((truth - response)^2, abs(truth - response)))\n      }\n      # call loss function\n      max_mse_mae(prediction$truth, prediction$response)\n    }\n  )\n)\n```\n:::\n\n\n:::\n\n:::\n\n## 3.2 Evaluate a custom measure\n\nAdd your custom measure to the `mlr3measures` dictionary and use it to evaluate the following model prediction:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntsk_mtcars = tsk(\"mtcars\")\nsplit = partition(tsk_mtcars)\nlrn_ranger = lrn(\"regr.ranger\")$train(tsk_mtcars, split$train)\nprediction = lrn_ranger$predict(tsk_mtcars, split$test)\n```\n:::\n\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmlr3::mlr_measures$add(\"regr.max_mse_mae\", MeasureRegrMaxMseMae)\nprediction$score(msr(\"regr.max_mse_mae\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmax_mse_mae \n   29.54115 \n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\n# Summary\n\n- Stratified resampling helps with balancing classes and features within CV folds, to ensure each fold represents the data well enough.\n- Block resampling reduces bias in generalization error estimates by ensuring that observations from the same group end up in the same fold.\n- Custom domain applications require custom performance measures. In `mlr3`, you can define custom measures by creating a new `R6` class.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}