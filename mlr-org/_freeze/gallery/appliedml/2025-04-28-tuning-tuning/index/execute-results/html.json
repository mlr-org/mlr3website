{
  "hash": "3808e62c9ca27ce609a8a6eb5490f714",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Tuning\ncategories:\n  - tuning\nauthor:\n  - name: Giuseppe Casalicchio\n  - name: Essential Data Science Training GmbH\n    url: https://www.essentialds.de\ndescription: |\n  Optimize hyperparameters for k-NN and SVM classifier on german credit set.\ndate: \"\"\nparams:\n  showsolution: true\n  base64encode: true\nlisting: false\nsearch: false\nformat:\n  html:\n    filters:\n      - ../../b64_solution.lua\n---\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n```{=html}\n<script>\nconst correctHash = \"2abeefba61df06775a5fe67fb63b040694676feb8acb711382b1ae172b9f94eb\";   // value injected by knitr\n\n/* ---------- reusable helper ---------- */\nfunction b64DecodeUtf8(b64) {\n  // 1) atob  -> binary-string   (bytes 0…255)\n  // 2) map   -> Uint8Array      (array of bytes)\n  // 3) TextDecoder('utf-8')     -> real JS string\n  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n  return new TextDecoder('utf-8').decode(bytes);\n}\n\nasync function sha256(txt) {\n  const buf = await crypto.subtle.digest('SHA-256',\n                 new TextEncoder().encode(txt));\n  return Array.from(new Uint8Array(buf))\n              .map(b => b.toString(16).padStart(2, '0')).join('');\n}\n\nasync function unlockOne(btn) {\n  const pass = prompt(\"Password:\");\n  if (!pass) return;\n  if (await sha256(pass) !== correctHash) {\n    alert(\"Wrong password\"); return;\n  }\n\n  /* --- decode only the solution that belongs to THIS button --- */\n  const wrapper = btn.parentElement;             // .b64-wrapper\n  wrapper.querySelectorAll('.hidden-solution').forEach(div => {\n    div.innerHTML = b64DecodeUtf8(div.dataset.encoded);\n    div.classList.remove('hidden-solution');\n    div.style.display = 'block';\n  });\n\n  /* Remove the button so the user can’t click it again */\n  btn.remove();\n}\n</script>\n\n<noscript>\n<div style=\"border: 1px solid #ccc; padding: 1em; margin-top: 1em; background: #f9f9f9;\">\n    <strong>JavaScript is required to unlock solutions.</strong><br>\n    Please enable JavaScript and reload the page,<br>\n    or download the source files from\n    <a href=\"https://github.com/mlr-org/mlr3website/\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>\n    and run the code locally.\n  </div>\n</noscript>\n```\n\n\n\n\n\n# Goal\n\nAfter this exercise, you should be able to define search spaces for learning algorithms and apply different hyperparameter (HP) optimization (HPO) techniques to search through the search space to find a well-performing hyperparameter configuration (HPC).\n\n# Exercises\n\nAgain, we are looking at the `german_credit` data set and corresponding task (you can quickly load the task with `tsk(\"german_credit\")`). We want to train a k-NN model but ask ourselves what the best choice of $k$ might be? Furthermore, we are not sure how to set other HPs of the learner, e.g., if we should scale the data or not. In this exercise, we conduct HPO for k-NN to automatically find a good HPC.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\ntask = tsk(\"german_credit\")\n```\n:::\n\n\n\n<details>\n  <summary>**Recap: k-NN**</summary>\n  k-NN is a machine learning method that predicts new data by averaging over the responses of the k nearest neighbors.\n</details>\n\n## Parameter spaces\n  \nDefine a meaningful search space for the HPs `k` and `scale`.\nYou can checkout the help page `lrn(\"classif.kknn\")$help()` for an overview of the k-NN learner.\n\n<details>\n  <summary>**Hint 1**</summary>\n  Each learner has a slot `param_set` that contains all HPs that can be used for the tuning. In this use case we tune a       learner with the key `\"classif.kknn\"`. The functions to define the search space are `ps` and `p_int`, `p_dbl`, `p_fct`, or   `p_lgl` for HPs in the search space.\n</details>\n  \n<details>\n  <summary>**Hint 2**</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3tuning)\n\nsearch_space = ps(\n  k = p_int(...),\n  scale = ...\n)\n```\n:::\n\n\n</details>\n  \n  \n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3tuning)\n\nsearch_space = ps(\n  k = p_int(1, 100),\n  scale = p_lgl()\n)\n```\n:::\n\n\n\n:::\n  \n:::\n\n\n## Hyperparameter optimization\n  \nNow, we want to tune the k-NN model with the search space from the previous exercise. As resampling strategy we use a 3 fold cross validation. The tuning strategy should be a random search. As termination criteria we choose 40 evaluations.\n\n<details>\n  <summary>**Hint 1**</summary>\n  The elements required for the tuning are:\n  \n  - Task: German credit\n  - Algorithm: k-NN algorithm from `lrn()`\n  - Resampling: 3-fold cross validation using `rsmp()`\n  - Terminator: 40 evaluations using `trm()`\n  - Search space: See previous exercise\n  - We use the default performance measure (`msr(\"classif.ce\")` for classification and `msr(\"classif.mse\")` for regression)\n  \n  The tuning instance is then defined by calling `ti()`. \n  The random search optimization algorithm is obtained from `tnr()` with the corresponding key as argument.\n  Furthermore, we allow parallel computations and set the batch size as well as the number of cores to four.\n</details>\n  \n<details>\n  <summary>**Hint 2**</summary>\n  \n  The optimization algorithm is obtained from `tnr()` with the corresponding key as argument. Furthermore we allow parallel   computations using four cores:\n  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3)\nlibrary(mlr3learners)\nlibrary(mlr3tuning)\n\nfuture::plan(\"multicore\", workers = 4L)\n\ntask = tsk(...)\nlrn_knn = lrn(...)\n\nsearch_space = ps(\n  k = p_int(1, 100),\n  scale = p_lgl()\n)\nresampling = rsmp(...)\n\nterminator = trm(..., ... = 40L)\n\ninstance = ti(\n  task = ...,\n  learner = ...,\n  resampling = ...,\n  terminator = ...,\n  search_space = ...\n)\n\noptimizer = tnr(...)\noptimizer$...(...)\n```\n:::\n\n\n\nFinally, the optimization is started by passing the tuning instance to the `$optimize()` method of the tuner.\n</details>\n  \n  \n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3)\nlibrary(mlr3learners)\nlibrary(mlr3tuning)\nlibrary(kknn)\n\nfuture::plan(\"multicore\", workers = 4L)\n\ntask = tsk(\"german_credit\")\nlrn_knn = lrn(\"classif.kknn\")\n\nsearch_space = ps(\n  k = p_int(1, 100),\n  scale = p_lgl()\n)\nresampling = rsmp(\"cv\", folds = 3L)\n\nterminator = trm(\"evals\", n_evals = 40L)\n\ninstance = ti(\n  task = task,\n  learner = lrn_knn,\n  resampling = resampling,\n  terminator = terminator,\n  search_space = search_space\n)\n\noptimizer = tnr(\"random_search\", batch_size = 4L)\n\noptimizer$optimize(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [08:37:05.480] [bbotk] Starting to optimize 2 parameter(s) with '<OptimizerBatchRandomSearch>' and '<TerminatorEvals> [n_evals=40, k=0]'\nINFO  [08:37:05.498] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:05.503] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:05.515] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.537] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:05.556] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:05.579] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.592] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:05.604] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:05.619] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.633] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:05.647] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:05.661] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.676] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:05.688] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:05.701] [mlr3] Finished benchmark\nINFO  [08:37:05.720] [bbotk] Result of batch 1:\nINFO  [08:37:05.722] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:05.722] [bbotk]  15  TRUE  0.2690145        0      0            0.053 194d7f18-d03b-427d-81b1-4871a7341fbf\nINFO  [08:37:05.722] [bbotk]  18 FALSE  0.3279927        0      0            0.030 ff9f5509-11e1-4356-8d38-d9ce324e90e0\nINFO  [08:37:05.722] [bbotk]  34 FALSE  0.3220106        0      0            0.032 dd397f22-7b1b-4950-8cb6-ab6cb60dc114\nINFO  [08:37:05.722] [bbotk]  19 FALSE  0.3279957        0      0            0.029 6e4fc6a9-d4a5-47d2-abc2-28497de394d3\nINFO  [08:37:05.725] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:05.727] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:05.729] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.742] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:05.752] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:05.762] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.787] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:05.810] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:05.836] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.851] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:05.867] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:05.885] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.906] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:05.928] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:05.948] [mlr3] Finished benchmark\nINFO  [08:37:05.969] [bbotk] Result of batch 2:\nINFO  [08:37:05.970] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:05.970] [bbotk]   2 FALSE  0.3789898        0      0            0.021 828e118e-7e36-48e5-86ca-2fbb7b4fdd19\nINFO  [08:37:05.970] [bbotk]  62  TRUE  0.2810355        0      0            0.062 b38d9b38-5706-42e5-931e-019221df8cf0\nINFO  [08:37:05.970] [bbotk]  47 FALSE  0.3150156        0      0            0.038 85b8ee55-6924-4143-8f93-2d4b9b278147\nINFO  [08:37:05.970] [bbotk]  36  TRUE  0.2680315        0      0            0.052 3912efd5-12f4-47d5-9950-ed2910931552\nINFO  [08:37:05.973] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:05.975] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:05.977] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:05.994] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.020] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.036] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.055] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.077] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.096] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.121] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.149] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.174] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.193] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.214] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.232] [mlr3] Finished benchmark\nINFO  [08:37:06.251] [bbotk] Result of batch 3:\nINFO  [08:37:06.252] [bbotk]    k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:06.252] [bbotk]    7  TRUE  0.2930086        0      0            0.049 50887057-53b6-434a-b24e-3da7018935be\nINFO  [08:37:06.252] [bbotk]   24  TRUE  0.2710285        0      0            0.050 c78f3a13-b69a-4695-b86f-516b84d1492c\nINFO  [08:37:06.252] [bbotk]  100  TRUE  0.2870325        0      0            0.067 7457bb02-5572-4627-a519-80d75583b3ee\nINFO  [08:37:06.252] [bbotk]   68 FALSE  0.3030156        0      0            0.048 eaa4d9b7-8b20-4b43-808e-27feebcaeb86\nINFO  [08:37:06.254] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:06.259] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:06.262] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.279] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.296] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.316] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.335] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.358] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.377] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.397] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.419] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.438] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.550] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.563] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.576] [mlr3] Finished benchmark\nINFO  [08:37:06.595] [bbotk] Result of batch 4:\nINFO  [08:37:06.595] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:06.595] [bbotk]   6  TRUE  0.2930086        0      0            0.045 f4124aa0-3f6a-4724-b4ef-23f375cf000d\nINFO  [08:37:06.595] [bbotk]  24  TRUE  0.2710285        0      0            0.050 1a988904-b489-4bb1-812d-edbd69943ba6\nINFO  [08:37:06.595] [bbotk]  24  TRUE  0.2710285        0      0            0.051 ea40f74b-a2d9-4820-82df-90ca797d1f56\nINFO  [08:37:06.595] [bbotk]  24 FALSE  0.3170176        0      0            0.126 de9203d5-6ebc-4dd0-99a2-829427bc0c3b\nINFO  [08:37:06.598] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:06.600] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:06.603] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.614] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.625] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.637] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.665] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.690] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.714] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.740] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.764] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.787] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.807] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.830] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.850] [mlr3] Finished benchmark\nINFO  [08:37:06.868] [bbotk] Result of batch 5:\nINFO  [08:37:06.869] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:06.869] [bbotk]   9 FALSE  0.3429927        0      0            0.025 d7fb035b-f8f5-4c4e-b7a8-899c62dc9b90\nINFO  [08:37:06.869] [bbotk]  95  TRUE  0.2860315        0      0            0.067 00d05971-e9af-4879-9083-9c1cf9c9e4dc\nINFO  [08:37:06.869] [bbotk]  73  TRUE  0.2800345        0      0            0.063 4bad2fbc-fd82-4578-a1b9-4f79a41c386a\nINFO  [08:37:06.869] [bbotk]  93 FALSE  0.3030156        0      0            0.052 94ddd018-e085-499a-8320-b7176d5e2eed\nINFO  [08:37:06.872] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:06.874] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:06.876] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.903] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.927] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.950] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:06.967] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:06.982] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:06.997] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.021] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.048] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.072] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.097] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.119] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.142] [mlr3] Finished benchmark\nINFO  [08:37:07.162] [bbotk] Result of batch 6:\nINFO  [08:37:07.163] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:07.163] [bbotk]  78  TRUE  0.2830375        0      0            0.064 1c7663c2-b733-412a-af72-a75110468a08\nINFO  [08:37:07.163] [bbotk]  34 FALSE  0.3220106        0      0            0.037 65e4a779-0084-4a2b-aab3-0827cc106014\nINFO  [08:37:07.163] [bbotk]  86  TRUE  0.2840325        0      0            0.063 4ad58e75-20fb-4b16-935e-24978829eb0b\nINFO  [08:37:07.163] [bbotk]  59  TRUE  0.2820335        0      0            0.060 6434dafc-a93d-43eb-809f-243644a56dae\nINFO  [08:37:07.166] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:07.168] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:07.170] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.190] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.212] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.231] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.246] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.263] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.278] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.305] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.329] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.355] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.375] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.401] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.421] [mlr3] Finished benchmark\nINFO  [08:37:07.440] [bbotk] Result of batch 7:\nINFO  [08:37:07.440] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:07.440] [bbotk]  93 FALSE  0.3030156        0      0            0.051 bc0fea7b-e390-4242-acef-9694b892f6bb\nINFO  [08:37:07.440] [bbotk]  44 FALSE  0.3130136        0      0            0.034 01217a5c-e673-488b-ac21-1fb5f8351450\nINFO  [08:37:07.440] [bbotk]  87  TRUE  0.2840325        0      0            0.068 303be45d-8ed5-425c-9bf4-15c47c4a4e37\nINFO  [08:37:07.440] [bbotk]  31  TRUE  0.2600295        0      0            0.055 8c9cc31e-3693-4486-a1fc-aa38c5c12a17\nINFO  [08:37:07.443] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:07.445] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:07.447] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.470] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.493] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.520] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.541] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.562] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.583] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.598] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.609] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.621] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.638] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.655] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.676] [mlr3] Finished benchmark\nINFO  [08:37:07.694] [bbotk] Result of batch 8:\nINFO  [08:37:07.695] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:07.695] [bbotk]  66  TRUE  0.2780325        0      0            0.061 6f813c04-dabc-4f7a-886a-6f37a052e156\nINFO  [08:37:07.695] [bbotk]  52  TRUE  0.2840295        0      0            0.053 9ee033ae-7f61-458e-a8a1-07c91bc93050\nINFO  [08:37:07.695] [bbotk]  15 FALSE  0.3279867        0      0            0.027 aad91229-9a39-4c6a-ae50-7fd3b520215c\nINFO  [08:37:07.695] [bbotk]  62 FALSE  0.3010196        0      0            0.046 cf59574e-2ae9-4962-a148-6f270b9bb477\nINFO  [08:37:07.697] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:07.699] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:07.701] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.717] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.732] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.751] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.770] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.790] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.812] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.829] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.846] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.863] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.884] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.902] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:07.921] [mlr3] Finished benchmark\nINFO  [08:37:07.942] [bbotk] Result of batch 9:\nINFO  [08:37:07.943] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:07.943] [bbotk]  51 FALSE  0.3100166        0      0            0.040 1528f3f1-b00a-43ef-8794-47da8b0d2f4a\nINFO  [08:37:07.943] [bbotk]  28  TRUE  0.2590285        0      0            0.050 7c4bdf00-533e-46c7-bff2-0a914854c4f3\nINFO  [08:37:07.943] [bbotk]  60 FALSE  0.3010196        0      0            0.042 0f6aa967-1452-440f-8f71-06efb9a4728f\nINFO  [08:37:07.943] [bbotk]  74 FALSE  0.3030156        0      0            0.049 70cb050f-4fa5-46ec-9510-21055fdaae27\nINFO  [08:37:07.945] [bbotk] Evaluating 4 configuration(s)\nINFO  [08:37:07.947] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [08:37:07.949] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:07.968] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:07.988] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:08.009] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:08.027] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:08.050] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:08.068] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:08.093] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:08.118] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:08.147] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [08:37:08.166] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [08:37:08.185] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [08:37:08.203] [mlr3] Finished benchmark\nINFO  [08:37:08.222] [bbotk] Result of batch 10:\nINFO  [08:37:08.223] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [08:37:08.223] [bbotk]  84 FALSE  0.3030156        0      0            0.047 d956ba30-738e-41c9-a459-dbe9325fb781\nINFO  [08:37:08.223] [bbotk]  12  TRUE  0.2780145        0      0            0.049 870165ae-bff5-47d1-868a-70545961d868\nINFO  [08:37:08.223] [bbotk]  96  TRUE  0.2860315        0      0            0.070 f80ae578-3fae-4470-95ac-71e42d8a05a5\nINFO  [08:37:08.223] [bbotk]  75 FALSE  0.3030156        0      0            0.045 b5394957-24b1-40f9-bb63-eda7c105a85b\nINFO  [08:37:08.230] [bbotk] Finished optimizing after 40 evaluation(s)\nINFO  [08:37:08.230] [bbotk] Result:\nINFO  [08:37:08.231] [bbotk]      k  scale learner_param_vals  x_domain classif.ce\nINFO  [08:37:08.231] [bbotk]  <int> <lgcl>             <list>    <list>      <num>\nINFO  [08:37:08.231] [bbotk]     28   TRUE          <list[2]> <list[2]>  0.2590285\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       k  scale learner_param_vals  x_domain classif.ce\n   <int> <lgcl>             <list>    <list>      <num>\n1:    28   TRUE          <list[2]> <list[2]>  0.2590285\n```\n\n\n:::\n\n```{.r .cell-code}\ninstance$result_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclassif.ce \n 0.2590285 \n```\n\n\n:::\n\n```{.r .cell-code}\ninstance$result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       k  scale learner_param_vals  x_domain classif.ce\n   <int> <lgcl>             <list>    <list>      <num>\n1:    28   TRUE          <list[2]> <list[2]>  0.2590285\n```\n\n\n:::\n:::\n\n\n\n__Syntactic sugar to define the HP space__\n\n`mlr3` provides syntactic sugar to shorten the process of search space definition. To do so, it is possible to directly specify the HP range in the learner construction:\n  \n<details>\n  <summary>**Click me**</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3learners)\nlibrary(kknn)\n\ntask = tsk(\"german_credit\")\n\nlrn_knn = lrn(\"classif.kknn\", k = to_tune(1, 100), scale = to_tune())\n```\n:::\n\n\n\nThis adjust the parameter set (`lrn_knn$param_set`) attached to the learner and flags it as \"tunable\". \n</details>\n  \n:::\n  \n:::\n\n\n## Analyzing the tuning archive\n  \nInspect the archive of hyperparameters evaluated during the tuning process with `instance$archive`. Create a simple plot with the goal of illustrating the association between the hyperparametere `k` and the estimated classification error.\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(x = instance$archive$data$k, y = instance$archive$data$classif.ce)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n:::\n\n:::\n\n\n## Visualizing hyperparameters\n\nTo see how effective the tuning was, it is useful to look at the effect of the HPs on the performance. It also helps us to understand how important different HPs are. Therefore, access the archive of the tuning instance and visualize the effect.\n\n\n<details>\n  <summary>**Hint 1**</summary>\n  Access the `archive` of the tuning instance to get all information about the tuning. You can use all known plotting        techniques after transforming it to a `data.table`.\n</details>\n  \n<details>\n  <summary>**Hint 2**</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\narx = as...(instance$...)\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\ngg_k = ggplot(..., aes(...)) + ...()\ngg_scale = ggplot(..., aes(...)) + ...()\n\ngg_k + gg_scale & theme(legend.position = \"bottom\")\n```\n:::\n\n\n</details>\n  \n  \n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\narx = as.data.table(instance$archive)\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\ngg_k = ggplot(arx, aes(x = k, y = classif.ce)) + geom_point()\ngg_scale = ggplot(arx, aes(x = scale, y = classif.ce, fill = scale)) + geom_boxplot()\n\ngg_k + gg_scale & theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\n## ALTERNATIVE:\n\n# The `mlr3viz` automatically creates plots for getting an idea of the\n# effect of the HPs:\n\nlibrary(mlr3viz)\n\nautoplot(instance)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-2.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\nThe number of neighbours `k` and `scale` seem to have a big impact on the performance of the model. \n\n:::\n  \n:::\n\n## Hyperparameter dependencies\n  \nWhen defining a hyperparameter search space via the `ps()` function, we sometimes encounter nested search spaces, also called hyperparameter dependencies. One example for this are SVMs. Here, the hyperparameter `degree` is only relevant if the hyperparameter `kernel` is set to `\"polynomial\"`. Therefore, we only have to consider different configurations for `degree` if we evaluate candidate configurations with polynomial kernel. Construct a search space for a SVM with hyperparameters `kernel` (candidates should be `\"polynomial\"` and `\"radial\"`) and `degree` (integer ranging from 1 to 3, but only for polynomial kernels), and account for the dependency structure. \n\n<details>\n  <summary>**Hint 1**</summary>\n  In the `p_fct`, `p_dbl`, ... functions, we specify this using the `depends` argument, which takes a named argument of the   form `<param> == value` or `<param> %in% <vector>`.\n</details>\n  \n  \n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nps(\n  kernel = p_fct(c(\"polynomial\", \"radial\")),\n  degree = p_int(1, 3, depends = (kernel == \"polynomial\"))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ParamSet(2)>\nKey: <id>\n       id    class lower upper nlevels        default parents  value\n   <char>   <char> <num> <num>   <num>         <list>  <list> <list>\n1: degree ParamInt     1     3       3 <NoDefault[0]>  kernel [NULL]\n2: kernel ParamFct    NA    NA       2 <NoDefault[0]>  [NULL] [NULL]\n```\n\n\n:::\n:::\n\n\n\n:::\n  \n:::\n\n\n## Hyperparameter transformations\n  \nWhen tuning non-negative hyperparameters with a broad range, using a logarithmic scale can be more efficient. This approach works especially well if we want to test many small values, but also a few very large ones. By selecting values on a logarithmic scale and then exponentiating them, we ensure a concentrated exploration of smaller values while still considering the possibility of very large values, allowing for a targeted and efficient search in finding optimal hyperparameter configurations.\n\nA simple way to do this is to pass `logscale = TRUE` when using `to_tune()` to define the parameter search space while constructing the learner:\n  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn = lrn(\"classif.svm\", cost = to_tune(1e-5, 1e5, logscale = TRUE))\nlrn$param_set$search_space()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ParamSet(1)>\n       id    class     lower    upper nlevels        default  value\n   <char>   <char>     <num>    <num>   <num>         <list> <list>\n1:   cost ParamDbl -11.51293 11.51293     Inf <NoDefault[0]> [NULL]\nTrafo is set.\n```\n\n\n:::\n:::\n\n\n\nTo manually create the same transformation, we can pass the transformation to the more general `trafo` argument in `p_dbl()` and related functions and set the bounds using the `log()` function. For the following search space, implement a logarithmic transformation. the output should look exactly as the search space above.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Change this to a log trafo:\nps(cost = p_dbl(1e-5, 1e5))\n```\n:::\n\n\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsearch_space = ps(cost = p_dbl(log(1e-5), log(1e5),\n                               trafo = function(x) exp(x))) # alternatively: 'trafo = exp'\nsearch_space\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ParamSet(1)>\n       id    class     lower    upper nlevels        default  value\n   <char>   <char>     <num>    <num>   <num>         <list> <list>\n1:   cost ParamDbl -11.51293 11.51293     Inf <NoDefault[0]> [NULL]\nTrafo is set.\n```\n\n\n:::\n:::\n\n\n\n:::\n  \n:::\n\n\n# Summary\n  \n- In this use-case we learned how to define search spaces for learner HPs.\n- Based on this search space, we defined a tuning strategy to try a number of random configurations.\n- We visualized the tested configurations to get an idea how the HP effect the performance of our learner.\n- We learned about scale transformations in tuning.\n- Finally we added a transformation to favor a certain range in the parameter space.\n\n# Further information\n\nOther (more advanced) tuning algorithms:\n  \n- `Simuated annealing`: Random HPC are sampled and accepted based on an acceptance probability function which states how likely an improvement in performance is. The method is implemented in `tnr(\"gensa\")`.\n- `Model-based optimization (MBO)`: Guess the most promising HPC by estimating the expected improvement of new points. Available in [`mlr3mbo`](https://mlr3mbo.mlr-org.com/).\n- `Multifidelity optimization/Successive halving algorithm`: This technique starts with multiple HPC and throws away unpromising candidates. This is repeated several times to efficiently use the tuning budget. The method is implemented in [`mlr3hyperband`](https://mlr3hyperband.mlr-org.com/).\n\n  ",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}