{
  "hash": "3808e62c9ca27ce609a8a6eb5490f714",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Tuning\ncategories:\n  - tuning\nauthor:\n  - name: Giuseppe Casalicchio\n  - name: Essential Data Science Training GmbH\n    url: https://www.essentialds.de\ndescription: |\n  Optimize hyperparameters for k-NN and SVM classifier on german credit set.\ndate: \"\"\nparams:\n  showsolution: true\n  base64encode: true\nlisting: false\nsearch: false\nformat:\n  html:\n    filters:\n      - ../../b64_solution.lua\n---\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n```{=html}\n<script>\nconst correctHash = \"2abeefba61df06775a5fe67fb63b040694676feb8acb711382b1ae172b9f94eb\";   // value injected by knitr\n\n/* ---------- reusable helper ---------- */\nfunction b64DecodeUtf8(b64) {\n  // 1) atob  -> binary-string   (bytes 0…255)\n  // 2) map   -> Uint8Array      (array of bytes)\n  // 3) TextDecoder('utf-8')     -> real JS string\n  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n  return new TextDecoder('utf-8').decode(bytes);\n}\n\nasync function sha256(txt) {\n  const buf = await crypto.subtle.digest('SHA-256',\n                 new TextEncoder().encode(txt));\n  return Array.from(new Uint8Array(buf))\n              .map(b => b.toString(16).padStart(2, '0')).join('');\n}\n\nasync function unlockOne(btn) {\n  const pass = prompt(\"Password:\");\n  if (!pass) return;\n  if (await sha256(pass) !== correctHash) {\n    alert(\"Wrong password\"); return;\n  }\n\n  /* --- decode only the solution that belongs to THIS button --- */\n  const wrapper = btn.parentElement;             // .b64-wrapper\n  wrapper.querySelectorAll('.hidden-solution').forEach(div => {\n    div.innerHTML = b64DecodeUtf8(div.dataset.encoded);\n    div.classList.remove('hidden-solution');\n    div.style.display = 'block';\n  });\n\n  /* Remove the button so the user can’t click it again */\n  btn.remove();\n}\n</script>\n\n<noscript>\n<div style=\"border: 1px solid #ccc; padding: 1em; margin-top: 1em; background: #f9f9f9;\">\n    <strong>JavaScript is required to unlock solutions.</strong><br>\n    Please enable JavaScript and reload the page,<br>\n    or download the source files from\n    <a href=\"https://github.com/mlr-org/mlr3website/\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>\n    and run the code locally.\n  </div>\n</noscript>\n```\n\n\n\n\n\n# Goal\n\nAfter this exercise, you should be able to define search spaces for learning algorithms and apply different hyperparameter (HP) optimization (HPO) techniques to search through the search space to find a well-performing hyperparameter configuration (HPC).\n\n# Exercises\n\nAgain, we are looking at the `german_credit` data set and corresponding task (you can quickly load the task with `tsk(\"german_credit\")`). We want to train a k-NN model but ask ourselves what the best choice of $k$ might be? Furthermore, we are not sure how to set other HPs of the learner, e.g., if we should scale the data or not. In this exercise, we conduct HPO for k-NN to automatically find a good HPC.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\ntask = tsk(\"german_credit\")\n```\n:::\n\n\n\n<details>\n  <summary>**Recap: k-NN**</summary>\n  k-NN is a machine learning method that predicts new data by averaging over the responses of the k nearest neighbors.\n</details>\n\n## Parameter spaces\n  \nDefine a meaningful search space for the HPs `k` and `scale`.\nYou can checkout the help page `lrn(\"classif.kknn\")$help()` for an overview of the k-NN learner.\n\n<details>\n  <summary>**Hint 1**</summary>\n  Each learner has a slot `param_set` that contains all HPs that can be used for the tuning. In this use case we tune a       learner with the key `\"classif.kknn\"`. The functions to define the search space are `ps` and `p_int`, `p_dbl`, `p_fct`, or   `p_lgl` for HPs in the search space.\n</details>\n  \n<details>\n  <summary>**Hint 2**</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3tuning)\n\nsearch_space = ps(\n  k = p_int(...),\n  scale = ...\n)\n```\n:::\n\n\n</details>\n  \n  \n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3tuning)\n\nsearch_space = ps(\n  k = p_int(1, 100),\n  scale = p_lgl()\n)\n```\n:::\n\n\n\n:::\n  \n:::\n\n\n## Hyperparameter optimization\n  \nNow, we want to tune the k-NN model with the search space from the previous exercise. As resampling strategy we use a 3 fold cross validation. The tuning strategy should be a random search. As termination criteria we choose 40 evaluations.\n\n<details>\n  <summary>**Hint 1**</summary>\n  The elements required for the tuning are:\n  \n  - Task: German credit\n  - Algorithm: k-NN algorithm from `lrn()`\n  - Resampling: 3-fold cross validation using `rsmp()`\n  - Terminator: 40 evaluations using `trm()`\n  - Search space: See previous exercise\n  - We use the default performance measure (`msr(\"classif.ce\")` for classification and `msr(\"classif.mse\")` for regression)\n  \n  The tuning instance is then defined by calling `ti()`. \n  The random search optimization algorithm is obtained from `tnr()` with the corresponding key as argument.\n  Furthermore, we allow parallel computations and set the batch size as well as the number of cores to four.\n</details>\n  \n<details>\n  <summary>**Hint 2**</summary>\n  \n  The optimization algorithm is obtained from `tnr()` with the corresponding key as argument. Furthermore we allow parallel   computations using four cores:\n  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3)\nlibrary(mlr3learners)\nlibrary(mlr3tuning)\n\nfuture::plan(\"multicore\", workers = 4L)\n\ntask = tsk(...)\nlrn_knn = lrn(...)\n\nsearch_space = ps(\n  k = p_int(1, 100),\n  scale = p_lgl()\n)\nresampling = rsmp(...)\n\nterminator = trm(..., ... = 40L)\n\ninstance = ti(\n  task = ...,\n  learner = ...,\n  resampling = ...,\n  terminator = ...,\n  search_space = ...\n)\n\noptimizer = tnr(...)\noptimizer$...(...)\n```\n:::\n\n\n\nFinally, the optimization is started by passing the tuning instance to the `$optimize()` method of the tuner.\n</details>\n  \n  \n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3)\nlibrary(mlr3learners)\nlibrary(mlr3tuning)\nlibrary(kknn)\n\nfuture::plan(\"multicore\", workers = 4L)\n\ntask = tsk(\"german_credit\")\nlrn_knn = lrn(\"classif.kknn\")\n\nsearch_space = ps(\n  k = p_int(1, 100),\n  scale = p_lgl()\n)\nresampling = rsmp(\"cv\", folds = 3L)\n\nterminator = trm(\"evals\", n_evals = 40L)\n\ninstance = ti(\n  task = task,\n  learner = lrn_knn,\n  resampling = resampling,\n  terminator = terminator,\n  search_space = search_space\n)\n\noptimizer = tnr(\"random_search\", batch_size = 4L)\n\noptimizer$optimize(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [11:54:42.279] [bbotk] Starting to optimize 2 parameter(s) with '<OptimizerBatchRandomSearch>' and '<TerminatorEvals> [n_evals=40, k=0]'\nINFO  [11:54:42.295] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:42.300] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:42.311] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.333] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.351] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.372] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.383] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.394] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.407] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.420] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.433] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.446] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.460] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.471] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.482] [mlr3] Finished benchmark\nINFO  [11:54:42.500] [bbotk] Result of batch 1:\nINFO  [11:54:42.501] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:42.501] [bbotk]  15  TRUE  0.2690145        0      0            0.049 62b573ab-9c78-4d58-a7a3-adce89be8697\nINFO  [11:54:42.501] [bbotk]  18 FALSE  0.3279927        0      0            0.026 893fbc67-73be-46ba-bb43-fe7bbe214d5f\nINFO  [11:54:42.501] [bbotk]  34 FALSE  0.3220106        0      0            0.028 748365fa-8a83-466f-b32f-4e3065b44d4d\nINFO  [11:54:42.501] [bbotk]  19 FALSE  0.3279957        0      0            0.026 ea2e07ca-9cd1-45e1-abcb-96ab2963e559\nINFO  [11:54:42.504] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:42.506] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:42.508] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.520] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.529] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.538] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.561] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.581] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.610] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.624] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.638] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.652] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.673] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.691] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.710] [mlr3] Finished benchmark\nINFO  [11:54:42.727] [bbotk] Result of batch 2:\nINFO  [11:54:42.730] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:42.730] [bbotk]   2 FALSE  0.3789898        0      0            0.021 f968a2b0-9bab-4a5c-a2f2-29c1135c4e38\nINFO  [11:54:42.730] [bbotk]  62  TRUE  0.2810355        0      0            0.063 5730eaca-99a6-4697-af85-5cbccf8e07f6\nINFO  [11:54:42.730] [bbotk]  47 FALSE  0.3150156        0      0            0.033 1f546795-64c9-4149-a4dc-438d2ca58902\nINFO  [11:54:42.730] [bbotk]  36  TRUE  0.2680315        0      0            0.048 a8a7b8a2-cd54-4637-a9d7-7710944a11f2\nINFO  [11:54:42.733] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:42.735] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:42.737] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.753] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.769] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.787] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.805] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.823] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.844] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.868] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.894] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.917] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:42.936] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:42.952] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:42.971] [mlr3] Finished benchmark\nINFO  [11:54:42.988] [bbotk] Result of batch 3:\nINFO  [11:54:42.989] [bbotk]    k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:42.989] [bbotk]    7  TRUE  0.2930086        0      0            0.040 a0973374-01da-419c-a114-74d972ef0e61\nINFO  [11:54:42.989] [bbotk]   24  TRUE  0.2710285        0      0            0.046 caa1c679-eb9b-4d9f-a872-eed558fcc995\nINFO  [11:54:42.989] [bbotk]  100  TRUE  0.2870325        0      0            0.063 a80dfd1a-21d4-43eb-8aa6-d23787820173\nINFO  [11:54:42.989] [bbotk]   68 FALSE  0.3030156        0      0            0.044 0cc309d9-45f9-4850-b107-75c0d9331dec\nINFO  [11:54:42.991] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:42.993] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:42.995] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.013] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.127] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.142] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.160] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.177] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.195] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.212] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.233] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.250] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.262] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.273] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.285] [mlr3] Finished benchmark\nINFO  [11:54:43.302] [bbotk] Result of batch 4:\nINFO  [11:54:43.303] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:43.303] [bbotk]   6  TRUE  0.2930086        0      0            0.139 49e7fc04-2c3a-4851-b9b6-43eacf2145ed\nINFO  [11:54:43.303] [bbotk]  24  TRUE  0.2710285        0      0            0.044 5c724395-e3b4-4b06-a87c-a47fb47e524e\nINFO  [11:54:43.303] [bbotk]  24  TRUE  0.2710285        0      0            0.046 b54d896e-8d4c-4ec6-91c4-784789ca5296\nINFO  [11:54:43.303] [bbotk]  24 FALSE  0.3170176        0      0            0.026 7e034041-a5fe-49d6-bf91-45e40145e282\nINFO  [11:54:43.305] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:43.307] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:43.309] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.322] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.332] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.342] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.365] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.391] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.414] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.437] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.459] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.485] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.504] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.522] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.541] [mlr3] Finished benchmark\nINFO  [11:54:43.561] [bbotk] Result of batch 5:\nINFO  [11:54:43.562] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:43.562] [bbotk]   9 FALSE  0.3429927        0      0            0.023 41c0303d-d2b5-4300-a138-4a9e76730265\nINFO  [11:54:43.562] [bbotk]  95  TRUE  0.2860315        0      0            0.061 f8b54fd7-2fa5-4b48-9a41-8f4fa577ec76\nINFO  [11:54:43.562] [bbotk]  73  TRUE  0.2800345        0      0            0.062 b6a13cb8-96d7-4992-838b-73dc70ab5067\nINFO  [11:54:43.562] [bbotk]  93 FALSE  0.3030156        0      0            0.045 b8017660-c2ca-4854-a390-c465f91433fd\nINFO  [11:54:43.564] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:43.566] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:43.568] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.590] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.613] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.635] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.651] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.664] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.677] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.700] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.723] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.748] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.770] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.791] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.811] [mlr3] Finished benchmark\nINFO  [11:54:43.832] [bbotk] Result of batch 6:\nINFO  [11:54:43.833] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:43.833] [bbotk]  78  TRUE  0.2830375        0      0            0.059 89a1a9b8-4172-4759-9db0-1c7fba856875\nINFO  [11:54:43.833] [bbotk]  34 FALSE  0.3220106        0      0            0.034 4d40982d-3a5e-41cb-af9a-aba30e8de17b\nINFO  [11:54:43.833] [bbotk]  86  TRUE  0.2840325        0      0            0.063 45023270-3f7f-4c69-ad31-37ea7dd17f0d\nINFO  [11:54:43.833] [bbotk]  59  TRUE  0.2820335        0      0            0.054 06f4004d-a686-4ee3-9455-244d6b5a0d86\nINFO  [11:54:43.835] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:43.837] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:43.839] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.857] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.876] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.894] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.910] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.924] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:43.937] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:43.960] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:43.985] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.007] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.025] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.044] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.065] [mlr3] Finished benchmark\nINFO  [11:54:44.082] [bbotk] Result of batch 7:\nINFO  [11:54:44.083] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:44.083] [bbotk]  93 FALSE  0.3030156        0      0            0.047 5662204d-69a1-4dfe-8cb9-6e362b481801\nINFO  [11:54:44.083] [bbotk]  44 FALSE  0.3130136        0      0            0.034 e0aaed6f-98ac-47b6-aacb-1608b229a878\nINFO  [11:54:44.083] [bbotk]  87  TRUE  0.2840325        0      0            0.061 7c33921d-5e7b-408f-b211-f69fa96eded1\nINFO  [11:54:44.083] [bbotk]  31  TRUE  0.2600295        0      0            0.050 4e263ee6-a9c1-4949-9812-2da4068afc5c\nINFO  [11:54:44.085] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:44.087] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:44.089] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.110] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.134] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.156] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.175] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.197] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.216] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.227] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.239] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.250] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.265] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.281] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.299] [mlr3] Finished benchmark\nINFO  [11:54:44.317] [bbotk] Result of batch 8:\nINFO  [11:54:44.317] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:44.317] [bbotk]  66  TRUE  0.2780325        0      0            0.058 37b1d50b-ceb1-4eb7-9690-9fc9de3cced5\nINFO  [11:54:44.317] [bbotk]  52  TRUE  0.2840295        0      0            0.051 00928db2-e06b-44d6-b44b-0dc02236ff07\nINFO  [11:54:44.317] [bbotk]  15 FALSE  0.3279867        0      0            0.026 670825c1-b091-4116-8945-9d8b897d5163\nINFO  [11:54:44.317] [bbotk]  62 FALSE  0.3010196        0      0            0.041 19e1deea-78c7-42fc-9bb4-6c031a283f25\nINFO  [11:54:44.320] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:44.322] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:44.324] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.341] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.355] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.376] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.394] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.413] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.431] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.448] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.467] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.483] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.501] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.518] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.535] [mlr3] Finished benchmark\nINFO  [11:54:44.556] [bbotk] Result of batch 9:\nINFO  [11:54:44.557] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:44.557] [bbotk]  51 FALSE  0.3100166        0      0            0.043 b30607ad-f080-446f-9d02-1aef21f0b947\nINFO  [11:54:44.557] [bbotk]  28  TRUE  0.2590285        0      0            0.046 2994b4d0-c232-4b4b-b3a7-086a62fc38a1\nINFO  [11:54:44.557] [bbotk]  60 FALSE  0.3010196        0      0            0.044 1a415bcb-424c-428f-b247-9e03d5902ada\nINFO  [11:54:44.557] [bbotk]  74 FALSE  0.3030156        0      0            0.043 bf584767-897d-45ca-aa07-7e8cbd4b742f\nINFO  [11:54:44.559] [bbotk] Evaluating 4 configuration(s)\nINFO  [11:54:44.561] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [11:54:44.563] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.581] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.599] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.617] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.637] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.654] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.671] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.694] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.721] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.745] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/3)\nINFO  [11:54:44.762] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/3)\nINFO  [11:54:44.784] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/3)\nINFO  [11:54:44.801] [mlr3] Finished benchmark\nINFO  [11:54:44.818] [bbotk] Result of batch 10:\nINFO  [11:54:44.819] [bbotk]   k scale classif.ce warnings errors runtime_learners                                uhash\nINFO  [11:54:44.819] [bbotk]  84 FALSE  0.3030156        0      0            0.047 8fa6308a-431d-4380-898b-4e7f90c4b62b\nINFO  [11:54:44.819] [bbotk]  12  TRUE  0.2780145        0      0            0.044 d08d1bdd-c99a-41e9-97fb-3f97ad8df94f\nINFO  [11:54:44.819] [bbotk]  96  TRUE  0.2860315        0      0            0.063 7421059d-6de5-4878-9f24-4458f947451d\nINFO  [11:54:44.819] [bbotk]  75 FALSE  0.3030156        0      0            0.048 932fd3f9-8201-4bb5-8a66-625978099042\nINFO  [11:54:44.825] [bbotk] Finished optimizing after 40 evaluation(s)\nINFO  [11:54:44.825] [bbotk] Result:\nINFO  [11:54:44.826] [bbotk]      k  scale learner_param_vals  x_domain classif.ce\nINFO  [11:54:44.826] [bbotk]  <int> <lgcl>             <list>    <list>      <num>\nINFO  [11:54:44.826] [bbotk]     28   TRUE          <list[2]> <list[2]>  0.2590285\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       k  scale learner_param_vals  x_domain classif.ce\n   <int> <lgcl>             <list>    <list>      <num>\n1:    28   TRUE          <list[2]> <list[2]>  0.2590285\n```\n\n\n:::\n\n```{.r .cell-code}\ninstance$result_y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclassif.ce \n 0.2590285 \n```\n\n\n:::\n\n```{.r .cell-code}\ninstance$result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       k  scale learner_param_vals  x_domain classif.ce\n   <int> <lgcl>             <list>    <list>      <num>\n1:    28   TRUE          <list[2]> <list[2]>  0.2590285\n```\n\n\n:::\n:::\n\n\n\n__Syntactic sugar to define the HP space__\n\n`mlr3` provides syntactic sugar to shorten the process of search space definition. To do so, it is possible to directly specify the HP range in the learner construction:\n  \n<details>\n  <summary>**Click me**</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3learners)\nlibrary(kknn)\n\ntask = tsk(\"german_credit\")\n\nlrn_knn = lrn(\"classif.kknn\", k = to_tune(1, 100), scale = to_tune())\n```\n:::\n\n\n\nThis adjust the parameter set (`lrn_knn$param_set`) attached to the learner and flags it as \"tunable\". \n</details>\n  \n:::\n  \n:::\n\n\n## Analyzing the tuning archive\n  \nInspect the archive of hyperparameters evaluated during the tuning process with `instance$archive`. Create a simple plot with the goal of illustrating the association between the hyperparametere `k` and the estimated classification error.\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(x = instance$archive$data$k, y = instance$archive$data$classif.ce)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n:::\n\n:::\n\n\n## Visualizing hyperparameters\n\nTo see how effective the tuning was, it is useful to look at the effect of the HPs on the performance. It also helps us to understand how important different HPs are. Therefore, access the archive of the tuning instance and visualize the effect.\n\n\n<details>\n  <summary>**Hint 1**</summary>\n  Access the `archive` of the tuning instance to get all information about the tuning. You can use all known plotting        techniques after transforming it to a `data.table`.\n</details>\n  \n<details>\n  <summary>**Hint 2**</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\narx = as...(instance$...)\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\ngg_k = ggplot(..., aes(...)) + ...()\ngg_scale = ggplot(..., aes(...)) + ...()\n\ngg_k + gg_scale & theme(legend.position = \"bottom\")\n```\n:::\n\n\n</details>\n  \n  \n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\narx = as.data.table(instance$archive)\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\ngg_k = ggplot(arx, aes(x = k, y = classif.ce)) + geom_point()\ngg_scale = ggplot(arx, aes(x = scale, y = classif.ce, fill = scale)) + geom_boxplot()\n\ngg_k + gg_scale & theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\n## ALTERNATIVE:\n\n# The `mlr3viz` automatically creates plots for getting an idea of the\n# effect of the HPs:\n\nlibrary(mlr3viz)\n\nautoplot(instance)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-2.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\nThe number of neighbours `k` and `scale` seem to have a big impact on the performance of the model. \n\n:::\n  \n:::\n\n## Hyperparameter dependencies\n  \nWhen defining a hyperparameter search space via the `ps()` function, we sometimes encounter nested search spaces, also called hyperparameter dependencies. One example for this are SVMs. Here, the hyperparameter `degree` is only relevant if the hyperparameter `kernel` is set to `\"polynomial\"`. Therefore, we only have to consider different configurations for `degree` if we evaluate candidate configurations with polynomial kernel. Construct a search space for a SVM with hyperparameters `kernel` (candidates should be `\"polynomial\"` and `\"radial\"`) and `degree` (integer ranging from 1 to 3, but only for polynomial kernels), and account for the dependency structure. \n\n<details>\n  <summary>**Hint 1**</summary>\n  In the `p_fct`, `p_dbl`, ... functions, we specify this using the `depends` argument, which takes a named argument of the   form `<param> == value` or `<param> %in% <vector>`.\n</details>\n  \n  \n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nps(\n  kernel = p_fct(c(\"polynomial\", \"radial\")),\n  degree = p_int(1, 3, depends = (kernel == \"polynomial\"))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ParamSet(2)>\nKey: <id>\n       id    class lower upper nlevels        default parents  value\n   <char>   <char> <num> <num>   <num>         <list>  <list> <list>\n1: degree ParamInt     1     3       3 <NoDefault[0]>  kernel [NULL]\n2: kernel ParamFct    NA    NA       2 <NoDefault[0]>  [NULL] [NULL]\n```\n\n\n:::\n:::\n\n\n\n:::\n  \n:::\n\n\n## Hyperparameter transformations\n  \nWhen tuning non-negative hyperparameters with a broad range, using a logarithmic scale can be more efficient. This approach works especially well if we want to test many small values, but also a few very large ones. By selecting values on a logarithmic scale and then exponentiating them, we ensure a concentrated exploration of smaller values while still considering the possibility of very large values, allowing for a targeted and efficient search in finding optimal hyperparameter configurations.\n\nA simple way to do this is to pass `logscale = TRUE` when using `to_tune()` to define the parameter search space while constructing the learner:\n  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn = lrn(\"classif.svm\", cost = to_tune(1e-5, 1e5, logscale = TRUE))\nlrn$param_set$search_space()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ParamSet(1)>\n       id    class     lower    upper nlevels        default  value\n   <char>   <char>     <num>    <num>   <num>         <list> <list>\n1:   cost ParamDbl -11.51293 11.51293     Inf <NoDefault[0]> [NULL]\nTrafo is set.\n```\n\n\n:::\n:::\n\n\n\nTo manually create the same transformation, we can pass the transformation to the more general `trafo` argument in `p_dbl()` and related functions and set the bounds using the `log()` function. For the following search space, implement a logarithmic transformation. the output should look exactly as the search space above.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Change this to a log trafo:\nps(cost = p_dbl(1e-5, 1e5))\n```\n:::\n\n\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsearch_space = ps(cost = p_dbl(log(1e-5), log(1e5),\n                               trafo = function(x) exp(x))) # alternatively: 'trafo = exp'\nsearch_space\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ParamSet(1)>\n       id    class     lower    upper nlevels        default  value\n   <char>   <char>     <num>    <num>   <num>         <list> <list>\n1:   cost ParamDbl -11.51293 11.51293     Inf <NoDefault[0]> [NULL]\nTrafo is set.\n```\n\n\n:::\n:::\n\n\n\n:::\n  \n:::\n\n\n# Summary\n  \n- In this use-case we learned how to define search spaces for learner HPs.\n- Based on this search space, we defined a tuning strategy to try a number of random configurations.\n- We visualized the tested configurations to get an idea how the HP effect the performance of our learner.\n- We learned about scale transformations in tuning.\n- Finally we added a transformation to favor a certain range in the parameter space.\n\n# Further information\n\nOther (more advanced) tuning algorithms:\n  \n- `Simuated annealing`: Random HPC are sampled and accepted based on an acceptance probability function which states how likely an improvement in performance is. The method is implemented in `tnr(\"gensa\")`.\n- `Model-based optimization (MBO)`: Guess the most promising HPC by estimating the expected improvement of new points. Available in [`mlr3mbo`](https://mlr3mbo.mlr-org.com/).\n- `Multifidelity optimization/Successive halving algorithm`: This technique starts with multiple HPC and throws away unpromising candidates. This is repeated several times to efficiently use the tuning budget. The method is implemented in [`mlr3hyperband`](https://mlr3hyperband.mlr-org.com/).\n\n  ",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}