{
  "hash": "f4902f6bb43458db210eb4bdba902523",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Resampling Solution\ngroup: Introduction\ncategories:\n  - resampling\nauthor:\n  - name: Giuseppe Casalicchio\n  - name: Essential Data Science Training GmbH\n    url: https://www.essentialds.de\ndescription: |\n  Use 5-fold cross validation to evaluate logistic regression and knn learner on german credit set.\ndate: 04-24-2025\nparams:\n  showsolution: true\n  base64encode: true\nlisting: false\nsearch: false\nformat:\n  html:\n    filters:\n      - ../../b64_solution.lua\n---\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n```{=html}\n<script>\nconst correctHash = \"85901eaba8fbc9f2c1672fdaa218ff42b45d5d74b30f6d3d1415bb805bae365b\";   // value injected by knitr\n\n/* ---------- reusable helper ---------- */\nfunction b64DecodeUtf8(b64) {\n  // 1) atob  -> binary-string   (bytes 0…255)\n  // 2) map   -> Uint8Array      (array of bytes)\n  // 3) TextDecoder('utf-8')     -> real JS string\n  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n  return new TextDecoder('utf-8').decode(bytes);\n}\n\nasync function sha256(txt) {\n  const buf = await crypto.subtle.digest('SHA-256',\n                 new TextEncoder().encode(txt));\n  return Array.from(new Uint8Array(buf))\n              .map(b => b.toString(16).padStart(2, '0')).join('');\n}\n\nasync function unlockOne(btn) {\n  const pass = prompt(\"Password:\");\n  if (!pass) return;\n  if (await sha256(pass) !== correctHash) {\n    alert(\"Wrong password\"); return;\n  }\n\n  /* --- decode only the solution that belongs to THIS button --- */\n  const wrapper = btn.parentElement;             // .b64-wrapper\n  wrapper.querySelectorAll('.hidden-solution').forEach(div => {\n    div.innerHTML = b64DecodeUtf8(div.dataset.encoded);\n    div.classList.remove('hidden-solution');\n    div.style.display = 'block';\n  });\n\n  /* Remove the button so the user can’t click it again */\n  btn.remove();\n}\n</script>\n\n<noscript>\n<div style=\"border: 1px solid #ccc; padding: 1em; margin-top: 1em; background: #f9f9f9;\">\n    <strong>JavaScript is required to unlock solutions.</strong><br>\n    Please enable JavaScript and reload the page,<br>\n    or download the source files from\n    <a href=\"https://github.com/mlr-org/mlr3website/\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>\n    and run the code locally.\n  </div>\n</noscript>\n```\n\n\n\n\n\n# Goal\n\nYou will learn how to estimate the model performance with `mlr3` using resampling techniques such as 5-fold cross-validation.\nAdditionally, you will compare k-NN model against a logistic regression model.\n\n# German Credit Data\n\nWe work with the German credit data.\nYou can either manually create the corresponding `mlr3` task as we did before or use a pre-defined task which is already included in the `mlr3` package (you can look at the output of `as.data.table(mlr_tasks)` to see which other pre-defined tasks that can be used to play around are included in the `mlr3` package).\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\ntask = tsk(\"german_credit\")\ntask \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<TaskClassif:german_credit> (1000 x 21): German Credit\n* Target: credit_risk\n* Properties: twoclass\n* Features (20):\n  - fct (14): credit_history, employment_duration, foreign_worker, housing, job, other_debtors,\n    other_installment_plans, people_liable, personal_status_sex, property, purpose, savings, status,\n    telephone\n  - int (3): age, amount, duration\n  - ord (3): installment_rate, number_credits, present_residence\n```\n\n\n:::\n\n```{.r .cell-code}\ntask$positive # (check the positive class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"good\"\n```\n\n\n:::\n:::\n\n\n\n# Exercise: Fairly evaluate the performance of two learners\n\nWe first create two `mlr3` learners, a logistic regression and a KNN learner. \nWe then compare their performance via resampling.\n\n## Create the learners\n\nCreate a logistic regression learner (store it as an R object called `log_reg`) and KNN learner with $k = 5$ (store it as an R object called `knn`).\n\n<details>\n  <summary>**Show Hint 1:**</summary>\n  Check `as.data.table(mlr_learners)` to find the appropriate learner.\n  </details>\n  \n<details>\n  <summary>**Show Hint 2:**</summary>\n  Make sure to have the `kknn` package installed.\n  </details>\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\" base64encode='true'}\n\n```{.r .cell-code}\nlog_reg = lrn(\"classif.log_reg\")\nknn = lrn(\"classif.kknn\", k = 5)\n```\n:::\n\n\n\n:::\n\n:::\n\n## Set up a resampling instance\n\nUse the `mlr3` to set up a resampling instance and store it as an R object called `cv5`. \nHere, we aim for 5-fold cross-validation.\nA table of possible resampling techniques implemented in `mlr3` can be shown by looking at `as.data.table(mlr_resamplings)`.\n\n<details>\n  <summary>**Show Hint 1:**</summary>\n  Look at the table returned by `as.data.table(mlr_resamplings)` and use the `rsmp` function to set up a 5-fold cross-validation instance. Store the result of the `rsmp` function in an R object called `cv5`.\n  </details>\n<details>\n  <summary>**Show Hint 2:**</summary>\n  `rsmp(\"cv\")` by default sets up a 10-fold cross-validation instance.\n  The number of folds can be set using an additional argument (see the `params` column from `as.data.table(mlr_resamplings)`).\n  </details>\n  \n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\" base64encode='true'}\n\n```{.r .cell-code}\ncv5 = rsmp(\"cv\", folds = 5)\ncv5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ResamplingCV>: Cross-Validation\n* Iterations: 5\n* Instantiated: FALSE\n* Parameters: folds=5\n```\n\n\n:::\n:::\n\n\n\nNote: `Instantiated: FALSE` means that we only created the resampling instance and did not apply the resampling technique to a task yet.\n\n:::\n\n:::\n\n## Run the resampling\n\nAfter having created a resampling instance, use it to apply the chosen resampling technique to both previously created learners.\n\n<details>\n  <summary>**Show Hint 1:**</summary>\n  You need to supply the task, the learner and the previously created resampling instance as arguments to the `resample` function. See `?resample` for further details and examples.\n  </details>\n<details>\n  <summary>**Show Hint 2:**</summary>\n  The key ingredients for `resample()` are a task (created by `tsk()`), a learner (created by `lrn()`) and a resampling strategy (created by `rsmp()`), e.g.,\n  \n  `resample(task = task, learner = log_reg, resampling = cv5)`\n\n  </details>\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\" base64encode='true'}\n\n```{.r .cell-code}\nres_log_reg = resample(task, log_reg, cv5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [09:02:44.500] [mlr3] Applying learner 'classif.log_reg' on task 'german_credit' (iter 1/5)\nINFO  [09:02:44.681] [mlr3] Applying learner 'classif.log_reg' on task 'german_credit' (iter 2/5)\nINFO  [09:02:44.863] [mlr3] Applying learner 'classif.log_reg' on task 'german_credit' (iter 3/5)\nINFO  [09:02:45.050] [mlr3] Applying learner 'classif.log_reg' on task 'german_credit' (iter 4/5)\nINFO  [09:02:45.240] [mlr3] Applying learner 'classif.log_reg' on task 'german_credit' (iter 5/5)\n```\n\n\n:::\n\n```{.r .cell-code}\nres_knn = resample(task, knn, cv5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [09:02:45.407] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 1/5)\nINFO  [09:02:45.483] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 2/5)\nINFO  [09:02:45.573] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 3/5)\nINFO  [09:02:45.668] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 4/5)\nINFO  [09:02:45.767] [mlr3] Applying learner 'classif.kknn' on task 'german_credit' (iter 5/5)\n```\n\n\n:::\n\n```{.r .cell-code}\nres_log_reg\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ResampleResult> with 5 resampling iterations\n       task_id      learner_id resampling_id iteration     prediction_test warnings errors\n german_credit classif.log_reg            cv         1 <PredictionClassif>        0      0\n german_credit classif.log_reg            cv         2 <PredictionClassif>        0      0\n german_credit classif.log_reg            cv         3 <PredictionClassif>        0      0\n german_credit classif.log_reg            cv         4 <PredictionClassif>        0      0\n german_credit classif.log_reg            cv         5 <PredictionClassif>        0      0\n```\n\n\n:::\n\n```{.r .cell-code}\nres_knn\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<ResampleResult> with 5 resampling iterations\n       task_id   learner_id resampling_id iteration     prediction_test warnings errors\n german_credit classif.kknn            cv         1 <PredictionClassif>        0      0\n german_credit classif.kknn            cv         2 <PredictionClassif>        0      0\n german_credit classif.kknn            cv         3 <PredictionClassif>        0      0\n german_credit classif.kknn            cv         4 <PredictionClassif>        0      0\n german_credit classif.kknn            cv         5 <PredictionClassif>        0      0\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n## Evaluation\n\nCompute the cross-validated classification accuracy of both models.\nWhich learner performed better?\n\n<details>\n  <summary>**Show Hint 1:**</summary>\nUse `msr(\"classif.acc\")` and the `aggregate` method of the resampling object.\n  </details>\n<details>\n  <summary>**Show Hint 2:**</summary>\n`res_knn$aggregate(msr(...))` to obtain the classification accuracy averaged across all folds.\n  </details>\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\" base64encode='true'}\n\n```{.r .cell-code}\nres_knn$aggregate(msr(\"classif.acc\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclassif.acc \n       0.72 \n```\n\n\n:::\n\n```{.r .cell-code}\nres_log_reg$aggregate(msr(\"classif.acc\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclassif.acc \n      0.747 \n```\n\n\n:::\n:::\n\n\n\nNote: Use e.g. `res_knn$score(msr(...))` to look at the results of each individual fold.\n \n:::\n\n:::\n\n# Summary\n\nWe can now apply different resampling methods to estimate the performance of different learners and fairly compare them.\nWe now have learnt how to obtain a better (in terms of variance) estimate of our model performance instead of doing a simple train and test split.\nThis enables us to fairly compare different learners.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}