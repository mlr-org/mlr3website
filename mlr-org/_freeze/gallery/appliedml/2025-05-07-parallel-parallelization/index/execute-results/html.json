{
  "hash": "5c933ef81654b2236335c01558a71127",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Parallelization\ncategories:\n  - benchmark\n  - parallelization\nauthor:\n  - name: Giuseppe Casalicchio\n  - name: Essential Data Science Training GmbH\n    url: https://www.essentialds.de\ndescription: |\n  Set up a large scale benchmark experiment with parallelization\ndate: \"\"\nparams:\n  showsolution: true\n  base64encode: true\nlisting: false\nsearch: false\nformat:\n  html:\n    filters:\n      - ../../b64_solution.lua\n---\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n```{=html}\n<script>\nconst correctHash = \"05810ead24a29ec518b5c89d17ea7da19a2d54fecc14f1abdfe93f21798ae89e\";   // value injected by knitr\n\n/* ---------- reusable helper ---------- */\nfunction b64DecodeUtf8(b64) {\n  // 1) atob  -> binary-string   (bytes 0…255)\n  // 2) map   -> Uint8Array      (array of bytes)\n  // 3) TextDecoder('utf-8')     -> real JS string\n  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n  return new TextDecoder('utf-8').decode(bytes);\n}\n\nasync function sha256(txt) {\n  const buf = await crypto.subtle.digest('SHA-256',\n                 new TextEncoder().encode(txt));\n  return Array.from(new Uint8Array(buf))\n              .map(b => b.toString(16).padStart(2, '0')).join('');\n}\n\nasync function unlockOne(btn) {\n  const pass = prompt(\"Password:\");\n  if (!pass) return;\n  if (await sha256(pass) !== correctHash) {\n    alert(\"Wrong password\"); return;\n  }\n\n  /* --- decode only the solution that belongs to THIS button --- */\n  const wrapper = btn.parentElement;             // .b64-wrapper\n  wrapper.querySelectorAll('.hidden-solution').forEach(div => {\n    div.innerHTML = b64DecodeUtf8(div.dataset.encoded);\n    div.classList.remove('hidden-solution');\n    div.style.display = 'block';\n  });\n\n  /* Remove the button so the user can’t click it again */\n  btn.remove();\n}\n</script>\n\n<noscript>\n<div style=\"border: 1px solid #ccc; padding: 1em; margin-top: 1em; background: #f9f9f9;\">\n    <strong>JavaScript is required to unlock solutions.</strong><br>\n    Please enable JavaScript and reload the page,<br>\n    or download the source files from\n    <a href=\"https://github.com/mlr-org/mlr3website/\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>\n    and run the code locally.\n  </div>\n</noscript>\n```\n\n\n\n\n\n# Goal\n\nThe objective of this exercise is to get hands-on experience with conducting large-scale machine learning experiments using MLR3, Batchtools, and the OpenML connector. You will learn how to set up a parallelized benchmark experiment on your laptop.\n\n# Prerequisites\n\nWe need the following libraries:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary('mlr3verse')\nlibrary('mlr3oml')\nlibrary('data.table')\nlibrary('batchtools')\nlibrary('ggplot2')\n```\n:::\n\n\n\n# Exercise 1: Getting Data from OpenML\n\nTo draw meaningful conclusions from benchmark experiments, a good choice of data sets and tasks is essential. [OpenML](https://www.openml.org) is an open-source online platform that facilitates the sharing of machine learning research data, algorithms, and experimental results in a standardized format. Finding data from OpenML is possible via the website or its API. The `mlr3oml` package offers an elegant connection between `mlr3` and OpenML. The function `list_oml_tasks()` can be used to filter tasks for specific properties. To get started, utilize this to create a list of tasks with 10-20 features, 500-1000 rows and a categorical outcome with two classes. From this list, remove duplicate instances with similar names (sometimes, different versions of more or less the same data set are produced). For example, you could do this by removing instances where the first 3 letters of the name column match those of other instances. Further, exclude instances where the minority class is less than 10% of the overall number of observations.\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Get data\nodata = list_oml_tasks(\n  number_features = c(10, 20),\n  number_instances = c(500, 1000),\n  number_classes = 2\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [10:22:13.429] Retrieving JSON {url: `https://www.openml.org/api/v1/json/task/list/number_instances/500..1000/number_features/10..20/number_classes/2/limit/1000`, authenticated: `FALSE`}\n```\n\n\n:::\n\n```{.r .cell-code}\n# Remove duplicates\nodata <- odata[!duplicated(substr(odata$name, 1, 3)), ]\n\n# Remove imbalanced data sets\nodata <- odata[9 * odata$MinorityClassSize >= odata$MajorityClassSize, ]\n\n# View result\nnrow(odata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(odata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   task_id                 task_type data_id            name status MajorityClassSize MaxNominalAttDistinctValues\n     <int>                    <char>   <int>          <char> <char>             <int>                       <int>\n1:      15 Supervised Classification      15        breast-w active               458                           2\n2:      29 Supervised Classification      29 credit-approval active               383                          14\n3:      49 Supervised Classification      50     tic-tac-toe active               626                           3\n4:    3561 Supervised Classification     470           profb active               448                          28\n5:    3583 Supervised Classification     717   rmftsa_ladata active               286                           2\n6:    3606 Supervised Classification     740  fri_c3_1000_10 active               560                           2\n   MinorityClassSize NumberOfClasses NumberOfFeatures NumberOfInstances NumberOfInstancesWithMissingValues\n               <int>           <int>            <int>             <int>                              <int>\n1:               241               2               10               699                                 16\n2:               307               2               16               690                                 37\n3:               332               2               10               958                                  0\n4:               224               2               10               672                                666\n5:               222               2               11               508                                  0\n6:               440               2               11              1000                                  0\n   NumberOfMissingValues NumberOfNumericFeatures NumberOfSymbolicFeatures\n                   <int>                   <int>                    <int>\n1:                    16                       9                        1\n2:                    67                       6                       10\n3:                     0                       0                       10\n4:                  1200                       5                        5\n5:                     0                      10                        1\n6:                     0                      10                        1\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n# Exercise 2: Working with OpenML data\n\nNotably, `list_oml__data_tasks()` only retrieves relevant information about the tasks, and not the data itself. Convert this list of tasks by directly transforming it to `mlr3` tasks with applying `otsk()` to each `data_id`. Find out how you can load and inspect the data from a single task in the list. \n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# List of tasks\ntasklist <- lapply(odata$task_id, otsk)\n\n# Example data of a single task\ntasklist[[17]]$data$data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [10:22:19.295] Retrieving JSON {url: `https://www.openml.org/api/v1/json/task/361983`, authenticated: `FALSE`}\nINFO  [10:22:19.357] Retrieving JSON {url: `https://www.openml.org/api/v1/json/data/45711`, authenticated: `FALSE`}\nINFO  [10:22:19.416] Retrieving ARFF {url: `https://api.openml.org/data/v1/download/22117212/doa_bwin.arff`, authenticated: `FALSE`}\nINFO  [10:22:19.856] Retrieving JSON {url: `https://www.openml.org/api/v1/json/data/features/45711`, authenticated: `FALSE`}\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     CountryID Gender ageRDATE p2sumstake p2sumbet p2sumday p2intvday    p2bpd     p2net    Zp2bpd1m Zp2stakeSD1m\n        <fctr> <fctr>    <int>      <num>    <int>    <int>     <int>    <num>     <num>       <num>        <num>\n  1:       620      1       21  6202.5700      347       68       308 5.102941   57.9500  0.36724532   0.41029440\n  2:        40      1       19   665.8765       57       26       540 2.192308  116.0765 -0.23909197  -0.06947528\n  3:       616      1       20   843.2210      306      105       679 2.914286  -27.4005  0.00760946  -0.23189846\n  4:       616      1       38   355.1172       31       20       458 1.550000   76.5577 -0.43097086  -0.06199048\n  5:       724      1       26 13622.0703      613       76       733 8.065789 1860.0303  0.54441350   0.04268775\n ---                                                                                                             \n526:       276      1       19   318.0900      141       22       373 6.409091   86.0800 -0.52691031  -0.26278703\n527:       276      1       24    31.7000       20        9        71 2.222222   10.6000 -0.14315253  -0.23098926\n528:       300      1       36   238.6500       37       19       461 1.947368  -51.6700 -0.18426943  -0.21703466\n529:       380      1       19   180.2000       18        8       451 2.250000    6.0000 -0.43097086  -0.19515845\n530:       380      1       27    42.5000        9        5       354 1.800000   25.8700 -0.43097086  -0.19204015\n     Zp2totalactivedays1m Zp2stakeslope1m     DV\n                    <num>           <num> <fctr>\n  1:           3.45617824      0.15568296      1\n  2:           1.34429259      0.27314822      0\n  3:           0.28834976     -0.04884159      0\n  4:           0.64033070      0.04042819      0\n  5:           1.16830211     -0.09077256      0\n ---                                            \n526:          -0.23962165      0.39170911      0\n527:          -0.59160260      1.91135366      1\n528:           0.28834976     -0.18182620      0\n529:          -0.06363118      0.31159202      0\n530:          -0.59160260      1.60435360      0\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n# Exercise 3: Batch Tools\n\n## Exercise 3.1: OpenML Task and Learners\n\nFor this task, look at the german credit data set. \nDownload it from OpenML (task id: 31) and create a task.\nDefine a tree, an SVM and a Random Forest as they shall be benchmarked later.\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noml_task = OMLTask$new(31)\noml_data = as_data_backend(oml_task$data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [10:22:19.956] Retrieving JSON {url: `https://www.openml.org/api/v1/json/task/31`, authenticated: `FALSE`}\nINFO  [10:22:20.122] Retrieving JSON {url: `https://www.openml.org/api/v1/json/data/31`, authenticated: `FALSE`}\nINFO  [10:22:20.187] Retrieving ARFF {url: `https://api.openml.org/data/v1/download/31/credit-g.arff`, authenticated: `FALSE`}\n```\n\n\n:::\n\n```{.r .cell-code}\ntask = as_task_classif(oml_data, target = \"class\")\nlearners = list(\n  lrn(\"classif.rpart\"),\n  lrn(\"classif.ranger\")\n)\n```\n:::\n\n\n\n:::\n\n:::\n\n\n## Exercise 3.2: Batchtools experiment registry\n\nCreate and configure a Batchtools experiment registry:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreg = makeExperimentRegistry(\n  file.dir = \"mlr3_experiments\",\n  packages = c(\"mlr3\", \"mlr3verse\"),\n  seed = 1\n)\n```\n:::\n\n\nYou can add problems and algorithms to the registry using the following code: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naddProblem(\"task\", data = task)\naddAlgorithm(name = \"mlr3\", fun = function(job, data, instance, learner) {\n  learner = lrn(learner)\n  task = as_task(data)\n  learner$train(task)\n})\n```\n:::\n\n\nDefine the design of experiments:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprob_design = list(task = data.table())\nalgo_design = list(mlr3 = data.frame(learner = sapply(learners, function(x) {x$id}),\n                                     stringsAsFactors = FALSE))\naddExperiments(prob.designs = prob_design, algo.designs = algo_design)\nsummarizeExperiments()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   problem algorithm .count\n    <char>    <char>  <int>\n1:    task      mlr3      2\n```\n\n\n:::\n:::\n\n\nTest a single job to ensure it works correctly:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntestJob(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### [bt]: Generating problem instance for problem 'task' ...\n### [bt]: Applying algorithm 'mlr3' on problem 'task' for job 1 (seed = 2) ...\n```\n\n\n:::\n:::\n\n\n\n1. Add at least two more learners to the benchmark experiment. Choose any classification learners from the `mlr3learners` package.\n2. Configure and run a resampling strategy (e.g., 10-fold cross-validation) instead of using the whole dataset for training and testing.\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Adding more learners\nlearners2 = list(\n  lrn(\"classif.rpart\"),\n  lrn(\"classif.ranger\"),\n  lrn(\"classif.kknn\"),       # Added k-Nearest Neighbors\n  lrn(\"classif.naive_bayes\") # Added Naive Bayes\n)\n\n# Define the algorithm with resampling\naddAlgorithm(name = \"mlr3res\", fun = function(job, data, instance, learner) {\n  learner = lrn(learner)\n  task = as_task(data)\n  resampling = rsmp(\"cv\", folds = 10)$instantiate(task)\n  rr = resample(task, learner, resampling, store_models = TRUE)\n  list(measure = rr$aggregate(msr(\"classif.acc\")))\n})\n\n# Define the design of experiments\nprob_design2 = list(task = data.table())\nalgo_design2 = list(mlr3res = data.frame(learner = sapply(learners2, \n                                                          function(x) {x$id}), \n                                         stringsAsFactors = FALSE))\naddExperiments(prob.designs = prob_design2, algo.designs = algo_design2)\nsummarizeExperiments()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   problem algorithm .count\n    <char>    <char>  <int>\n1:    task      mlr3      2\n2:    task   mlr3res      4\n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Test a single job to ensure it works correctly\ntestJob(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### [bt]: Generating problem instance for problem 'task' ...\n### [bt]: Applying algorithm 'mlr3' on problem 'task' for job 1 (seed = 2) ...\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::\n\n## Exercise 3.3: Benchmark\n\nSubmit jobs to be executed in parallel:   \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsubmitJobs()\nwaitForJobs() # Wait for the jobs to finish\n```\n:::\n\n\n\nCollect and analyze the results:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres = reduceResultsList()\nprint(res)\n```\n:::\n\n\n\nPlot the performance metrics of the different learners using the `ggplot2` package.\n\n\n:::{.callout-note collapse=\"true\"}\n\n### Solution\n\n:::{.b64-solution}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsubmitJobs()\nwaitForJobs() # Wait for the jobs to finish\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nres = reduceResultsList()\nprint(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n<LearnerClassifRpart:classif.rpart>: Classification Tree\n* Model: rpart\n* Parameters: xval=0\n* Packages: mlr3, rpart\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, factor, ordered\n* Properties: importance, missings, multiclass, selected_features, twoclass, weights\n\n[[2]]\n<LearnerClassifRanger:classif.ranger>: Random Forest\n* Model: ranger\n* Parameters: num.threads=1\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, missings, multiclass, oob_error, selected_features, twoclass,\n  weights\n\n[[3]]\n[[3]]$measure\nclassif.acc \n      0.736 \n\n\n[[4]]\n[[4]]$measure\nclassif.acc \n      0.769 \n\n\n[[5]]\n[[5]]$measure\nclassif.acc \n      0.725 \n\n\n[[6]]\n[[6]]$measure\nclassif.acc \n      0.756 \n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Collect results into a data.table\nresults = rbindlist(lapply(res, function(x) data.table(acc = x$measure)))\nresults$learner = algo_design2$mlr3res$learner\n\n# Plot the performance metrics using ggplot2\nggplot(results, aes(x = learner, y = acc)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Performance of Different Learners\",\n       x = \"Learner\",\n       y = \"Classification Accuracy\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n:::\n\n:::\n\n\n# Summary\n\nWe downloaded various data sets from OpenML and used batch tools to parallelize a benchmark study.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}