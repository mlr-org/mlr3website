{
  "hash": "66df15ad170d41123969a0da02157782",
  "result": {
    "markdown": "---\ntitle: A Production Example Using Plumber and Docker\ncategories:\n  - mlr3pipelines\n  - regression\nauthor:\n  - name: Lennart Schneider\ndate: 08-13-2020\ndescription: |\n  We write a REST API using plumber and deploy it using Docker.\nimage: ../../images/logo_color.png\n---\n\n\n\n\nProduction with R has come a long way.\nIn this tutorial, we give a brief example on how to write a REST API and deploy it (relying on the `mlr3` ecosystem for the actual training and predicting).\nMost of this tutorial was inspired by other excellent posts and vignettes:\n\n* [R can API and So Can You!](https://medium.com/tmobile-tech/r-can-api-c184951a24a3)\n* [Using docker to deploy an R plumber API](https://medium.com/tmobile-tech/using-docker-to-deploy-an-r-plumber-api-863ccf91516d)\n* `AzureContainer`'s [vignette](https://cran.r-project.org/web/packages/AzureContainers/vignettes/vig01_plumber_deploy.html)\n\nAll files presented in this tutorial are available [here](https://github.com/mlr-org/mlr3gallery/tree/master/_posts/2020-08-13-a-production-example-using-plumber-and-docker/mlr3_api).\n\n### Modeling Background\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(mlr3)\nlibrary(mlr3pipelines)\n```\n:::\n\n\nWe will use a subset of the [`boston_housing`](https://mlr3.mlr-org.com/reference/mlr_tasks_boston_housing.html) [`Task`](https://mlr3.mlr-org.com/reference/Task.html).\nOur goal is to predict the median value of owner-occupied homes in USD 1000's (target `medv`), using the features `crim`, `tax` and `town` (just to have `factor`, `integer`, and `numeric` feature types):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata = tsk(\"boston_housing\")$data()\ndata = data[, c(\"medv\", \"crim\", \"tax\", \"town\")]\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = TaskRegr$new(\"boston\", backend = data, target = \"medv\")\n```\n:::\n\n\nLet's create a toy pipeline:\n\nRegarding modeling, we will keep it very simple and use the [`rpart learner`](https://mlr3.mlr-org.com/reference/mlr_learners_regr.rpart.html). Missing numerical features (which could happen during prediction) will be imputed by their median via [`PipeOpImputeMedian`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_imputemedian.html), while missing factorial features will be imputed using a new level via [`PipeOpImputeOOR`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_imputeoor.html). As `PipeOpImputeOOR` will introduce a new `level`, `\".MISSING\"` to impute missing values, we also use [`PipeOpFixFactors`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_fixfactors.html):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ng = po(\"imputemedian\") %>>%\n  po(\"imputeoor\") %>>%\n  po(\"fixfactors\") %>>%\n  lrn(\"regr.rpart\")\n```\n:::\n\n\nWe wrap this [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) in a [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) and can train on the [`Task`](https://mlr3.mlr-org.com/reference/Task.html):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngl = GraphLearner$new(g)\ngl$train(task)\n```\n:::\n\n\nWe can inspect the trained pipeline looking at:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngl$model\n```\n:::\n\n\nFurthermore, we can save the trained pipeline, i.e., as `\"gl.rds\"`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsaveRDS(gl, \"gl.rds\")\n```\n:::\n\n\nWe will also store some information regarding the features, i.e., the feature names, types and levels (you will later see, why we need to do this):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfeature_info = list(\n  feature_names = task$feature_names,\n  feature_types = task$feature_types,\n  levels = task$levels()\n)\nsaveRDS(feature_info, \"feature_info.rds\")\n```\n:::\n\n\nPutting everything in a file, `train_gl.R` looks like the following, which we can then source before moving on:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# train_gl.R\n\nlibrary(mlr3)\nlibrary(mlr3pipelines)\n\ndata = tsk(\"boston_housing\")$data()\ndata = data[, c(\"medv\", \"crim\", \"tax\", \"town\")]\ntask = TaskRegr$new(\"boston\", backend = data, target = \"medv\")\n\ng = po(\"imputemedian\") %>>%\n  po(\"imputeoor\") %>>%\n  po(\"fixfactors\") %>>%\n  lrn(\"regr.rpart\")\n\ngl = GraphLearner$new(g)\n\ngl$train(task)\n\nsaveRDS(gl, \"gl.rds\")\n\nfeature_info = list(\n  feature_names = task$feature_names,\n  feature_types = task$feature_types,\n  levels = task$levels()\n)\n\nsaveRDS(feature_info, \"feature_info.rds\")\n```\n:::\n\n\nOur goal of our REST (representational state transfer) API (application programming interface) will be to predict the `medv` of a new observation, i.e., it should do something like the following:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewdata = data.table(crim = 3.14, tax = 691, town = \"Newton\")\ngl$predict_newdata(newdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionRegr> for 1 observations:\n row_ids truth response\n       1    NA 32.23288\n```\n:::\n:::\n\n\nHowever, in our REST API, the `newdata` will be received at an endpoint that accepts a particular input. In the next section we will use `plumber` to set up our web service.\n\n### Using plumber to set up our REST API\n\nThe package [plumber](https://cran.r-project.org/package=plumber) allows us to create a REST API by simply commenting existing R code. `plumber` makes use of these comments to define the web service. Running `plumber::plumb` on the commented R file then results in a runnable web service that other systems can interact with over a network.\n\nAs an endpoint for predicting the `medv`, we will use a `POST` request. This will allow us to enclose data in the body of the request message. More precisely, we assume that the data will be provided in the JSON format.\n\nWhen a `POST` request containing the data (in JSON format) is received our code must then:\n\n1. convert the input (in JSON format) to a [`data.table`](https://www.rdocumentation.org/packages/data.table/topics/data.table-package) with all feature columns matching their feature type\n\n2. predict the `medv` based on the input using our trained pipeline and provide an output that can be understood by the client\n\nTo make sure that all features match their feature type, we will later use the following function stored in the R file `fix_feature_types.R`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# fix_feature_types.R\n\nfix_feature_types = function(feature, feature_name, feature_info) {\n  id = match(feature_name, feature_info$feature_names)\n  feature_type = feature_info$feature_types$type[id]\n  switch(feature_type,\n    \"logical\"   = as.logical(feature),\n    \"integer\"   = as.integer(feature),\n    \"numeric\"   = as.numeric(feature),\n    \"character\" = as.character(feature),\n    \"factor\"    = factor(feature, levels = feature_info$levels[[feature_name]],\n      ordered = FALSE),\n    \"ordered\"   = factor(feature, levels = feature_info$levels[[feature_name]],\n      ordered = TRUE),\n    \"POSIXct\"   = as.POSIXct(feature)\n  )\n}\n```\n:::\n\n\n`fix_feature_types()` can later be applied to the `newdata`, and will make sure, that all incoming features are converted to their expected feature type as in the original [`Task`](https://mlr3.mlr-org.com/reference/Task.html) we used for training our pipeline (and this is the reason, why we stored the information about the features earlier).\nNote that in our tutorial we only have `factor`, `integer`, and `numeric` features, but `fix_feature_types()` should also work for all other supported `feature_types` listed in `mlr_reflections$task_feature_types`. However, it may need some customization depending on your own production environment to make the conversions meaningful.\n\nThe following R file, `predict_gl.R` loads our trained pipepline and feature information and provides an endpoint for a `POST` request, `\"/predict_medv\"`. The incoming data then is converted using `jsonlite::fromJSON`. We expect the incoming data to either be JSON objects in an array or nested JSON objects and therefore we bind the converted vectors row-wise to a [`data.table`](https://www.rdocumentation.org/packages/data.table/topics/data.table-package) using  `data.table::rbindlist`. We then convert all features to their expected `feature_types` (using the `fix_feature_types()` function as defined above) and can finally predict the `medv` using our trained pipeline. As no default serialization from `R6` objects to JSON objects exists (yet), we wrap the [`Prediction`](https://mlr3.mlr-org.com/reference/Prediction.html) in a [`data.table`](https://www.rdocumentation.org/packages/data.table/topics/data.table-package) (of course we could also only return the numeric prediction values):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# predict_gl.R\n\nlibrary(data.table)\nlibrary(jsonlite)\nlibrary(mlr3)\nlibrary(mlr3pipelines)\n\nsource(\"fix_feature_types.R\")\n\ngl = readRDS(\"gl.rds\")\n\nfeature_info = readRDS(\"feature_info.rds\")\n\n#* @post /predict_medv\nfunction(req) {\n  # get the JSON string from the post body\n  newdata = fromJSON(req$postBody, simplifyVector = FALSE)\n  # expect either JSON objects in an array or nested JSON objects\n  newdata = rbindlist(newdata, use.names = TRUE)\n  # convert all features in place to their expected feature_type\n  newdata[, colnames(newdata) := mlr3misc::pmap(\n    list(.SD, colnames(newdata)),\n    fix_feature_types,\n    feature_info = feature_info)]\n  # predict and return as a data.table\n  as.data.table(gl$predict_newdata(newdata))\n  # or only the numeric values\n  # gl$predict_newdata(newdata)$response\n}\n```\n:::\n\n\nNote that the only difference to a regular R file is the comment\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#* @post /predict_medv`\n```\n:::\n\n\ntelling `plumber` to construct the endpoint `\"/predict_medv\"` for a `POST` request.\n\nWe can then run `plumber::plumb`. The following code sets up the web service locally on your personal machine at port 1030 (we use such a high number because some systems require administrator rights to allow processes to listen to lower ports):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(plumber)\nr = plumb(\"predict_gl.R\")\nr$run(port = 1030, host = \"0.0.0.0\")\n```\n:::\n\n\nCongratulations, your first REST API is running on your local machine. We can test it by providing some data, using `curl` via the command line:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\ncurl --data '[{\"crim\":3.14, \"tax\":691, \"town\":\"Newton\"}]' \"http://127.0.0.1:1030/predict_medv\"\n```\n:::\n\n\nThis should return the predicted `medv`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\n[{\"row_id\":1,\"response\":\"32.2329\"}]\n```\n:::\n\n\nAlternatively, we can also use the `httr::POST` function within R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewdata = '[{\"crim\":3.14, \"tax\":691, \"town\":\"Newton\"}]'\nresp = httr::POST(url = \"http://127.0.0.1:1030/predict_medv\",\n  body = newdata, encode = \"json\")\nhttr::content(resp)\n```\n:::\n\n\nWe can further play around a bit more and provide more than a single new observation and also check whether our feature type conversion and missing value imputation works:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewdata = '[\n  {\"crim\":3.14, \"tax\":691, \"town\":\"Newton\"},\n  {\"crim\":\"not_a_number\", \"tax\":3.14, \"town\":\"Munich\"},\n  {\"tax\":\"not_a_number\", \"town\":31, \"crim\":99}\n]'\nresp = httr::POST(url = \"http://127.0.0.1:1030/predict_medv\",\n  body = newdata, encode = \"json\")\nhttr::content(resp)\n```\n:::\n\n\nNote that you can also use `jsonlite::toJSON` to convert a `data.frame` to JSON data for your toy examples here.\n\nIn the following final section we want to use `Docker` to run a virtual machine as a container (an instance of a snapshot of a machine at a moment in time).\n\n### Using Docker to Deploy our REST API\n\nA [`Docker`](https://www.docker.com/) container image is a lightweight, standalone, executable package of software that includes everything needed to run an application. Suppose we want to run our REST API on an Amazon Web Service or Microsoft's Azure Cloud. Then we can use a `Docker` container to easily set up our web service without going through the hassle of configuring manually our hosting instance.\n\nWe are going to need two things: An image and a container. An image defines the OS and software while the container is the actual running instance of the image. To build a `Docker` image we have to specify a `Dockerfile`. Note that it is sensible to set up the whole project in its own directory, e.g., `~/mlr3_api`.\n\nEvery `Dockerfile` starts with a `FROM` statement describing the image we are building our image from. In our case we want an R based image that ideally already has `plumber` and its dependencies installed. Luckily, the `trestletech/plumber` image exists:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\nFROM trestletech/plumber\n```\n:::\n\n\nWe then install the R packages needed to set up our REST API (note that we can skip `jsonlite`, because `plumber` already depends on it):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\nRUN R -e 'install.packages(c(\"data.table\", \"mlr3\", \"mlr3pipelines\"))'\n```\n:::\n\n\nNext, we copy our trained pipeline (`gl.rds`), our stored feature information (`feature_info.rds`), our R file to convert features, (`fix_feature_types.R`) and our R file to predict (`predict_gl.R`) to a new directory `/data` and set this as the working directory:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\nRUN mkdir /data\nCOPY gl.rds /data\nCOPY feature_info.rds /data\nCOPY fix_feature_types.R /data\nCOPY predict_gl.R /data\nWORKDIR /data\n```\n:::\n\n\nFinally, we listen on port 1030 and start the server (this is analogously done as manually calling `plumber::plumb` on the `predict_gl.R` file and running it):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\nEXPOSE 1030\nENTRYPOINT [\"R\", \"-e\", \\\n    \"r = plumber::plumb('/data/predict_gl.R'); r$run(port = 1030, host = '0.0.0.0')\"]\n```\n:::\n\n\nThe complete `Dockerfile` looks like the following:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\nFROM trestletech/plumber\n\nRUN R -e 'install.packages(c(\"data.table\", \"mlr3\", \"mlr3misc\", \"mlr3pipelines\"))'\n\nRUN mkdir /data\nCOPY gl.rds /data\nCOPY feature_info.rds /data\nCOPY fix_feature_types.R /data\nCOPY predict_gl.R /data\nWORKDIR /data\n\nEXPOSE 1030\nENTRYPOINT [\"R\", \"-e\", \\\n    \"r = plumber::plumb('/data/predict_gl.R'); r$run(port = 1030, host = '0.0.0.0')\"]\n```\n:::\n\n\nTo build the image we open a terminal in the `mlr3_api` directory and run:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\ndocker build -t mlr3-plumber-demo .\n```\n:::\n\n\nThis may take quite some time.\n\nTo finally run the container, simply use:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\ndocker run --rm -p 1030:1030 mlr3-plumber-demo\n```\n:::\n\n\nYou can then proceed to provide some data via `curl` or `httr::POST` (to the same local address, because the `Docker` container is still running on your local machine).\n\nTo stop all running containers use:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.bash .cell-code}\ndocker stop $(docker ps -a -q)\n```\n:::\n\n\nFinally, you can proceed to deploy your container to an Amazon Web Service or an Azure Cloud. For the latter, the package [AzureContainers](https://cran.r-project.org/package=AzureContainers) is especially helpful. If you do plan to do this note that the `plumber` service above is exposed over HTTP, and there is no authentication layer making it insecure. You may think about adding a layer of authentification and restricting the service to HTTPS.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}