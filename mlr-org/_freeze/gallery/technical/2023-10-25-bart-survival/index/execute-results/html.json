{
  "hash": "b5b35634aa2013a84f1eb0cca5ceb76b",
  "result": {
    "markdown": "---\ntitle: \"Survival modeling in mlr3 using Bayesian Additive Regression Trees (BART)\"\ndescription: |\n  Demonstrate use of survival BART on the lung dataset via mlr3proba and distr6.\nauthor:\n  - name: John Zobolas\n    orcid: 0000-0002-3609-8674\n    url: https://github.com/bblodfon\ndate: 2023-10-25\nbibliography: ../../bibliography.bib\n---\n\n\n\n\n## Intro\n\nHere are some interesting reads regarding BART:\n\n- The first BART paper [@Chipman2010].\n- The first implementation of BART for survival data [@Bonato2011].\nThis includes fully parametric AFT and Weibull models and the semi-parametric CoxPH regression model.\n- The first non-parametric implementation of BART for survival data [@Sparapani2016]\n- `BART` R package tutorial [@Sparapani2021]\n\nWe incorporated the survival `BART` model in `mlr3extralearners` and in this tutorial we will demonstrate how we can use packages like `mlr3`, `mlr3proba` and `distr6` to more easily manipulate the output predictions to assess model convergence, validate our model (via several survival metrics), as well as perform model interpretation via PDPs (Partial Dependence Plots).\n\n## Libraries\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3extralearners)\nlibrary(mlr3pipelines)\nlibrary(mlr3proba)\nlibrary(distr6)\nlibrary(BART) # 2.9.4\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\n```\n:::\n\n\n## Data\n\nWe will use the Lung Cancer Dataset.\nWe convert the `time` variable from days to months to ease the computational burden:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask_lung = tsk('lung')\n\nd = task_lung$data()\n# in case we want to select specific columns to keep\n# d = d[ ,colnames(d) %in% c(\"time\", \"status\", \"age\", \"sex\", \"ph.karno\"), with = FALSE]\nd$time = ceiling(d$time/30.44)\ntask_lung = as_task_surv(d, time = 'time', event = 'status', id = 'lung')\ntask_lung$label = \"Lung Cancer\"\n```\n:::\n\n\n:::{.callout-note}\n1. The original `BART` implementation supports categorical features (factors).\nThis results in different importance scores per each dummy level which doesn't work well with `mlr3`.\nSo features of type `factor` or `character` are not allowed and we leave it to the user to encode them as they please.\n2. The original `BART` implementation supports features with missing values.\nThis is totally fine with `mlr3` as well!\nIn this example, we impute the features to show good ML practice.\n:::\n\nIn our lung dataset, we encode the `sex` feature and perform model-based imputation with the `rpart` regression learner:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npo_encode = po('encode', method = 'treatment')\npo_impute = po('imputelearner', lrn('regr.rpart'))\npre = po_encode %>>% po_impute\ntask = pre$train(task_lung)[[1]]\ntask\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskSurv:lung> (228 x 10): Lung Cancer\n* Target: time, status\n* Properties: -\n* Features (8):\n  - int (7): age, inst, meal.cal, pat.karno, ph.ecog, ph.karno, wt.loss\n  - dbl (1): sex\n```\n:::\n:::\n\n\nNo missing values in our data:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask$missings()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     time    status       age       sex      inst  meal.cal pat.karno   ph.ecog  ph.karno   wt.loss \n        0         0         0         0         0         0         0         0         0         0 \n```\n:::\n:::\n\n\nWe partition the data to train and test sets:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(42)\npart = partition(task, ratio = 0.9)\n```\n:::\n\n\n## Train and Test\n\nWe train the `BART` model and predict on the test set:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# default `ndpost` value: 1000. We reduce it to 50 to speed up calculations in this tutorial\nlearner = lrn(\"surv.bart\", nskip = 250, ndpost = 50, keepevery = 10, mc.cores = 10)\nlearner$train(task, row_ids = part$train)\np = learner$predict(task, row_ids = part$test)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionSurv> for 23 observations:\n    row_ids time status    crank     distr\n          9    8   TRUE 66.19326 <list[1]>\n         10    6   TRUE 98.43005 <list[1]>\n         21   10   TRUE 54.82313 <list[1]>\n---                                       \n        160   13  FALSE 37.82089 <list[1]>\n        163   10  FALSE 69.63534 <list[1]>\n        194    8  FALSE 81.13678 <list[1]>\n```\n:::\n:::\n\n\nSee more details about `BART`'s parameters on the online [documentation](https://mlr3extralearners.mlr-org.com/reference/mlr_learners_surv.bart.html).\n\n### distr\n\nWhat kind of object is the predicted `distr`?\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np$distr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArrdist(23x31x50) \n```\n:::\n:::\n\n\n:::{.callout-tip}\n## Arrdist dimensions:\n\n1. Patients (observations)\n2. Time points (months)\n3. Number of posterior draws\n:::\n\nActually the `$distr` is an active [R6](https://r6.r-lib.org/index.html) field - this means that some computation is required to create it.\nWhat the prediction object actually stores internally is a 3d survival array (can be used directly with no performance overhead):\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndim(p$data$distr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 23 31 50\n```\n:::\n:::\n\n\nThis is a more easy-to-understand and manipulate form of the full posterior survival matrix prediction from the `BART` package ([@Sparapani2021], pages 34-35).\n\n:::{.callout-warning}\nThough we have optimized with C++ code the way the `Arrdist` object is constructed, calling the `$distr` field can be computationally taxing if the product of the sizes of the 3 dimensions above **exceeds ~1 million**.\nIn our case, $23 \\times 31 \\times 50 = 35650$ so the conversion to an `Arrdist` via `$distr` will certainly not create performance issues.\n:::\n\nAn example using the internal prediction data: get all the posterior probabilities of the 3rd patient in the test set, at 12 months (1 year):\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np$data$distr[3, 12, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.26546909 0.27505937 0.21151435 0.46700513 0.26178380 0.24040003 0.29946469 0.52357780 0.40833108 0.40367780\n[11] 0.27027392 0.31781286 0.54151844 0.34460027 0.41826554 0.41866367 0.33694401 0.34511270 0.47244492 0.49423660\n[21] 0.42069678 0.20095489 0.48696980 0.48409357 0.35649439 0.47969355 0.16355660 0.33728105 0.40245228 0.42418033\n[31] 0.36336145 0.48181667 0.51858238 0.49635078 0.37238179 0.26694030 0.52219952 0.48992897 0.08572207 0.30306005\n[41] 0.33881682 0.33463870 0.29102074 0.43176131 0.38554545 0.38053756 0.36808776 0.13772665 0.21898264 0.14552514\n```\n:::\n:::\n\n\nWorking with the `$distr` interface and `Arrdist` objects is very efficient as we will see later for predicting survival estimates.\n\n:::{.callout-tip}\nIn survival analysis, $S(t) = 1 - F(t)$, where $S(t)$ the survival function and $F(t)$ the cumulative distribution function (cdf).\nThe latter can be interpreted as `risk` or probability of death up to time $t$.\n\nWe can verify the above from the prediction object:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsurv_array = 1 - distr6::gprm(p$distr, \"cdf\") # 3d array\ntestthat::expect_equal(p$data$distr, surv_array)\n```\n:::\n\n:::\n\n### crank\n\n`crank` is the **expected mortality** [@Sonabend2022] which is the sum of the predicted cumulative hazard function (as is done in random survival forest models).\nHigher values denote larger risk.\nTo calculate `crank`, we need a survival matrix.\nSo we have to choose which 3rd dimension we should use from the predicted survival array.\nThis is what the `which.curve` parameter of the `learner` does:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner$param_set$get_values()$which.curve\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5\n```\n:::\n:::\n\n\nThe default value ($0.5$ quantile) is the **median survival probability**.\nIt could be any other quantile (e.g. $0.25$).\nOther possible values for `which.curve` are `mean` or a number denoting the exact posterior draw to extract (e.g. the last one, `which.curve = 50`).\n\n## Feature importance\n\nDefault score is the **observed count of each feature** in the trees (so the higher the score, the more important the feature):\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner$param_set$values$importance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"count\"\n```\n:::\n\n```{.r .cell-code}\nlearner$importance()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      sex  meal.cal      inst pat.karno  ph.karno   wt.loss       age   ph.ecog \n     7.84      7.46      7.08      6.76      6.60      6.46      5.48      5.42 \n```\n:::\n:::\n\n\n## MCMC Diagnostics\n\n`BART` uses internally MCMC (Markov Chain Monte Carlo) to sample from the posterior survival distribution.\nWe need to check that MCMC has converged, meaning that the chains have reached a stationary distribution that approximates the true posterior survival distribution (otherwise the predictions may be inaccurate, misleading and unreliable).\n\nWe use Geweke's convergence diagnostic test as it is implemented in the `BART` R package.\nWe choose 10 random patients from the train set to evaluate the MCMC convergence.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# predictions on the train set\np_train = learner$predict(task, row_ids = part$train)\n\n# choose 10 patients from the train set randomly and make a list\nids = as.list(sample(length(part$train), 10))\n\nz_list = lapply(ids, function(id) {\n  # matrix with columns => time points and rows => posterior draws\n  post_surv = 1 - t(distr6::gprm(p_train$distr[id], \"cdf\")[1,,])\n  BART::gewekediag(post_surv)$z # get the z-scores\n})\n\n# plot the z scores vs time for all patients\ndplyr::bind_rows(z_list) %>%\n  tidyr::pivot_longer(cols = everything()) %>%\n  mutate(name = as.numeric(name)) %>%\n  ggplot(aes(x = name, y = value)) +\n  geom_point() +\n  labs(x = \"Time (months)\", y = \"Z-scores\") +\n  # add critical values for a = 0.05\n  geom_hline(yintercept = 1.96, linetype = 'dashed', color = \"red\") +\n  geom_hline(yintercept = -1.96, linetype = 'dashed', color = \"red\") +\n  theme_bw(base_size = 14)\n```\n\n::: {.cell-output-display}\n![Geweke plot for MCMC diagnostics. Z-scores for the difference in the mean survival prediction between the first 10% and last 50% part of a Markov chain. The predictions are taken from 10 random patients in the train set. Red lines indicate the a = 0.05 critical line. Only a few z-scores exceed the 95% limits so we conclude that convergence has been attained.](index_files/figure-html/diag-mcmc-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Performance (test set)\n\nWe will use the following survival metrics:\n\n1. Integrated Brier Score (requires a survival distribution prediction - `distr`)\n2. Right-Censored Log loss (requires a survival distribution prediction - `distr`)\n3. Uno's C-index (requires a continuous ranking score prediction - `crank`)\n\nFor the first two measures we will use the ERV (**Explained Residual Variation**) version, which standardizes the scores against a Kaplan-Meier (KM) baseline [@Sonabend2022a].\nThis means that values close to $0$ represent performance similar to a KM model, negative values denote worse performance than KM and $1$ is the absolute best possible score.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmeasures = list(\n  msr(\"surv.graf\", ERV = TRUE),\n  msr(\"surv.rcll\", ERV = TRUE),\n  msr(\"surv.cindex\", weight_meth = \"G2\", id = \"surv.cindex.uno\")\n)\n\nfor (measure in measures) {\n  print(p$score(measure, task = task, train_set = part$train))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  surv.graf \n-0.09950096 \n  surv.rcll \n-0.02622117 \nsurv.cindex.uno \n       0.551951 \n```\n:::\n:::\n\n\n:::{.callout-note}\nAll metrics use by default the **median survival distribution** from the 3d array, no matter what is the `which.curve` argument during the learner's construction.\n:::\n\n## Resampling\n\nPerforming resampling with the `BART` learner is very easy using `mlr3`.\n\nWe first stratify the data by `status`, so that in each resampling the proportion of censored vs un-censored patients remains the same:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask$col_roles$stratum = 'status'\ntask$strata\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       N                row_id\n   <int>                <list>\n1:   165       1,2,4,5,7,8,...\n2:    63  3, 6,38,68,71,83,...\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/unnamed-chunk-16_c842465294e8cacdd194b2d077fa21df'}\n\n```{.r .cell-code}\nrr = resample(task, learner, resampling = rsmp(\"cv\", folds = 5), store_backends = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nINFO  [11:41:53.078] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 1/5)\nINFO  [11:41:55.545] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 2/5)\nINFO  [11:41:57.937] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 3/5)\nINFO  [11:42:00.417] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 4/5)\nINFO  [11:42:03.357] [mlr3] Applying learner 'surv.bart' on task 'lung' (iter 5/5)\n```\n:::\n:::\n\n\nNo errors or warnings:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrr$errors\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEmpty data.table (0 rows and 2 cols): iteration,msg\n```\n:::\n\n```{.r .cell-code}\nrr$warnings\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEmpty data.table (0 rows and 2 cols): iteration,msg\n```\n:::\n:::\n\n\nPerformance in each fold:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrr$score(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   task_id learner_id resampling_id iteration    surv.graf    surv.rcll surv.cindex.uno\n    <char>     <char>        <char>     <int>        <num>        <num>           <num>\n1:    lung  surv.bart            cv         1 -0.312614598 -0.102013166       0.5869665\n2:    lung  surv.bart            cv         2 -0.103181391 -0.009579343       0.5502903\n3:    lung  surv.bart            cv         3  0.001448263  0.338851363       0.6178001\n4:    lung  surv.bart            cv         4 -0.044161171  0.003691073       0.6157215\n5:    lung  surv.bart            cv         5 -0.043129352  0.157902047       0.5688389\nHidden columns: task, learner, resampling, prediction\n```\n:::\n:::\n\n\nMean cross-validation performance:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrr$aggregate(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      surv.graf       surv.rcll surv.cindex.uno \n     -0.1003276       0.0777704       0.5879235 \n```\n:::\n:::\n\n\n## Uncertainty Quantification in Survival Prediction\n\nWe will choose two patients from the test set and plot their survival prediction posterior estimates.\n\nLet's choose the patients with the worst and the best survival time:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndeath_times = p$truth[,1]\nsort(death_times)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  3  5  5  6  6  6  7  8  8  8  8 10 10 10 12 12 12 13 15 16 17 18 27\n```\n:::\n\n```{.r .cell-code}\nworst_indx = which(death_times == min(death_times))[1] # died first\nbest_indx  = which(death_times == max(death_times))[1] # died last\n\npatient_ids = c(worst_indx, best_indx)\npatient_ids # which patient IDs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  5 18\n```\n:::\n\n```{.r .cell-code}\ndeath_times = death_times[patient_ids]\ndeath_times # 1st is worst, 2nd is best\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  3 27\n```\n:::\n:::\n\n\nSubset `Arrdist` to only the above 2 patients:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\narrd = p$distr[patient_ids]\narrd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArrdist(2x31x50) \n```\n:::\n:::\n\n\nWe choose time points (in months) for the survival estimates:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmonths = seq(1, 36) # 1 month - 3 years\n```\n:::\n\n\nWe use the `$distr` interface and the `$survival` property to get survival probabilities from an `Arrdist` object as well as the **quantile credible intervals** (CIs).\nThe median survival probabilities can be extracted as follows:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmed = arrd$survival(months) # 'med' for median\n\ncolnames(med) = paste0(patient_ids, \"_med\")\nmed = as_tibble(med) %>% add_column(month = months)\nhead(med)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  `5_med` `18_med` month\n    <dbl>    <dbl> <int>\n1   0.874    0.981     1\n2   0.767    0.962     2\n3   0.670    0.945     3\n4   0.569    0.927     4\n5   0.465    0.901     5\n6   0.366    0.869     6\n```\n:::\n:::\n\n\nWe can briefly verify model's predictions: 1st patient survival probabilities on any month are lower (worst) compared to the 2nd patient.\n\nNote that subsetting an `Arrdist` (3d array) creates a `Matdist` (2d matrix), for example we can explicitly get the median survival probabilities:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmatd_median = arrd[, 0.5] # median\nhead(matd_median$survival(months)) # same as with `arrd`\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       [,1]      [,2]\n1 0.8741127 0.9808363\n2 0.7670382 0.9621618\n3 0.6701276 0.9450867\n4 0.5688809 0.9272284\n5 0.4647686 0.9007042\n6 0.3660939 0.8687270\n```\n:::\n:::\n\n\nUsing the `mean` posterior survival probabilities or the ones from the last posterior draw is also possible and can be done as follows:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmatd_mean = arrd[, \"mean\"] # mean (if needed)\nhead(matd_mean$survival(months))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       [,1]      [,2]\n1 0.8652006 0.9748463\n2 0.7533538 0.9521817\n3 0.6560050 0.9293229\n4 0.5623555 0.9051549\n5 0.4750038 0.8758896\n6 0.3815333 0.8360373\n```\n:::\n\n```{.r .cell-code}\nmatd_50draw = arrd[, 50] # the 50th posterior draw\nhead(matd_50draw$survival(months))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       [,1]      [,2]\n1 0.9178342 0.9920982\n2 0.8424195 0.9842589\n3 0.7732014 0.9764815\n4 0.7096707 0.9687656\n5 0.6029119 0.9495583\n6 0.5122132 0.9307318\n```\n:::\n:::\n\n\nTo get the CIs we will subset the `Arrdist` using a quantile number (0-1), which extracts a `Matdist` based on the cdf.\nThe survival function is 1 - cdf, so low and upper bounds are reversed:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlow  = arrd[, 0.975]$survival(months) # 2.5% bound\nhigh = arrd[, 0.025]$survival(months) # 97.5% bound\ncolnames(low)  = paste0(patient_ids, \"_low\")\ncolnames(high) = paste0(patient_ids, \"_high\")\nlow  = as_tibble(low)\nhigh = as_tibble(high)\n```\n:::\n\n\nThe median posterior survival probabilities for the two patient of interest and the corresponding CI bounds in a tidy format are:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsurv_tbl =\n  bind_cols(low, med, high) %>%\n  pivot_longer(cols = !month, values_to = \"surv\",\n    names_to = c(\"patient_id\", \".value\"), names_sep = \"_\") %>%\n  relocate(patient_id)\nsurv_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 72 × 5\n   patient_id month   low   med  high\n   <chr>      <int> <dbl> <dbl> <dbl>\n 1 5              1 0.713 0.874 0.953\n 2 18             1 0.929 0.981 0.996\n 3 5              2 0.508 0.767 0.903\n 4 18             2 0.863 0.962 0.991\n 5 5              3 0.362 0.670 0.855\n 6 18             3 0.801 0.945 0.985\n 7 5              4 0.244 0.569 0.804\n 8 18             4 0.734 0.927 0.977\n 9 5              5 0.146 0.465 0.748\n10 18             5 0.654 0.901 0.969\n# ℹ 62 more rows\n```\n:::\n:::\n\n\nWe draw survival curves with the uncertainty for the survival probability quantified:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmy_colors = c(\"#E41A1C\", \"#4DAF4A\")\nnames(my_colors) = patient_ids\n\nsurv_tbl %>%\n  ggplot(aes(x = month, y = med)) +\n  geom_step(aes(color = patient_id), linewidth = 1) +\n  xlab('Time (Months)') +\n  ylab('Survival Probability') +\n  geom_ribbon(aes(ymin = low, ymax = high, fill = patient_id),\n    alpha = 0.3, show.legend = F) +\n  geom_vline(xintercept = death_times[1], linetype = 'dashed', color = my_colors[1]) +\n  geom_vline(xintercept = death_times[2], linetype = 'dashed', color = my_colors[2]) +\n  theme_bw(base_size = 14) +\n  scale_color_manual(values = my_colors) +\n  scale_fill_manual(values = my_colors) +\n  guides(color = guide_legend(title = \"Patient ID\"))\n```\n\n::: {.cell-output-display}\n![Uncertainty quantification for the survival prediction of two patients in the test set using 95% credible intervals. The two vertical lines correspond to the reported time of death (in months) for the two patients.](index_files/figure-html/surv-with-uq-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Partial Dependence Plot\n\nWe will use a Partial Dependence Plot (PDP) [@Friedman2001] to visualize how much different are males vs females in terms of their average survival predictions across time.\n\n:::{.callout-note}\nPDPs assume that features are independent.\nIn our case we need to check that `sex` doesn't correlate with any of the other features used for training the `BART` learner.\nSince `sex` is a categorical feature, we fit a linear model using as target variable every other feature in the data ($lm(feature \\sim sex)$) and conduct an ANOVA (ANalysis Of VAriance) to get the variance explained or $R^2$.\nThe square root of that value is the correlation measure we want.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# code from https://christophm.github.io/interpretable-ml-book/ale.html\nmycor = function(cnames, data) {\n  x.num = data[, cnames[1], with = FALSE][[1]]\n  x.cat = data[, cnames[2], with = FALSE][[1]]\n  # R^2 = Cor(X, Y)^2 in simple linear regression\n  sqrt(summary(lm(x.num ~ x.cat))$r.squared)\n}\n\ncnames = c(\"sex\")\ncombs = expand.grid(y = setdiff(colnames(d), \"sex\"), x = cnames)\ncombs$cor = apply(combs, 1, mycor, data = task$data()) # use the train set\ncombs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          y   x        cor\n1      time sex 0.12941337\n2    status sex 0.24343282\n3       age sex 0.12216709\n4      inst sex 0.07826337\n5  meal.cal sex 0.18389545\n6 pat.karno sex 0.04132443\n7   ph.ecog sex 0.02564987\n8  ph.karno sex 0.01702471\n9   wt.loss sex 0.13431983\n```\n:::\n:::\n\n\n`sex` doesn't correlate strongly with any other feature, so we can compute the PDP:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# create two datasets: one with males and one with females\n# all other features remain the same (use train data, 205 patients)\nd = task$data(rows = part$train) # `rows = part$test` to use the test set\n\nd$sex = 1\ntask_males = as_task_surv(d, time = 'time', event = 'status', id = 'lung-males')\nd$sex = 0\ntask_females = as_task_surv(d, time = 'time', event = 'status', id = 'lung-females')\n\n# make predictions\np_males   = learner$predict(task_males)\np_females = learner$predict(task_females)\n\n# take the median posterior survival probability\nsurv_males   = p_males$distr$survival(months) # patients x times\nsurv_females = p_females$distr$survival(months) # patients x times\n\n# tidy up data: average and quantiles across patients\ndata_males =\n  apply(surv_males, 1, function(row) {\n    tibble(\n      low = quantile(row, probs = 0.025),\n      avg = mean(row),\n      high = quantile(row, probs = 0.975)\n    )\n  }) %>%\n  bind_rows() %>%\n  add_column(sex = 'male', month = months, .before = 1)\n\ndata_females =\n  apply(surv_females, 1, function(row) {\n    tibble(\n      low = quantile(row, probs = 0.025),\n      avg = mean(row),\n      high = quantile(row, probs = 0.975)\n    )\n  }) %>%\n  bind_rows() %>%\n  add_column(sex = 'female', month = months, .before = 1)\n\npdp_tbl = bind_rows(data_males, data_females)\npdp_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 72 × 5\n   sex   month    low   avg  high\n   <chr> <int>  <dbl> <dbl> <dbl>\n 1 male      1 0.836  0.942 0.981\n 2 male      2 0.704  0.889 0.963\n 3 male      3 0.587  0.839 0.943\n 4 male      4 0.488  0.788 0.924\n 5 male      5 0.392  0.732 0.897\n 6 male      6 0.304  0.663 0.860\n 7 male      7 0.234  0.601 0.829\n 8 male      8 0.172  0.550 0.799\n 9 male      9 0.130  0.503 0.766\n10 male     10 0.0945 0.455 0.733\n# ℹ 62 more rows\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmy_colors = c(\"#E41A1C\", \"#4DAF4A\")\nnames(my_colors) = c('male', 'female')\n\npdp_tbl %>%\n  ggplot(aes(x = month, y = avg)) +\n  geom_step(aes(color = sex), linewidth = 1) +\n  xlab('Time (Months)') +\n  ylab('Survival Probability') +\n  geom_ribbon(aes(ymin = low, ymax = high, fill = sex), alpha = 0.2, show.legend = F) +\n  theme_bw(base_size = 14) +\n  scale_color_manual(values = my_colors) +\n  scale_fill_manual(values = my_colors)\n```\n\n::: {.cell-output-display}\n![Friedman’s partial dependence function with 95% prediction intervals: males vs females. Females show on average larger survival estimates compared to men, across all time points. Overlapping shaded area represents men and women that have similar survival characteristics.](index_files/figure-html/surv-pdp-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}