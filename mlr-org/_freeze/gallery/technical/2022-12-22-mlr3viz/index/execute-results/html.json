{
  "hash": "bc6f67e34bb25ccd42314d0f7c70be22",
  "result": {
    "markdown": "---\ntitle: \"Visualization in mlr3\"\ndescription: |\n  Quickly plot the mlr3 ecosystem.\ncategories:\n  - visualization\nauthor:\n  - name: Marc Becker\n    orcid: 0000-0002-8115-0400\n    url: https://github.com/be-marc\ndate: 2022-12-22\n---\n\n\n\n\n\n\n# Scope\n\nWe showcase the visualization functions of the mlr3 ecosystem.\nThe [mlr3viz](https://mlr3viz.mlr-org.com) package creates a plot for almost all mlr3 objects.\nThis post displays all available plots with their reproducible code.\nWe start with plots of the base mlr3 objects.\nThis includes boxplots of tasks, dendrograms of cluster learners and ROC curves of predictions.\nAfter that, we tune a classification tree and visualize the results.\nFinally, we show visualizations for filters.\n\n# Package\n\nThe [mlr3viz](https://mlr3viz.mlr-org.com) package defines `autoplot()` functions to draw plots with [ggplot2](https://cran.r-project.org/package=ggplot2).\nOften there is more than one type of plot for an object.\nYou can change the plot with the `type` argument.\nThe help pages list all possible choices.\nThe easiest way to access the help pages is via the [pkgdown website](https://mlr3viz.mlr-org.com/reference/index.html).\nThe plots use the [viridis](https://cran.r-project.org/package=viridis) color pallet and the appearance is controlled with the `theme` argument.\nBy default, the [`minimal theme`](https://www.rdocumentation.org/packages/ggpplot2/topics/theme_minimal) is applied.\n\n# Tasks\n\n## Classification\n\nWe begin with plots of the classification task [`Palmer Penguins`](https://mlr3.mlr-org.com/reference/mlr_tasks.html).\nWe plot the class frequency of the target variable.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlibrary(mlr3viz)\n\ntask = tsk(\"penguins\")\ntask$select(c(\"body_mass\", \"bill_length\"))\n\nautoplot(task, type = \"target\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-002-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"duo\"` plot shows the distribution of multiple features.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(task, type = \"duo\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-003-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"pairs\"` plot shows the pairwise comparison of multiple features.\nThe classes of the target variable are shown in different colors.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(task, type = \"pairs\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-004-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Regression\n\nNext, we plot the regression task [`mtcars`](https://mlr3.mlr-org.com/reference/mlr_tasks.html).\nWe create a boxplot of the target variable.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"mtcars\")\ntask$select(c(\"am\", \"carb\"))\n\nautoplot(task, type = \"target\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-005-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"pairs\"` plot shows the pairwise comparison of mutiple features and the target variable.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(task, type = \"pairs\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-006-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Cluster\n\nFinally, we plot the cluster task [`US Arrests`](https://mlr3.mlr-org.com/reference/mlr_tasks.html).\nThe `\"pairs\"` plot shows the pairwise comparison of mutiple features.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3cluster)\n\ntask = mlr_tasks$get(\"usarrests\")\n\nautoplot(task, type = \"pairs\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-007-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Learner\n\n## GLMNet\n\nThe [`classification`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.glmnet.html) and [`regression`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.glmnet.html)  GLMNet learner is equipped with a plot function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3data)\n\ntask = tsk(\"ilpd\")\ntask$select(setdiff(task$feature_names, \"gender\"))\nlearner = lrn(\"classif.glmnet\")\nlearner$train(task)\n\nautoplot(learner)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-008-1.png){fig-align='center' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"mtcars\")\nlearner = lrn(\"regr.glmnet\")\nlearner$train(task)\n\nautoplot(learner)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-009-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Rpart\n\nWe plot a [`classification tree`](https://mlr3.mlr-org.com/reference/mlr_learners_classif.rpart.html) of the [rpart](https://cran.r-project.org/package=rpart) package.\nWe have to fit the learner with `keep_model = TRUE` to keep the model object.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"penguins\")\nlearner = lrn(\"classif.rpart\", keep_model = TRUE)\nlearner$train(task)\n\nautoplot(learner)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-010-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe can also plot regression trees.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"mtcars\")\nlearner = lrn(\"regr.rpart\", keep_model = TRUE)\nlearner$train(task)\n\nautoplot(learner)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-011-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## ClustHierachical\n\nThe `\"dend\"` plot shows the result of the hierarchical clustering of the data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3cluster)\n\ntask = tsk(\"usarrests\")\nlearner = lrn(\"clust.hclust\")\nlearner$train(task)\n\nautoplot(learner, type = \"dend\", task = task)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-012-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"scree\"` type plots the number of clusters and the height.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(learner, type = \"scree\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-013-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Prediction\n\n## Classification\n\nWe plot the predictions of a classification learner.\nThe `\"stacked\"` plot shows the predicted and true class labels.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"spam\")\nlearner = lrn(\"classif.rpart\", predict_type = \"prob\")\npred = learner$train(task)$predict(task)\n\nautoplot(pred, type = \"stacked\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-014-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe ROC curve plots the true positive rate against the false positive rate at different thresholds.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(pred, type = \"roc\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-015-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\nThe precision-recall curve plots the precision against the recall at different thresholds.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(pred, type = \"prc\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-016-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"threshold\"` plot varies the threshold of a binary classification and plots against the resulting performance.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(pred, type = \"threshold\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-017-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Regression\n\nThe predictions of a regression learner are often presented as a scatterplot of truth and predicted response.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"boston_housing\")\nlearner = lrn(\"regr.rpart\")\npred = learner$train(task)$predict(task)\n\nautoplot(pred, type = \"xy\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-018-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAdditionally, we plot the response with the residuals.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(pred, type = \"residual\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-019-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe can also plot the distribution of the residuals.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(pred, type = \"histogram\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-020-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Cluster\n\nThe predictions of a cluster learner are often presented as a scatterplot of the data points colored by the cluster.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3cluster)\n\ntask = tsk(\"usarrests\")\nlearner = lrn(\"clust.kmeans\", centers = 3)\npred = learner$train(task)$predict(task)\n\nautoplot(pred, task, type = \"scatter\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-021-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"sil\"` plot shows the silhouette width of the clusters.\nThe dashed line is the mean silhouette width.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(pred, task, type = \"sil\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-022-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"pca\"` plot shows the first two principal components of the data colored by the cluster.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(pred, task, type = \"pca\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-023-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Resample Result\n\n## Classification\n\nThe `\"boxplot\"` shows the distribution of the performance measures.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"sonar\")\nlearner = lrn(\"classif.rpart\", predict_type = \"prob\")\nresampling = rsmp(\"cv\")\nrr = resample(task, learner, resampling)\n\nautoplot(rr, type = \"boxplot\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-024-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe can also plot the distribution of the performance measures as a \"`histogram`\".\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(rr, type = \"histogram\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-025-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe ROC curve plots the true positive rate against the false positive rate at different thresholds.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(rr, type = \"roc\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-026-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe precision-recall curve plots the precision against the recall at different thresholds.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(rr, type = \"prc\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-027-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"prediction\"` plot shows two features and the predicted class in the background.\nPoints mark the observations of the test set and the color presents the truth.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"pima\")\ntask$filter(seq(100))\ntask$select(c(\"age\", \"glucose\"))\nlearner = lrn(\"classif.rpart\")\nresampling = rsmp(\"cv\", folds = 3)\nrr = resample(task, learner, resampling, store_models = TRUE)\n\nautoplot(rr, type = \"prediction\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-028-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAlternatively, we can plot class probabilities.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"pima\")\ntask$filter(seq(100))\ntask$select(c(\"age\", \"glucose\"))\nlearner = lrn(\"classif.rpart\", predict_type = \"prob\")\nresampling = rsmp(\"cv\", folds = 3)\nrr = resample(task, learner, resampling, store_models = TRUE)\n\nautoplot(rr, type = \"prediction\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-029-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nIn addition to the test set, we can also plot the train set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"pima\")\ntask$filter(seq(100))\ntask$select(c(\"age\", \"glucose\"))\nlearner = lrn(\"classif.rpart\", predict_type = \"prob\", predict_sets = c(\"train\", \"test\"))\nresampling = rsmp(\"cv\", folds = 3)\nrr = resample(task, learner, resampling, store_models = TRUE)\n\nautoplot(rr, type = \"prediction\", predict_sets = c(\"train\", \"test\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-030-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"prediction\"` plot can also show categorical features.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"german_credit\")\ntask$filter(seq(100))\ntask$select(c(\"housing\", \"employment_duration\"))\nlearner = lrn(\"classif.rpart\")\nresampling = rsmp(\"cv\", folds = 3)\nrr = resample(task, learner, resampling, store_models = TRUE)\n\nautoplot(rr, type = \"prediction\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-031-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Regression\n\nThe \"`prediction`\" plot shows one feature and the response.\nPoints mark the observations of the test set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"boston_housing\")\ntask$select(\"age\")\ntask$filter(seq(100))\nlearner = lrn(\"regr.rpart\")\nresampling = rsmp(\"cv\", folds  = 3)\nrr = resample(task, learner, resampling, store_models = TRUE)\n\nautoplot(rr, type = \"prediction\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-032-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAdditionally, we can add confidence bounds.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"boston_housing\")\ntask$select(\"age\")\ntask$filter(seq(100))\nlearner = lrn(\"regr.lm\", predict_type = \"se\")\nresampling = rsmp(\"cv\", folds  = 3)\nrr = resample(task, learner, resampling, store_models = TRUE)\n\nautoplot(rr, type = \"prediction\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-033-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAnd add the train set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"boston_housing\")\ntask$select(\"age\")\ntask$filter(seq(100))\nlearner = lrn(\"regr.lm\", predict_type = \"se\", predict_sets = c(\"train\", \"test\"))\nresampling = rsmp(\"cv\", folds = 3)\nrr = resample(task, learner, resampling, store_models = TRUE)\n\nautoplot(rr, type = \"prediction\", predict_sets = c(\"train\", \"test\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-034-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe can also add the prediction surface to the background.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = tsk(\"boston_housing\")\ntask$select(c(\"age\", \"rm\"))\ntask$filter(seq(100))\nlearner = lrn(\"regr.rpart\")\nresampling = rsmp(\"cv\", folds = 3)\nrr = resample(task, learner, resampling, store_models = TRUE)\n\nautoplot(rr, type = \"prediction\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-035-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Benchmark Result\n\nWe show the performance distribution of a benchmark with multiple tasks.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntasks = tsks(c(\"pima\", \"sonar\"))\nlearner = lrns(c(\"classif.featureless\", \"classif.rpart\", \"classif.xgboost\"), predict_type = \"prob\")\nresampling = rsmps(\"cv\")\nbmr = benchmark(benchmark_grid(tasks, learner, resampling))\n\nautoplot(bmr, type = \"boxplot\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-036-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe plot a benchmark result with one task and multiple learners.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntasks = tsk(\"pima\")\nlearner = lrns(c(\"classif.featureless\", \"classif.rpart\", \"classif.xgboost\"), predict_type = \"prob\")\nresampling = rsmps(\"cv\")\nbmr = benchmark(benchmark_grid(tasks, learner, resampling))\n```\n:::\n\n\nWe plot an roc curve for each learner.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(bmr, type = \"roc\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-038-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAlternatively, we can plot precision-recall curves.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(bmr, type = \"prc\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-039-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Tuning Instance\n\nWe tune the hyperparameters of a decision tree on the sonar task.\nThe `\"performance\"` plot shows the performance over batches.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3tuning)\nlibrary(mlr3tuningspaces)\nlibrary(mlr3learners)\n\ninstance = tune(\n  tuner = tnr(\"gensa\"),\n  task = tsk(\"sonar\"),\n  learner = lts(lrn(\"classif.rpart\")),\n  resampling = rsmp(\"holdout\"),\n  measures = msr(\"classif.ce\"),\n  term_evals = 100\n)\n\nautoplot(instance, type = \"performance\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-040-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\nThe `\"parameter\"` plot shows the performance for each hyperparameter setting.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(instance, type = \"parameter\", cols_x = c(\"cp\", \"minsplit\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-042-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"marginal\"` plot shows the performance of different hyperparameter values.\nThe color indicates the batch.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(instance, type = \"marginal\", cols_x = \"cp\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-043-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe `\"parallel\"` plot visualizes the relationship of hyperparameters.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(instance, type = \"parallel\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-044-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe plot `cp` against `minsplit` and color the points by the performance.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(instance, type = \"points\", cols_x = c(\"cp\", \"minsplit\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-045-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nNext, we plot all hyperparameters against each other.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(instance, type = \"pairs\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-046-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe plot the performance surface of two hyperparameters.\nThe surface is interpolated with a learner.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(instance, type = \"surface\", cols_x = c(\"cp\", \"minsplit\"), learner = mlr3::lrn(\"regr.ranger\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-047-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Filter\n\nWe plot filter scores for the mtcars task.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3filters)\n\ntask = tsk(\"mtcars\")\nf = flt(\"correlation\")\nf$calculate(task)\n\nautoplot(f, n = 5)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2022-12-22-mlr3viz-048-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Conclusion\n\nThe [mlr3viz](https://mlr3viz.mlr-org.com) package brings together the visualization functions of the mlr3 ecosystem.\nAll plots are drawn with the `autoplot()` function and the appearance can be customized with the `theme` argument.\nIf you need to highly customize a plot e.g. for a publication, we encourage you to check our code on [GitHub](https://github.com/mlr-org/mlr3viz).\nThe code should be easily adaptable to your needs.\nWe are also looking forward to new visualizations.\nYou can suggest new plots in an issue on [GitHub](https://github.com/mlr-org/mlr3viz/issues).\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}