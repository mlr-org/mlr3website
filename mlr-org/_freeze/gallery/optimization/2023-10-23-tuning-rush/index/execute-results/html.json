{
  "hash": "6903957968d0dbf2a0e3b8adb5703894",
  "result": {
    "markdown": "---\ntitle: \"Tuning with the Rush Package\"\ndescription: |\n  Efficient tuning with the parallel computing package rush.\ncategories:\n  - feature selection\n  - classification\nauthor:\n  - name: Marc Becker\n    url: https://github.com/be-marc\ndate: 2023-10-23\nbibliography: ../../bibliography.bib\nknitr:\n  opts_chunk:\n    R.options:\n      datatable.print.nrows: 12\n---\n\n\n\n\n\n\n\n# Scope\n\nParallel processing is a powerful tool to speed up the tuning of machine learning algorithms.\nSo far, [`mlr3tuning`](https://mlr3tuning.mlr-org.com/reference/mlr3tuning-package.html) has taken the approach\n\n\nthat the tuner proposes a batch of hyperparameter configurations, which are then evaluated in parallel with [`benchmark()`](https://mlr3.mlr-org.com/reference/benchmark.html).\nThe benchmark function uses the [future](https://cran.r-project.org/package=future) package to evaluate the configurations in parallel on different workers.\nHowever, this kind of parallelization excludes some novel optimization algorithms and does not improve the runtime performance in all situations as expected.\nIf the runtime of the configurations is heterogeneous, the system may wait for the last configuration to finish, while the other workers are idle.\nThis is referred to as synchronization overhead and can reduce the runtime performance of the tuner drastically.\nThis blocking behavior also excludes newer algorithms that want to react immediately to a single evaluated configuration.\nWe address these issues with the [rush](https://cran.r-project.org/package=rush) package.\nThe package implements a non-blocking parallelization strategy that is based on a [Redis](https://redis.io/) server.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nremotes::install_github(c(\n  \"mlr-org/mlr3@hotstart_time\",\n  \"mlr-org/rush\",\n  \"mlr-org/bbotk@rush\",\n  \"mlr-org/mlr3tuning@rush\"))\n```\n:::\n\n\n\n# Batch Parallelization\n\nThe current strategy of [mlr3tuning](https://mlr3tuning.mlr-org.com) parallelizes the evaluation of hyperparameter configurations.\nThe tuner proposes a batch of configurations, which are then evaluated in parallel with [`benchmark()`](https://mlr3.mlr-org.com/reference/benchmark.html).\nThe process waits until all configurations are evaluated and then continues with the next batch.\nThis approach has several disadvantages.\nThe [`benchmark()`](https://mlr3.mlr-org.com/reference/benchmark.html) function uses the [future](https://cran.r-project.org/package=future) package to evaluate the configurations in parallel on different workers.\nThe [future](https://cran.r-project.org/package=future) package has to serialize the learner, task and resampling in each tuning iteration.\nThis adds a significant overhead to each tuning iteration especially if the runtime of the configurations is short.\n\nAnother problem is that the tuning process is blocked until the last configuration of a batch is evaluated.\nThis is especially problematic if the runtime of the configurations is heterogeneous.\nWhile the system waits for the last configuration to finish, the other workers are idle.\nThis is referred to as synchronization overhead and can reduce the runtime performance of the tuner drastically.\n\nThe chunk size determines how many configurations are evaluated in a single future.\nDeciding the appropriate chunk size is difficult.\nIf the chunk size is too small, the overhead of creating the futures is too high.\nA chunk size of 1 creates a new future for each configuration.\nIf the chunk size is too large and the runtimes are heterogeneous, the risk that many workers idle increases.\n\nBlocking the process also prevents the implementation of some novel optimization algorithms.\nFor example, the asynchronous successive halving algorithm reacts immediately to the evaluation of a single configuration.\nWaiting for the last configuration to finish would make the algorithm inefficient.\n\nWe have also observed that the main process is quickly overloaded when a large number of fast-fitting models are evaluated.\nThis makes it necessary to subdivide batches even further.\n\n\n::: {#fig-sleep-benchmark .cell layout-ncol=\"1\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Benchmark with 300 resampling iterations on 3 workers.](index_files/figure-html/fig-sleep-benchmark-1.png){#fig-sleep-benchmark-1 fig-align='center' width=672}\n:::\n\n::: {.cell-output-display}\n![Benchmark with 3000 resampling iterations on 30 Workers.](index_files/figure-html/fig-sleep-benchmark-2.png){#fig-sleep-benchmark-2 fig-align='center' width=672}\n:::\n\nRuntime of a random search in seconds depending on batch size and chunk size for different training times. The first three runs use a constant training time of 10 ms, 100 ms and 1 second. The last three runs use a homogenous training time ranging from 10 ms to 10 seconds. Rush does not have a batch size and chunk size parameter.\n:::\n\n\n# Rush Parallelization\n\nThe parallelization with rush takes a different approach.\nAt the beginning of the tuning process, a future is started on each available worker.\nThe future contains a loop that evaluates configurations from a queue.\nThe future only stops when the tuning is finished.\nThis minimizes the overhead of serializing the learner, task and resampling.\n\nThe tuner proposes one or more configurations and sends them to a queue.\nThis process is non-blocking and the tuner can react immediately to the evaluation of a single configuration.\nThe overhead per configuration is in the range of 1 to 2 milliseconds.\n\n\n![](flow.png)\n\n\n# Rush Examples\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(rush)\nlibrary(mlr3tuning)\n\nrush = rsh(network_id = \"mlr3tuning\")\nrush\n```\n:::\n\n\nThe `ti()` function returns a `TuningInstanceRushSingleCrit` instead of a `TuningInstanceSingleCrit` when a `rush` controller is passed.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance = ti(\n  task = tsk(\"pima\"),\n  learner = lrn(\"classif.rpart\", cp = to_tune(0.01, 0.1), minsplit = to_tune(1, 100)),\n  resampling = rsmp(\"cv\", folds = 3),\n  measure = msr(\"classif.ce\"),\n  terminator = trm(\"evals\", n_evals = 100),\n  rush = rush\n)\n```\n:::\n\n\nThe new instance has a new method `$start_workers()` to start the workers.\nThe `await_workers` argument determines if the main process waits until all workers are ready.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfuture::plan(\"multisession\", workers = 2L)\n\ninstance$start_workers(await_workers = TRUE)\nrush\n```\n:::\n\n\nThe tuner classes of `mlr3tuning` are extended to support rush.\nJust use the tuners as normal.\nInternally a slightly different algorithm is used when parallelizing with rush.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntuner = tnr(\"random_search\")\n```\n:::\n\n\nThe optimization is started as always with the `$optimize()` method.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntuner$optimize(instance)\n```\n:::\n\n\n\nHow does rush work?\n\n* The overhead of creating futures in tuning iteration is eliminated. The workers run permanently and wait for new configurations.\n* The tuning process is not blocked by the slowest configuration. The workers can immediately start with the next configuration.\n\n## Supported Tuners\n\nCurrently, the tuners random search, grid search and design points from `mlr3tuning` are supported.\nDepending on the scenario, small runtime performance improvements can be seen here.\nThe `mlr3hyperband` package adds asynchronous successive halving and hyperband to the list of supported tuners.\nThese tuners especially benefit from parallelization with rush.\nThe batch parallelization was always a major bottleneck for tuners of the hyperband family.\n\n## Terminators\n\nIf the tuning was running on a system with time constraints e.g. a high-performance cluster, it was difficult to finish the tuning in time with long-running models.\nSince the process was blocked until the last configuration was evaluated, the tuning could not be stopped immediately.\nTo prevent long-running models from threatening the whole tuning, a time limit had to be set on the training.\nToo large batches also endangered the correct completion of the tuning.\nWith rush, these problems no longer exist.\nThe terminators are much more precise with rush since the termination criterion is constantly checked.\nLearners that train far beyond the time limit and thus do not deliver a result are simply ignored when evaluating the tuning.\n\n## Local Worker\n\nA local worker runs on the same machine as the main tuning process.\nWe recommend using the `future` package with the `multisession` backend to spawn local workers.\n\n## Remote Worker\n\nA remote worker runs on a different machine than the main tuning process.\nRemote workers can be started with `future` or manually with a bash script.\nThere is no restriction for the system on which the manually started worker runs. It must only be possible to establish a connection to the Redis server in the main process.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance$create_worker_script()\n```\n:::\n\n\n## Reproducibility\n\nReproducibility can't be guaranteed with rush.\nIf multiple workers are used, the order in which the configurations are evaluated and finished is non-deterministic.\nWe recommend running the tuning on a single worker if reproducibility is important.\n\n## Logging\n\nThe logging on the workers is not synchronized with the main process.\nThis means that the logging messages of the workers are not displayed in the console.\nThe logging messages are stored in the Redis database and can be retrieved with the `read_log()` function.\nThis is useful for debugging purposes.\nTo activate the logging on the workers, the `lgr_thresholds`  must be set when the workers are started.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstanceh$start_workers(\n  lgr_thresholds = c(mlr3 = \"info\", bbotk = \"warn\", rush = \"warn\"))\n```\n:::\n\n\nThis example sets the logging threshold of the `mlr3` package to `info` and the logging threshold of the `bbotk` and `rush` package to `warn`.\nSee the chapter on [logging](https://mlr3book.mlr-org.com/chapters/chapter10/advanced_technical_aspects_of_mlr3.html#sec-logging) for details on logging in `mlr3`.\nTo retrieve the logging messages, the `read_log()` function of the rush controller must be called.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrush$read_log()\n```\n:::\n\n\n## Heartbeat\n\nThe [encapsulation](https://mlr3book.mlr-org.com/chapters/chapter10/advanced_technical_aspects_of_mlr3.html#sec-encapsulation) mechanism of `mlr3` guards the tuning against segmentation faults and simple errors.\nA heartbeat process gives additional safety when the tuning runs on remote workers.\nThe heartbeat is a mechanism to detect if a remote worker has crashed, was killed or lost the connection to the main process.\nIf a worker is lost, the evaluation of a hyperparameter configuration seems to run forever.\nThe heartbeat process periodically signals that the worker is still alive.\nIf the heartbeat is not received for a certain time, the worker is considered lost.\nThe option `detect_lost_tasks` of the `$start_workers()` function activates the detection of lost evaluations via the heartbeat.\nThe heartbeat is enabled by passing `heartbeat_period` and  `heartbeat_expire` when starting the workers.\nThe `heartbeat_period` is the time in seconds between two heartbeats.\nThe `heartbeat_expire` defines the time in seconds after which a worker is considered lost.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstanceh$start_workers(\n  heartbeat_period = 1,\n  heartbeat_expire = 3,\n  detect_lost_tasks = TRUE)\n```\n:::\n\n\nIn this example, the heartbeat process sends a heartbeat every second.\nIf the heartbeat is not received for three seconds, the worker is considered lost.\nThe tuning process marks the corresponding evaluations as failed.\nThe heartbeat is a separate process that runs on each worker.\nRunning the process adds a small overhead to the worker.\n\n# Hotstarting\n\nThe hotstart mechanism of mlr3 can now finally be used effectively in tuning.\n\n\n# Questions\n\nHow to implement seeds?\nHow to implement auto tuner? When call `start_workers()`? Set start options before?\nCheck hotstart stacks.\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}