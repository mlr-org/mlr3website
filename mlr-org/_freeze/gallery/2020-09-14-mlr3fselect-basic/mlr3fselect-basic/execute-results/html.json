{
  "hash": "1697856496008aa4f0578e372bd6361e",
  "result": {
    "markdown": "---\ntitle: Feature Selection on the Titanic Data Set\ncategories:\n  - feature selection\n  - resampling\n  - classification\ndescription: |\n  Short introduction to feature selection with mlr3fselect.\nauthor:\n  - name: Marc Becker\ndate: 01-08-2021\nimage: ../../images/logo_color.png\n---\n\n\n\n\n## Introduction\n\nIn this tutorial, we introduce the [mlr3fselect](https://mlr3fselect.mlr-org.com) package by comparing feature selection methods on the Titanic disaster data set.\nThe objective of feature selection is to enhance the interpretability of models, speed up the learning process and increase the predictive performance.\n\nWe load the [mlr3verse](https://mlr3verse.mlr-org.com) package which pulls in the most important packages for this example.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlibrary(mlr3fselect)\n```\n:::\n\n\nWe initialize the random number generator with a fixed seed for reproducibility, and decrease the verbosity of the logger to keep the output clearly represented.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(7832)\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\nlgr::get_logger(\"bbotk\")$set_threshold(\"warn\")\n```\n:::\n\n\n## Titanic Data Set\n\nThe [Titanic data set](https://www.kaggle.com/c/titanic/data) contains data for 887 Titanic passengers, including whether they survived when the Titanic sank.\nOur goal will be to predict the survival of the Titanic passengers.\n\nAfter loading the data set from the [mlr3data](https://mlr3data.mlr-org.com) package, we impute the missing age values with the median age of the passengers, set missing embarked values to `\"s\"` and remove `character` features.\nWe could use feature engineering to create new features from the `character` features, however we want to focus on feature selection in this tutorial.\n\nIn addition to the `survived` column, the reduced data set contains the following attributes for each passenger:\n\n| Feature    | Description                         |\n|------------|-------------------------------------|\n| `age`      | Age                                 |\n| `sex`      | Sex                                 |\n| `sib_sp`   | Number of siblings / spouses aboard |\n| `parch`    | Number of parents / children aboard |\n| `fare`     | Amount paid for the ticket          |\n| `pc_class` | Passenger class                     |\n| `embarked` | Port of embarkation                 |\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3data)\n\ndata(\"titanic\", package = \"mlr3data\")\ntitanic$age[is.na(titanic$age)] = median(titanic$age, na.rm = TRUE)\ntitanic$embarked[is.na(titanic$embarked)] = \"S\"\ntitanic$ticket = NULL\ntitanic$name = NULL\ntitanic$cabin = NULL\ntitanic = titanic[!is.na(titanic$survived),]\n```\n:::\n\n\nWe construct a binary classification task.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask = as_task_classif(titanic, target = \"survived\", positive = \"yes\")\n```\n:::\n\n\n## Model\n\nWe use the logistic regression learner provided by the [mlr3learners](https://mlr3learners.mlr-org.com) package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3learners)\n\nlearner = lrn(\"classif.log_reg\")\n```\n:::\n\n\nTo evaluate the predictive performance, we choose a 3-fold cross-validation and the classification error as the measure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresampling = rsmp(\"cv\", folds = 3)\nmeasure = msr(\"classif.ce\")\n\nresampling$instantiate(task)\n```\n:::\n\n\n## Classes\n\nThe [`FSelectInstanceSingleCrit`](https://mlr3fselect.mlr-org.com/reference/FSelectInstanceSingleCrit.html) class specifies a general feature selection scenario.\nIt includes the [`ObjectiveFSelect`](https://mlr3fselect.mlr-org.com/reference/ObjectiveFSelect.html) object that encodes the black box objective function which is optimized by a feature selection algorithm.\nThe evaluated feature sets are stored in an [`ArchiveFSelect`](https://mlr3fselect.mlr-org.com/reference/ArchiveFSelect.html) object.\nThe archive provides a method for querying the best performing feature set.\n\nThe [`Terminator`](https://bbotk.mlr-org.com/reference/Terminator.html) classes determine when to stop the feature selection.\nIn this example we choose a terminator that stops the feature selection after 10 seconds.\nThe sugar functions [`trm()`](https://bbotk.mlr-org.com/reference/trm.html) and [`trms()`](https://bbotk.mlr-org.com/reference/trm.html) can be used to retrieve terminators from the [`mlr_terminators`](https://bbotk.mlr-org.com/reference/mlr_terminators.html) dictionary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nterminator = trm(\"run_time\", secs = 10)\nFSelectInstanceSingleCrit$new(\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measure = measure,\n  terminator = terminator)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<FSelectInstanceSingleCrit>\n* State:  Not optimized\n* Objective: <ObjectiveFSelect:classif.log_reg_on_titanic>\n* Search Space:\n         id    class lower upper nlevels\n1:      age ParamLgl    NA    NA       2\n2: embarked ParamLgl    NA    NA       2\n3:     fare ParamLgl    NA    NA       2\n4:    parch ParamLgl    NA    NA       2\n5:   pclass ParamLgl    NA    NA       2\n6:      sex ParamLgl    NA    NA       2\n7:   sib_sp ParamLgl    NA    NA       2\n* Terminator: <TerminatorRunTime>\n```\n:::\n:::\n\n\nThe [`FSelector`](https://mlr3fselect.mlr-org.com/reference/FSelector.html) subclasses describe the feature selection strategy. The sugar function [`fs()`](https://mlr3fselect.mlr-org.com/reference/fs.html) can be used to retrieve feature selection algorithms from the [`mlr_fselectors`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors.html) dictionary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_fselectors\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<DictionaryFSelector> with 7 stored values\nKeys: design_points, exhaustive_search, genetic_search, random_search, rfe, sequential,\n  shadow_variable_search\n```\n:::\n:::\n\n\n## Random search\n\nRandom search randomly draws feature sets and evaluates them in batches.\nWe retrieve the [`FSelectorRandomSearch`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_random_search.html) class with the [`fs()`](https://mlr3fselect.mlr-org.com/reference/fs.html) sugar function and choose [`TerminatorEvals`](https://bbotk.mlr-org.com/reference/mlr_terminators_evals.html).\nWe set the `n_evals` parameter to `10` which means that 10 feature sets are evaluated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nterminator = trm(\"evals\", n_evals = 10)\ninstance = FSelectInstanceSingleCrit$new(\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measure = measure,\n  terminator = terminator)\nfselector = fs(\"random_search\", batch_size = 5)\n```\n:::\n\n\nThe feature selection is started by passing the [`FSelectInstanceSingleCrit`](https://mlr3fselect.mlr-org.com/reference/FSelectInstanceSingleCrit.html) object to the `$optimize()` method of [`FSelectorRandomSearch`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_random_search.html) which generates the feature sets.\nThese features set are internally passed to the `$eval_batch()` method of [`FSelectInstanceSingleCrit`](https://mlr3fselect.mlr-org.com/reference/FSelectInstanceSingleCrit.html) which evaluates them with the objective function and stores the results in the archive.\nThis general interaction between the objects of **mlr3fselect** stays the same for the different feature selection methods.\nHowever, the way how new feature sets are generated differs depending on the chosen [`FSelector`](https://mlr3fselect.mlr-org.com/reference/FSelector.html) subclass.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfselector$optimize(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    age embarked fare parch pclass  sex sib_sp                         features classif.ce\n1: TRUE    FALSE TRUE  TRUE   TRUE TRUE   TRUE age,fare,parch,pclass,sex,sib_sp  0.2020202\n```\n:::\n:::\n\n\nThe [`ArchiveFSelect`](https://mlr3fselect.mlr-org.com/reference/ArchiveFSelect.html) stores a `data.table::data.table()` which consists of the evaluated feature sets and the corresponding estimated predictive performances.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.data.table(instance$archive)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"table-responsive\"><table class = 'table'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> age </th>\n   <th style=\"text-align:left;\"> embarked </th>\n   <th style=\"text-align:left;\"> fare </th>\n   <th style=\"text-align:left;\"> parch </th>\n   <th style=\"text-align:left;\"> pclass </th>\n   <th style=\"text-align:left;\"> sex </th>\n   <th style=\"text-align:left;\"> sib_sp </th>\n   <th style=\"text-align:right;\"> classif.ce </th>\n   <th style=\"text-align:left;\"> timestamp </th>\n   <th style=\"text-align:right;\"> batch_nr </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:right;\"> 0.2031425 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:55 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:right;\"> 0.3838384 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:55 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:right;\"> 0.3804714 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:55 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:right;\"> 0.3288440 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:55 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:right;\"> 0.2188552 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:55 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:right;\"> 0.3209877 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:56 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:right;\"> 0.3838384 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:56 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:right;\"> 0.2020202 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:56 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:right;\"> 0.2031425 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:56 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:right;\"> 0.3389450 </td>\n   <td style=\"text-align:left;\"> 2022-11-08 16:37:56 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n  </tr>\n</tbody>\n</table></div>\n```\n:::\n:::\n\n\nThe associated resampling iterations can be accessed in the [`BenchmarkResult`](https://mlr3.mlr-org.com/reference/BenchmarkResult.html) by calling\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstance$archive$benchmark_result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<BenchmarkResult> of 30 rows with 10 resampling runs\n nr task_id             learner_id resampling_id iters warnings errors\n  1 titanic select.classif.log_reg            cv     3        0      0\n  2 titanic select.classif.log_reg            cv     3        0      0\n  3 titanic select.classif.log_reg            cv     3        0      0\n  4 titanic select.classif.log_reg            cv     3        0      0\n  5 titanic select.classif.log_reg            cv     3        0      0\n  6 titanic select.classif.log_reg            cv     3        0      0\n  7 titanic select.classif.log_reg            cv     3        0      0\n  8 titanic select.classif.log_reg            cv     3        0      0\n  9 titanic select.classif.log_reg            cv     3        0      0\n 10 titanic select.classif.log_reg            cv     3        0      0\n```\n:::\n:::\n\n\nWe retrieve the best performing feature set with\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstance$result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    age embarked fare parch pclass  sex sib_sp                         features classif.ce\n1: TRUE    FALSE TRUE  TRUE   TRUE TRUE   TRUE age,fare,parch,pclass,sex,sib_sp  0.2020202\n```\n:::\n:::\n\n\n## Sequential forward selection\n\nWe try sequential forward selection. We chose [`TerminatorStagnation`](https://bbotk.mlr-org.com/reference/mlr_terminators_stagnation.html) that stops the feature selection if the predictive performance does not increase anymore.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nterminator = trm(\"stagnation\", iters = 5)\ninstance = FSelectInstanceSingleCrit$new(\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measure = measure,\n  terminator = terminator)\n\nfselector = fs(\"sequential\")\nfselector$optimize(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     age embarked  fare parch pclass  sex sib_sp                features classif.ce\n1: FALSE    FALSE FALSE  TRUE   TRUE TRUE   TRUE parch,pclass,sex,sib_sp  0.1964085\n```\n:::\n:::\n\n\nThe [`FSelectorSequential`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_sequential.html) object has a special method for displaying the optimization path of the sequential feature selection.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfselector$optimization_path(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    age embarked  fare parch pclass   sex sib_sp classif.ce batch_nr\n1: TRUE    FALSE FALSE FALSE  FALSE FALSE  FALSE  0.3838384        1\n2: TRUE    FALSE FALSE FALSE  FALSE  TRUE  FALSE  0.2132435        2\n3: TRUE    FALSE FALSE FALSE  FALSE  TRUE   TRUE  0.2087542        3\n4: TRUE    FALSE FALSE FALSE   TRUE  TRUE   TRUE  0.2143659        4\n5: TRUE    FALSE FALSE  TRUE   TRUE  TRUE   TRUE  0.2065095        5\n6: TRUE    FALSE  TRUE  TRUE   TRUE  TRUE   TRUE  0.2020202        6\n```\n:::\n:::\n\n\n## Recursive feature elimination\n\nRecursive feature elimination utilizes the `$importance()` method of learners.\nIn each iteration the feature(s) with the lowest importance score is dropped.\nWe choose the non-recursive algorithm (`recursive = FALSE`) which calculates the feature importance once on the complete feature set.\nThe recursive version (`recursive = TRUE`) recomputes the feature importance on the reduced feature set in every iteration.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.ranger\", importance = \"impurity\")\nterminator = trm(\"none\")\ninstance = FSelectInstanceSingleCrit$new(\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measure = measure,\n  terminator = terminator,\n  store_models = TRUE)\n\nfselector = fs(\"rfe\", recursive = FALSE)\nfselector$optimize(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    age embarked fare parch pclass  sex sib_sp                               features classif.ce\n1: TRUE     TRUE TRUE  TRUE   TRUE TRUE   TRUE age,embarked,fare,parch,pclass,sex,...  0.1694725\n```\n:::\n:::\n\n\nWe access the results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.data.table(instance$archive, exclude_columns = c(\"runtime_learners\", \"timestamp\", \"batch_nr\", \"resample_result\", \"uhash\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"table-responsive\"><table class = 'table'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> age </th>\n   <th style=\"text-align:left;\"> embarked </th>\n   <th style=\"text-align:left;\"> fare </th>\n   <th style=\"text-align:left;\"> parch </th>\n   <th style=\"text-align:left;\"> pclass </th>\n   <th style=\"text-align:left;\"> sex </th>\n   <th style=\"text-align:left;\"> sib_sp </th>\n   <th style=\"text-align:right;\"> classif.ce </th>\n   <th style=\"text-align:left;\"> importance </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:right;\"> 0.1694725 </td>\n   <td style=\"text-align:left;\"> 68.711046, 45.345443, 37.314977, 22.890378, 11.733529, 9.171937, 8.422415 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:right;\"> 0.2143659 </td>\n   <td style=\"text-align:left;\"> 68.71105, 45.34544, 37.31498 </td>\n  </tr>\n</tbody>\n</table></div>\n```\n:::\n:::\n\n\n## Nested resampling\n\nIt is a common mistake to report the predictive performance estimated on resampling sets during the feature selection as the performance that can be expected from the combined feature selection and model training.\nThe repeated evaluation of the model might leak information about the test sets into the model and thus leads to over-fitting and over-optimistic performance results.\n[Nested resampling](https://mlr3book.mlr-org.com/nested-resampling.html) uses an outer and inner resampling to separate the feature selection from the performance estimation of the model.\nWe can use the [`AutoFSelector`](https://mlr3fselect.mlr-org.com/reference/AutoFSelector.html) class for running nested resampling.\nThe [`AutoFSelector`](https://mlr3fselect.mlr-org.com/reference/AutoFSelector.html) essentially combines a given [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) and feature selection method into a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) with internal automatic feature selection.\nThe inner resampling loop that is used to determine the best feature set is conducted internally each time the [`AutoFSelector`](https://mlr3fselect.mlr-org.com/reference/AutoFSelector.html) [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) object is trained.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresampling_inner = rsmp(\"cv\", folds = 5)\nmeasure = msr(\"classif.ce\")\n\nat = AutoFSelector$new(\n  learner = learner,\n  resampling = resampling_inner,\n  measure = measure,\n  terminator = terminator,\n  fselect = fs(\"sequential\"),\n  store_models = TRUE)\n```\n:::\n\n\nWe put the [`AutoFSelector`](https://mlr3fselect.mlr-org.com/reference/AutoFSelector.html) into a [`resample()`](https://mlr3.mlr-org.com/reference/resample.html) call to get the outer resampling loop.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresampling_outer = rsmp(\"cv\", folds = 3)\n\nrr = resample(task, at, resampling_outer, store_models = TRUE)\n```\n:::\n\n\nThe aggregated performance of all outer resampling iterations is the unbiased predictive performance we can expected from the logistic regression model with an optimized feature set found by sequential selection.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr$aggregate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n 0.1907969 \n```\n:::\n:::\n\n\nWe check whether the feature sets that were selected in the inner resampling are stable.\nThe selected feature sets should not differ too much.\nWe might observe unstable models in this example because the small data set and the low number of resampling iterations might introduces too much randomness.\nUsually, we aim for the selection of similar feature sets for all outer training sets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_inner_fselect_results(rr)\n```\n:::\n\n::: {.cell .column-page}\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-cb26bfeaa12c69f0dcb1\" style=\"width:100%;height:auto;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-cb26bfeaa12c69f0dcb1\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\"],[1,2,3],[true,true,true],[false,true,true],[true,true,false],[false,true,false],[true,true,true],[true,true,true],[true,false,false],[0.138000284859707,0.161529696624412,0.190343255946446],[[\"age\",\"fare\",\"pclass\",\"sex\",\"sib_sp\"],[\"age\",\"embarked\",\"fare\",\"parch\",\"pclass\",\"sex\"],[\"age\",\"embarked\",\"pclass\",\"sex\"]],[\"titanic\",\"titanic\",\"titanic\"],[\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\"],[\"cv\",\"cv\",\"cv\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>iteration<\\/th>\\n      <th>age<\\/th>\\n      <th>embarked<\\/th>\\n      <th>fare<\\/th>\\n      <th>parch<\\/th>\\n      <th>pclass<\\/th>\\n      <th>sex<\\/th>\\n      <th>sib_sp<\\/th>\\n      <th>classif.ce<\\/th>\\n      <th>features<\\/th>\\n      <th>task_id<\\/th>\\n      <th>learner_id<\\/th>\\n      <th>resampling_id<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,9]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nNext, we want to compare the predictive performances estimated on the outer resampling to the inner resampling.\nSignificantly lower predictive performances on the outer resampling indicate that the models with the optimized feature sets overfit the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr$score()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"table-responsive\"><table class = 'table'>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> iteration </th>\n   <th style=\"text-align:left;\"> task_id </th>\n   <th style=\"text-align:left;\"> learner_id </th>\n   <th style=\"text-align:left;\"> resampling_id </th>\n   <th style=\"text-align:right;\"> classif.ce </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> titanic </td>\n   <td style=\"text-align:left;\"> classif.ranger.fselector </td>\n   <td style=\"text-align:left;\"> cv </td>\n   <td style=\"text-align:right;\"> 0.2222222 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> titanic </td>\n   <td style=\"text-align:left;\"> classif.ranger.fselector </td>\n   <td style=\"text-align:left;\"> cv </td>\n   <td style=\"text-align:right;\"> 0.1750842 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:left;\"> titanic </td>\n   <td style=\"text-align:left;\"> classif.ranger.fselector </td>\n   <td style=\"text-align:left;\"> cv </td>\n   <td style=\"text-align:right;\"> 0.1750842 </td>\n  </tr>\n</tbody>\n</table></div>\n```\n:::\n:::\n\n\nThe archives of the [`AutoFSelector`](https://mlr3fselect.mlr-org.com/reference/AutoFSelector.html)s gives us all evaluated feature sets with the associated predictive performances.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_inner_fselect_archives(rr)\n```\n:::\n\n::: {.cell .column-page}\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-f1be6551176295e88111\" style=\"width:100%;height:auto;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-f1be6551176295e88111\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\"],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3],[true,false,false,false,false,false,false,true,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,true,false,false,false,false,false,true,false,false,false,false,true,false,false,false,true,false,false,true,true,true,true,false,false,false,false,false,false,true,false,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true],[false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,false,false,false,true,false,false,false,true,false,false,true,false,true,false,true,false,false,false,false,false,false,true,false,false,false,false,false,true,false,false,false,false,true,false,false,false,true,false,true,false,true,false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,false,false,false,true,false,false,false,true,true,true,true,true,true],[false,false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,false,false,false,true,false,false,true,true,true,true,true,true,false,false,true,false,false,false,false,false,false,true,false,false,false,false,false,true,false,false,false,false,true,false,true,true,true,true,true,true,false,false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,false,false,false,true,false,false,true,false,false,true,false,true],[false,false,false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,false,false,false,true,false,false,true,false,false,true,true,false,false,false,true,false,false,false,false,false,false,true,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,false,false,false,true,false,false,true,false,false,true,true],[false,false,false,false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,false,false,false,true,false,false,true,true,true,true,false,false,false,false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,true,true,true,true,true,true,true,true,true,true,false,false,false,false,true,false,false,false,false,false,false,true,false,false,false,false,true,false,true,true,true,true,true,true,true,true,true,true],[false,false,false,false,false,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true],[false,false,false,false,false,false,true,false,false,false,false,false,true,false,false,false,false,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,true,false,false,false,false,false,true,false,false,false,false,true,false,false,false,true,false,false,true,false,true,true,false,false,false,false,false,false,true,false,false,false,false,false,true,false,false,false,false,true,false,false,false,true,false,false,true,true,true,true],[0.422532402791625,0.348397664150406,0.319769263637658,0.397151402934055,0.302905569007264,0.21709158239567,0.402278877652756,0.206993305796895,0.21709158239567,0.215410910126763,0.218772254664578,0.233898305084746,0.21035465033471,0.208673978065803,0.20363196125908,0.21035465033471,0.212049565588947,0.185144566301097,0.17669847600057,0.149793476712719,0.186839481555334,0.168280871670702,0.159863267340835,0.148084318473152,0.138000284859707,0.148112804443811,0.139680957128614,0.153126335279875,0.393889759293548,0.380358923230309,0.33990884489389,0.37199829084176,0.341618003133457,0.206979062811565,0.370289132602193,0.210326164364051,0.206979062811565,0.206979062811565,0.201937046004843,0.217063096425011,0.20360347528842,0.201908560034183,0.20361771827375,0.201937046004843,0.193476712718986,0.201937046004843,0.183392679105541,0.180017091582396,0.169918814983621,0.186754023643356,0.164919527132887,0.17666999002991,0.193519441674975,0.161529696624412,0.173379860418744,0.169990029910269,0.417504628970232,0.373693206095998,0.323244552058111,0.400697906281157,0.348468879077055,0.215624554906708,0.372055262783079,0.208901865831078,0.215624554906708,0.218985899444524,0.213929639652471,0.220666571713431,0.213943882637801,0.217305227175616,0.215624554906708,0.213943882637801,0.193733086454921,0.200484261501211,0.190343255946446,0.192052414186013,0.208887622845748,0.210582538099986,0.192038171200684,0.197094430992736,0.192023928215354,0.190357498931776,0.207206950576841,0.197108673978066],[1.159,1.11700000000001,1.269,0.74400000000001,1.121,0.721000000000004,1.14099999999999,0.813000000000002,0.772999999999989,0.856000000000009,0.77300000000001,0.779000000000003,0.781999999999996,0.801000000000002,0.964000000000006,1.26899999999999,0.823999999999991,0.826000000000001,0.996000000000009,1.71599999999999,1.034,0.996000000000016,1.21000000000001,1.162,1.15,1.18100000000002,1.17199999999999,1.22599999999999,1.137,1.036,1.312,0.750000000000004,0.730000000000004,1.07300000000001,0.734999999999999,0.869999999999997,0.812000000000005,0.886999999999993,0.821000000000019,0.815999999999995,0.79099999999999,0.84500000000002,0.845999999999989,1.25200000000001,0.825999999999986,0.780000000000015,1.021,0.906000000000006,1.047,0.925999999999995,1.169,1.051,1.03400000000002,1.15799999999999,1.127,1.18899999999999,1.14,1.065,1.316,0.762,1.054,0.724999999999998,0.723999999999997,0.864000000000004,0.794000000000011,0.899000000000001,0.820999999999991,0.822999999999986,0.770999999999994,0.845000000000006,0.961000000000013,1.205,0.817999999999984,0.806000000000004,0.982000000000021,1.582,0.969000000000001,0.988,1.14599999999999,1.016,1.007,1.14199999999999,1.05200000000001,1.15900000000001],[\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:42Z\",\"2022-11-08T16:38:42Z\",\"2022-11-08T16:38:42Z\",\"2022-11-08T16:38:42Z\",\"2022-11-08T16:38:47Z\",\"2022-11-08T16:38:47Z\",\"2022-11-08T16:38:47Z\",\"2022-11-08T16:38:50Z\",\"2022-11-08T16:38:50Z\",\"2022-11-08T16:38:52Z\",\"2022-11-08T16:38:21Z\",\"2022-11-08T16:38:21Z\",\"2022-11-08T16:38:21Z\",\"2022-11-08T16:38:21Z\",\"2022-11-08T16:38:21Z\",\"2022-11-08T16:38:21Z\",\"2022-11-08T16:38:21Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:41Z\",\"2022-11-08T16:38:41Z\",\"2022-11-08T16:38:41Z\",\"2022-11-08T16:38:41Z\",\"2022-11-08T16:38:46Z\",\"2022-11-08T16:38:46Z\",\"2022-11-08T16:38:46Z\",\"2022-11-08T16:38:49Z\",\"2022-11-08T16:38:49Z\",\"2022-11-08T16:38:50Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:22Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:29Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:35Z\",\"2022-11-08T16:38:41Z\",\"2022-11-08T16:38:41Z\",\"2022-11-08T16:38:41Z\",\"2022-11-08T16:38:41Z\",\"2022-11-08T16:38:46Z\",\"2022-11-08T16:38:46Z\",\"2022-11-08T16:38:46Z\",\"2022-11-08T16:38:49Z\",\"2022-11-08T16:38:49Z\",\"2022-11-08T16:38:50Z\"],[1,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,4,4,4,4,5,5,5,6,6,7,1,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,4,4,4,4,5,5,5,6,6,7,1,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,4,4,4,4,5,5,5,6,6,7],[\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\",\"titanic\"],[\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\",\"classif.ranger.fselector\"],[\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\",\"cv\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>iteration<\\/th>\\n      <th>age<\\/th>\\n      <th>embarked<\\/th>\\n      <th>fare<\\/th>\\n      <th>parch<\\/th>\\n      <th>pclass<\\/th>\\n      <th>sex<\\/th>\\n      <th>sib_sp<\\/th>\\n      <th>classif.ce<\\/th>\\n      <th>runtime_learners<\\/th>\\n      <th>timestamp<\\/th>\\n      <th>batch_nr<\\/th>\\n      <th>task_id<\\/th>\\n      <th>learner_id<\\/th>\\n      <th>resampling_id<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,9,10,12]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n## Shortcuts\n\nSelecting a feature subset can be shortened by using the [`fselect()`](https://mlr3fselect.mlr-org.com/reference/fselect.html)-shortcut.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstance = fselect(\n  method = \"random_search\",\n  task = tsk(\"iris\"),\n  learner = lrn(\"classif.log_reg\"),\n  resampling = rsmp(\"cv\", folds = 3),\n  measure = msr(\"classif.ce\"),\n  term_evals = 10\n)\n```\n:::\n\n\nApplying nested resampling can be shortened by using the [`fselect_nested()`](https://mlr3fselect.mlr-org.com/reference/fselect_nested.html)-shortcut.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr = fselect_nested(\n  method = \"random_search\",\n  task = tsk(\"iris\"),\n  learner = lrn(\"classif.log_reg\"),\n  inner_resampling = rsmp (\"cv\", folds = 3),\n  outer_resampling = rsmp(\"cv\", folds = 3),\n  measure = msr(\"classif.ce\"),\n  term_evals = 10\n)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\n<link href=\"../../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/datatables-binding-0.25/datatables.js\"></script>\n<script src=\"../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../../site_libs/dt-core-1.11.3/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/dt-core-1.11.3/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/dt-core-1.11.3/js/jquery.dataTables.min.js\"></script>\n<link href=\"../../site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}