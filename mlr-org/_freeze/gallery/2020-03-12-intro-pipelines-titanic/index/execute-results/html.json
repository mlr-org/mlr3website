{
  "hash": "dc5c08e25d90448625996a1689aab15f",
  "result": {
    "markdown": "---\ntitle: A Pipeline for the Titanic Data Set - Basics\ncategories:\n  - imputation\n  - classification\n  - mlr3pipelines\n  - feature engineering\nauthor:\n  - name: Florian Pfisterer\ndescription: |\n  This post shows how to build a Graph using the mlr3pipelines package on the \"titanic\" dataset.\ndate: 03-12-2020\nimage: ../../images/logo_color.png\n---\n\n\n\n\n## Intro\n\nWe load the [mlr3verse](https://mlr3verse.mlr-org.com) package which pulls in the most important packages for this example.\nThe [mlr3learners](https://mlr3learners.mlr-org.com) package loads additional [`learners`](https://mlr3.mlr-org.com/reference/Learner.html).\nThe data is part of the [mlr3data](https://mlr3data.mlr-org.com)  package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\nlibrary(mlr3learners)\n```\n:::\n\n\nWe initialize the random number generator with a fixed seed for reproducibility, and decrease the verbosity of the logger to keep the output clearly represented.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(7832)\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n```\n:::\n\n\nThe titanic data is very interesting to analyze, even though it is part of many tutorials\nand showcases.\nThis is because it requires many steps often required in real-world applications of machine\nlearning techniques, such as **missing value imputation**, **handling factors** and others.\n\nFollowing features are illustrated in this use case section:\n\n* Summarizing the data set\n* Visualizing data\n* Splitting data into train and test data sets\n* Defining a task and a learner\n\n## Exploratory Data Analysis\n\nWith the dataset, we get an explanation of the meanings of the different variables:\n\n| Variables  | Description                         |\n| ---------- | ----------------------------------- |\n| `survived` | Survival                            |\n| `name`     | Name                                |\n| `age`      | Age                                 |\n| `sex`      | Sex                                 |\n| `sib_sp`   | Number of siblings / spouses aboard |\n| `parch`    | Number of parents / children aboard |\n| `fare`     | Amount paid for the ticket          |\n| `pc_class` | Passenger class                     |\n| `embarked` | Port of embarkation                 |\n| `ticket`   | Ticket number                       |\n| `cabin`    | Cabin                               |\n\nWe can use the [skimr](https://cran.r-project.org/package=skimr) package in order to get a first overview of the data:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(\"titanic\", package = \"mlr3data\")\n\nskimr::skim(titanic)\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |titanic |\n|Number of rows           |1309    |\n|Number of columns        |11      |\n|_______________________  |        |\n|Column type frequency:   |        |\n|character                |3       |\n|factor                   |4       |\n|numeric                  |4       |\n|________________________ |        |\n|Group variables          |None    |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|name          |         0|          1.00|  12|  82|     0|     1307|          0|\n|ticket        |         0|          1.00|   3|  18|     0|      929|          0|\n|cabin         |      1014|          0.23|   1|  15|     0|      186|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts             |\n|:-------------|---------:|-------------:|:-------|--------:|:----------------------|\n|survived      |       418|          0.68|FALSE   |        2|no: 549, yes: 342      |\n|pclass        |         0|          1.00|TRUE    |        3|3: 709, 1: 323, 2: 277 |\n|sex           |         0|          1.00|FALSE   |        2|mal: 843, fem: 466     |\n|embarked      |         2|          1.00|FALSE   |        3|S: 914, C: 270, Q: 123 |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|    sd|   p0|  p25|   p50|   p75|   p100|hist  |\n|:-------------|---------:|-------------:|-----:|-----:|----:|----:|-----:|-----:|------:|:-----|\n|age           |       263|           0.8| 29.88| 14.41| 0.17| 21.0| 28.00| 39.00|  80.00|▂▇▅▂▁ |\n|sib_sp        |         0|           1.0|  0.50|  1.04| 0.00|  0.0|  0.00|  1.00|   8.00|▇▁▁▁▁ |\n|parch         |         0|           1.0|  0.39|  0.87| 0.00|  0.0|  0.00|  0.00|   9.00|▇▁▁▁▁ |\n|fare          |         1|           1.0| 33.30| 51.76| 0.00|  7.9| 14.45| 31.27| 512.33|▇▁▁▁▁ |\n:::\n:::\n\n\nWe can now create a [`Task`](https://mlr3.mlr-org.com/reference/Task.html) from our data.\nAs we want to classify whether the person survived or not, we will create a\n[`TaskClassif`](https://mlr3.mlr-org.com/reference/TaskClassif.html). We'll ignore the 'titanic_test' data for now and come back to it later.\n\n## A first model\n\nIn order to obtain solutions comparable to official leaderboards, such as the ones available from kaggle, we split the data into train and validation set before doing any further analysis.\nHere we are using the predefined split used by Kaggle.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask = as_task_classif(titanic, target = \"survived\", positive = \"yes\")\ntask$set_row_roles(892:1309, \"holdout\")\ntask\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskClassif:titanic> (891 x 11)\n* Target: survived\n* Properties: twoclass\n* Features (10):\n  - chr (3): cabin, name, ticket\n  - dbl (2): age, fare\n  - fct (2): embarked, sex\n  - int (2): parch, sib_sp\n  - ord (1): pclass\n```\n:::\n:::\n\n\nOur [`Task`](https://mlr3.mlr-org.com/reference/Task.html) currently has $3$ features of type `character`, which we don't really know how  to handle:\n\"Cabin\", \"Name\", \"Ticket\" and \"PassengerId\".\nAdditionally, from our [`skimr::skim()`](https://www.rdocumentation.org/packages/skimr/topics/skim) of the data, we have seen, that they have many unique values (up to 891).\n\nWe'll drop them for now and see how we can deal with them later on.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntask$select(cols = setdiff(task$feature_names, c(\"cabin\", \"name\", \"ticket\")))\n```\n:::\n\n\nAdditionally, we create a resampling instance that allows to compare data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncv3 = rsmp(\"cv\", folds = 3L)$instantiate(task)\n```\n:::\n\n\nTo get a first impression of what performance we can fit a simple decision tree:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = mlr_learners$get(\"classif.rpart\")\n# or shorter:\nlearner = lrn(\"classif.rpart\")\n\nrr = resample(task, learner, cv3, store_models = TRUE)\n\nrr$aggregate(msr(\"classif.acc\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.acc \n  0.8013468 \n```\n:::\n:::\n\n\nSo our model should have a minimal accuracy of `0.80` in order to improve over the simple decision tree.\nIn order to improve more, we might need to do some feature engineering.\n\n# Optimizing the model\n\nIf we now try to fit a 'ranger' random forest model, we will get an error,\nas 'ranger' models can not naturally handle missing values.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.ranger\", num.trees = 250, min.node.size = 4)\n\nrr = resample(task, learner, cv3, store_models = TRUE)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: Task 'titanic' has missing values in column(s) 'age', 'embarked', but learner 'classif.ranger' does not support this\n```\n:::\n:::\n\n\nThis means we have to find a way to impute the missing values.\nTo learn how to use more advanced commands of the mlr3pipelines package see:\n\n* [Part II - Pipelines](https://mlr3gallery.mlr-org.com/posts/2020-04-27-mlr3pipelines-Imputation-titanic/)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}