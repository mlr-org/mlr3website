{
  "hash": "044f255ea2e5064699e3ab506d2d2a50",
  "result": {
    "markdown": "---\ntitle: Practical Tuning Series - Tune a Support Vector Machine\ndescription: |\n  Optimize the hyperparameters of a support vector machine.\ncategories:\n  - tuning\n  - resampling\n  - classification\n  - practical tuning series\nauthor:\n  - name: Marc Becker\n  - name: Theresa Ullmann\n  - name: Michel Lang\n  - name: Bernd Bischl\n  - name: Jakob Richter\n  - name: Martin Binder\ndate: 2021-03-09\nbibliography: bibliography.bib\n---\n\n\n\n\n# Scope\n\nThis is the first part of the practical tuning series.\nThe other parts can be found here:\n\n* [Part II - Tune a Preprocessing Pipeline](https://mlr-org.com/gallery/series/2021-03-10-practical-tuning-series-tune-a-preprocessing-pipeline/)\n* [Part III - Build an Automated Machine Learning System](https://mlr-org.com/gallery/series/2021-03-11-practical-tuning-series-build-an-automated-machine-learning-system/)\n* [Part IV - Tuning and Parallel Processing](https://mlr-org.com/gallery/series/2021-03-12-practical-tuning-series-tuning-and-parallel-processing/)\n\nIn this post, we demonstrate how to optimize the hyperparameters of a support vector machine (SVM).\nWe are using the [mlr3](https://mlr3.mlr-org.com) machine learning framework with the [mlr3tuning](https://mlr3tuning.mlr-org.com) extension package.\n\nFirst, we start by showing the basic building blocks of [mlr3tuning](https://mlr3tuning.mlr-org.com)  and tune the `cost` and `gamma` hyperparameters of an SVM with a radial basis function on the [Iris data set](https://mlr3.mlr-org.com/reference/mlr_tasks_iris.html).\nAfter that, we use transformations to tune the both hyperparameters on the logarithmic scale.\nNext, we explain the importance of dependencies to tune hyperparameters like `degree` which are dependent on the choice of kernel.\nAfter that, we fit an SVM with optimized hyperparameters on the full dataset.\nFinally, nested resampling is used to compute an unbiased performance estimate of our tuned SVM.\n\n# Prerequisites\n\nWe load the [mlr3verse](https://mlr3verse.mlr-org.com)  package which pulls in the most important packages for this example.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\n```\n:::\n\n\nWe initialize the random number generator with a fixed seed for reproducibility, and decrease the verbosity of the logger to keep the output clearly represented.\nThe [`lgr`](https://mlr3book.mlr-org.com/logging.html) package is used for logging in all [mlr3](https://mlr3.mlr-org.com) packages.\nThe [mlr3](https://mlr3.mlr-org.com) logger prints the logging messages from the base package, whereas the [bbotk](https://bbotk.mlr-org.com)  logger is responsible for logging messages from the optimization packages (e.g. [mlr3tuning](https://mlr3tuning.mlr-org.com) ).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(7832)\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\nlgr::get_logger(\"bbotk\")$set_threshold(\"warn\")\n```\n:::\n\n\nIn the example, we use the [Iris data set](https://mlr3.mlr-org.com/reference/mlr_tasks_iris.html) which classifies 150 flowers in three species of Iris.\nThe flowers are characterized by sepal length and width and petal length and width.\nThe Iris data set allows us to quickly fit models to it.\nHowever, the influence of hyperparameter tuning on the predictive performance might be minor.\nOther data sets might give more meaningful tuning results.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# retrieve the task from mlr3\ntask = tsk(\"iris\")\n\n# generate a quick textual overview using the skimr package\nskimr::skim(task$data())\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |            |\n|:------------------------|:-----------|\n|Name                     |task$data() |\n|Number of rows           |150         |\n|Number of columns        |5           |\n|Key                      |NULL        |\n|_______________________  |            |\n|Column type frequency:   |            |\n|factor                   |1           |\n|numeric                  |4           |\n|________________________ |            |\n|Group variables          |None        |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                |\n|:-------------|---------:|-------------:|:-------|--------:|:-------------------------|\n|Species       |         0|             1|FALSE   |        3|set: 50, ver: 50, vir: 50 |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate| mean|   sd|  p0| p25|  p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|----:|----:|---:|---:|----:|---:|----:|:-----|\n|Petal.Length  |         0|             1| 3.76| 1.77| 1.0| 1.6| 4.35| 5.1|  6.9|▇▁▆▇▂ |\n|Petal.Width   |         0|             1| 1.20| 0.76| 0.1| 0.3| 1.30| 1.8|  2.5|▇▁▇▅▃ |\n|Sepal.Length  |         0|             1| 5.84| 0.83| 4.3| 5.1| 5.80| 6.4|  7.9|▆▇▇▅▂ |\n|Sepal.Width   |         0|             1| 3.06| 0.44| 2.0| 2.8| 3.00| 3.3|  4.4|▁▆▇▂▁ |\n:::\n:::\n\n\nWe choose the support vector machine implementation from the [e1071](https://cran.r-project.org/package=e1071) package (which is based on [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)) and use it as a classification machine by setting `type` to `\"C-classification\"`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.svm\", type = \"C-classification\", kernel = \"radial\")\n```\n:::\n\n\n# Tuning Search Space\n\nFor tuning, it is important to create a search space that defines the type and range of the hyperparameters.\nA learner stores all information about its hyperparameters in the slot `$param_set`.\nNot all parameters are tunable.\nWe have to choose a subset of the hyperparameters we want to tune.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nas.data.table(learner$param_set)[, .(id, class, lower, upper, nlevels)]\n```\n:::\n\n\nWe use the [`to_tune()`](https://paradox.mlr-org.com/reference/to_tune.html) function to define the range over which the hyperparameter should be tuned.\nWe opt for the `cost` and `gamma` hyperparameters of the `radial` kernel and set the tuning ranges with lower and upper bounds.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner$param_set$values$cost = to_tune(0.1, 10)\nlearner$param_set$values$gamma = to_tune(0, 5)\n```\n:::\n\n\n# Tuning\n\nWe specify how to evaluate the performance of the different hyperparameter configurations.\nFor this, we choose 3-fold cross validation as the resampling strategy and the classification error as the performance measure.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresampling = rsmp(\"cv\", folds = 3)\nmeasure = msr(\"classif.ce\")\n```\n:::\n\n\nUsually, we have to select a budget for the tuning.\nThis is done by choosing a [`Terminator`](https://bbotk.mlr-org.com/reference/Terminator.html), which stops the tuning e.g. after a performance level is reached or after a given time.\nHowever, some tuners like grid search terminate themselves.\nIn this case, we  choose a terminator that never stops and the tuning is not stopped before all grid points are evaluated.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nterminator = trm(\"none\")\n```\n:::\n\n\nAt this point, we can construct a [`TuningInstanceSingleCrit`](https://mlr3tuning.mlr-org.com/reference/TuningInstanceSingleCrit.html) that describes the tuning problem.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance = TuningInstanceSingleCrit$new(\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measure = measure,\n  terminator = terminator\n)\n\nprint(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TuningInstanceSingleCrit>\n* State:  Not optimized\n* Objective: <ObjectiveTuning:classif.svm_on_iris>\n* Search Space:\n      id    class lower upper nlevels\n1:  cost ParamDbl   0.1    10     Inf\n2: gamma ParamDbl   0.0     5     Inf\n* Terminator: <TerminatorNone>\n```\n:::\n:::\n\n\nFinally, we have to choose a [`Tuner`](https://mlr3tuning.mlr-org.com/reference/Tuner.html).\n[Grid Search](https://mlr3tuning.mlr-org.com/reference/mlr_tuners_grid_search.html) discretizes numeric parameters into a given resolution and constructs a grid from the Cartesian product of these sets.\nCategorical parameters produce a grid over all levels specified in the search space.\nIn this example, we only use a resolution of 5 to keep the runtime low.\nUsually, a higher resolution is used to create a denser grid.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntuner = tnr(\"grid_search\", resolution = 5)\n\nprint(tuner)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TunerGridSearch>: Grid Search\n* Parameters: resolution=5, batch_size=1\n* Parameter classes: ParamLgl, ParamInt, ParamDbl, ParamFct\n* Properties: dependencies, single-crit, multi-crit\n* Packages: mlr3tuning\n```\n:::\n:::\n\n\nWe can preview the proposed configurations by using [`generate_design_grid()`](https://paradox.mlr-org.com/reference/generate_design_grid.html). This function is internally executed by [`TunerGridSearch`](https://mlr3tuning.mlr-org.com/reference/mlr_tuners_grid_search.html).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngenerate_design_grid(learner$param_set$search_space(), resolution = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Design> with 25 rows:\n      cost gamma\n 1:  0.100  0.00\n 2:  0.100  1.25\n 3:  0.100  2.50\n 4:  0.100  3.75\n 5:  0.100  5.00\n 6:  2.575  0.00\n 7:  2.575  1.25\n 8:  2.575  2.50\n 9:  2.575  3.75\n10:  2.575  5.00\n11:  5.050  0.00\n12:  5.050  1.25\n13:  5.050  2.50\n14:  5.050  3.75\n15:  5.050  5.00\n16:  7.525  0.00\n17:  7.525  1.25\n18:  7.525  2.50\n19:  7.525  3.75\n20:  7.525  5.00\n21: 10.000  0.00\n22: 10.000  1.25\n23: 10.000  2.50\n24: 10.000  3.75\n25: 10.000  5.00\n      cost gamma\n```\n:::\n:::\n\n\nWe trigger the tuning by passing the [`TuningInstanceSingleCrit`](https://mlr3tuning.mlr-org.com/reference/TuningInstanceSingleCrit.html) to the `$optimize()` method of the [`Tuner`](https://mlr3tuning.mlr-org.com/reference/Tuner.html). The instance is modified in-place.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntuner$optimize(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   cost gamma learner_param_vals  x_domain classif.ce\n1: 5.05  1.25          <list[4]> <list[2]>       0.04\n```\n:::\n:::\n\n\nWe plot the performances depending on the evaluated `cost` and `gamma` values.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(instance, type = \"surface\", cols_x = c(\"cost\", \"gamma\"),\n  learner = lrn(\"regr.km\"))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/2021-03-09-practical-tuning-series-tune-a-support-vector-machine-014-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe points mark the evaluated `cost` and `gamma` values.\nWe should not infer the performance of new values from the heatmap since it is only an interpolation.\nHowever, we can see the general interaction between the hyperparameters.\n\nTuning a learner can be shortened by using the [`tune()`](https://mlr3tuning.mlr-org.com/reference/tune.html)-shortcut.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.svm\", type = \"C-classification\", kernel = \"radial\")\nlearner$param_set$values$cost = to_tune(0.1, 10)\nlearner$param_set$values$gamma = to_tune(0, 5)\n\ninstance = tune(\n  method = \"grid_search\",\n  task = tsk(\"iris\"),\n  learner = learner,\n  resampling = rsmp (\"holdout\"),\n  measure = msr(\"classif.ce\"),\n  resolution = 5\n)\n```\n:::\n\n\n# Transformation\n\nNext, we want to tune the `cost` and `gamma` hyperparameter more efficiently.\nIt is recommended to tune `cost` and `gamma` on the logarithmic scale [@hsuPracticalGuideSupport2003].\nThe log transformation emphasizes smaller `cost` and `gamma` values but also creates large values.\nTherefore, we use a log transformation to emphasize this region of the search space with a denser grid.\n\nGenerally speaking, transformations can be used to convert hyperparameters to a new scale.\nThese transformations are applied before the proposed configuration is passed to the [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html).\nWe can directly define the transformation in the [`to_tune()`](https://paradox.mlr-org.com/reference/to_tune.html) function.\nThe lower and upper bound is set on the original scale.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.svm\", type = \"C-classification\", kernel = \"radial\")\n\n# tune from 2^-15 to 2^15 on a log scale\nlearner$param_set$values$cost = to_tune(p_dbl(-15, 15, trafo = function(x) 2^x))\n\n# tune from 2^-15 to 2^5 on a log scale\nlearner$param_set$values$gamma = to_tune(p_dbl(-15, 5, trafo = function(x) 2^x))\n```\n:::\n\n\nTransformations to the log scale are the ones most commonly used.\nWe can use a shortcut for this transformation.\nThe lower and upper bound is set on the transformed scale.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner$param_set$values$cost = to_tune(p_dbl(1e-5, 1e5, logscale = TRUE))\nlearner$param_set$values$gamma = to_tune(p_dbl(1e-5, 1e5, logscale = TRUE))\n```\n:::\n\n\nWe use the [`tune()`](https://mlr3tuning.mlr-org.com/reference/tune.html)-shortcut to run the tuning.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance = tune(\n  method = \"grid_search\",\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measure = measure,\n  resolution = 5\n)\n```\n:::\n\n\nThe hyperparameter values after the transformation are stored in the `x_domain` column as lists.\nWe can expand these lists into multiple columns by using `as.data.table()`.\nThe hyperparameter names are prefixed by `x_domain`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nas.data.table(instance$archive)[, .(cost, gamma, x_domain_cost, x_domain_gamma)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          cost      gamma x_domain_cost x_domain_gamma\n 1:  11.512925 -11.512925  1.000000e+05   1.000000e-05\n 2:   5.756463   0.000000  3.162278e+02   1.000000e+00\n 3: -11.512925  11.512925  1.000000e-05   1.000000e+05\n 4:   0.000000   5.756463  1.000000e+00   3.162278e+02\n 5: -11.512925  -5.756463  1.000000e-05   3.162278e-03\n 6:   0.000000   0.000000  1.000000e+00   1.000000e+00\n 7:  11.512925   5.756463  1.000000e+05   3.162278e+02\n 8:  -5.756463 -11.512925  3.162278e-03   1.000000e-05\n 9: -11.512925 -11.512925  1.000000e-05   1.000000e-05\n10:  -5.756463  11.512925  3.162278e-03   1.000000e+05\n11: -11.512925   5.756463  1.000000e-05   3.162278e+02\n12:  11.512925   0.000000  1.000000e+05   1.000000e+00\n13: -11.512925   0.000000  1.000000e-05   1.000000e+00\n14:   5.756463 -11.512925  3.162278e+02   1.000000e-05\n15:   5.756463   5.756463  3.162278e+02   3.162278e+02\n16:   5.756463  -5.756463  3.162278e+02   3.162278e-03\n17:   5.756463  11.512925  3.162278e+02   1.000000e+05\n18:  11.512925  11.512925  1.000000e+05   1.000000e+05\n19:  11.512925  -5.756463  1.000000e+05   3.162278e-03\n20:  -5.756463  -5.756463  3.162278e-03   3.162278e-03\n21:   0.000000 -11.512925  1.000000e+00   1.000000e-05\n22:   0.000000  11.512925  1.000000e+00   1.000000e+05\n23:   0.000000  -5.756463  1.000000e+00   3.162278e-03\n24:  -5.756463   0.000000  3.162278e-03   1.000000e+00\n25:  -5.756463   5.756463  3.162278e-03   3.162278e+02\n          cost      gamma x_domain_cost x_domain_gamma\n```\n:::\n:::\n\n\nWe plot the performances depending on the evaluated `cost` and `gamma` values.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(scales)\nautoplot(instance, type = \"points\", cols_x = c(\"x_domain_cost\", \"x_domain_gamma\")) +\n  scale_x_continuous(\n    trans = log2_trans(),\n    breaks = trans_breaks(\"log10\", function(x) 10^x),\n    labels = trans_format(\"log10\", math_format(10^.x))) +\n  scale_y_continuous(\n    trans = log2_trans(),\n    breaks = trans_breaks(\"log10\", function(x) 10^x),\n    labels = trans_format(\"log10\", math_format(10^.x)))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/2021-03-09-practical-tuning-series-tune-a-support-vector-machine-020-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# Dependencies\n\nDependencies ensure that certain parameters are only proposed depending on values of other hyperparameters.\nWe want to tune the `degree` hyperparameter that is only needed for the `polynomial` kernel.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.svm\", type = \"C-classification\")\n\nlearner$param_set$values$cost = to_tune(p_dbl(1e-5, 1e5, logscale = TRUE))\nlearner$param_set$values$gamma = to_tune(p_dbl(1e-5, 1e5, logscale = TRUE))\n\nlearner$param_set$values$kernel = to_tune(c(\"polynomial\", \"radial\"))\nlearner$param_set$values$degree = to_tune(1, 4)\n```\n:::\n\n\nThe dependencies are already stored in the learner parameter set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner$param_set$deps\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       id     on           cond\n1:   cost   type <CondEqual[9]>\n2:     nu   type <CondEqual[9]>\n3: degree kernel <CondEqual[9]>\n4:  coef0 kernel <CondAnyOf[9]>\n5:  gamma kernel <CondAnyOf[9]>\n```\n:::\n:::\n\n\nThe `gamma` hyperparameter depends on the kernel being `polynomial`, `radial` or `sigmoid`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner$param_set$deps$cond[[5]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCondAnyOf: x ∈ {polynomial, radial, sigmoid}\n```\n:::\n:::\n\n\nwhereas the `degree` hyperparameter is solely used by the `polynomial` kernel.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner$param_set$deps$cond[[3]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCondEqual: x = polynomial\n```\n:::\n:::\n\n\nWe preview the grid to show the effect of the dependencies.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngenerate_design_grid(learner$param_set$search_space(), resolution = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Design> with 12 rows:\n         cost     gamma     kernel degree\n 1: -11.51293 -11.51293 polynomial      1\n 2: -11.51293 -11.51293 polynomial      4\n 3: -11.51293 -11.51293     radial     NA\n 4: -11.51293  11.51293 polynomial      1\n 5: -11.51293  11.51293 polynomial      4\n 6: -11.51293  11.51293     radial     NA\n 7:  11.51293 -11.51293 polynomial      1\n 8:  11.51293 -11.51293 polynomial      4\n 9:  11.51293 -11.51293     radial     NA\n10:  11.51293  11.51293 polynomial      1\n11:  11.51293  11.51293 polynomial      4\n12:  11.51293  11.51293     radial     NA\n```\n:::\n:::\n\n\nThe value for `degree` is `NA` if the dependency on the `kernel` is not satisfied.\n\nWe use the [`tune()`](https://mlr3tuning.mlr-org.com/reference/tune.html)-shortcut to run the tuning.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance = tune(\n  method = \"grid_search\",\n  task = task,\n  learner = learner,\n  resampling = resampling,\n  measure = measure,\n  resolution = 3\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstance$result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   cost gamma     kernel degree learner_param_vals  x_domain classif.ce\n1:    0     0 polynomial      1          <list[5]> <list[4]>       0.02\n```\n:::\n:::\n\n\n# Final Model\n\nWe add the optimized hyperparameters to the learner and train the learner on the full dataset.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.svm\")\nlearner$param_set$values = instance$result_learner_param_vals\nlearner$train(task)\n```\n:::\n\n\nThe trained model can now be used to make predictions on new data.\nA common mistake is to report the performance estimated on the resampling sets on which the tuning was performed (`instance$result_y`) as the model's performance.\nThese scores might be biased and overestimate the ability of the fitted model to predict with new data.\nInstead, we have to use nested resampling to get an unbiased performance estimate.\n\n# Nested Resampling\n\nTuning should not be performed on the same resampling sets which are used for evaluating the model itself, since this would result in a biased performance estimate.\n[Nested resampling](https://mlr3book.mlr-org.com/nested-resampling.html) uses an outer and inner resampling to separate the tuning from the performance estimation of the model.\nWe can use the [`AutoTuner`](https://mlr3tuning.mlr-org.com/reference/AutoTuner.html) class for running nested resampling.\nThe [`AutoTuner`](https://mlr3tuning.mlr-org.com/reference/AutoTuner.html) wraps a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) and tunes the hyperparameter of the learner during `$train()`.\nThis is our inner resampling loop.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.svm\", type = \"C-classification\")\nlearner$param_set$values$cost = to_tune(p_dbl(1e-5, 1e5, logscale = TRUE))\nlearner$param_set$values$gamma = to_tune(p_dbl(1e-5, 1e5, logscale = TRUE))\nlearner$param_set$values$kernel = to_tune(c(\"polynomial\", \"radial\"))\nlearner$param_set$values$degree = to_tune(1, 4)\n\nresampling_inner = rsmp(\"cv\", folds = 3)\nterminator = trm(\"none\")\ntuner = tnr(\"grid_search\", resolution = 3)\n\nat = AutoTuner$new(\n  learner = learner,\n  resampling = resampling_inner,\n  measure = measure,\n  terminator = terminator,\n  tuner = tuner,\n  store_models = TRUE)\n```\n:::\n\n\nWe put the [`AutoTuner`](https://mlr3tuning.mlr-org.com/reference/AutoTuner.html) into a [`resample()`](https://mlr3.mlr-org.com/reference/resample.html) call to get the outer resampling loop.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresampling_outer = rsmp(\"cv\", folds = 3)\nrr = resample(task = task, learner = at, resampling = resampling_outer, store_models = TRUE)\n```\n:::\n\n\nWe check the inner tuning results for stable hyperparameters.\nThis means that the selected hyperparameters should not vary too much.\nWe might observe unstable models in this example because the small data set and the low number of resampling iterations might introduce too much randomness.\nUsually, we aim for the selection of stable hyperparameters for all outer training sets.\n\n\n::: {.cell .column-page layout-align=\"center\"}\n\n```{.r .cell-code}\nextract_inner_tuning_results(rr)[, .SD, .SDcols = !c(\"learner_param_vals\", \"x_domain\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   iteration     cost     gamma     kernel degree classif.ce task_id        learner_id resampling_id\n1:         1  0.00000  11.51293 polynomial      1 0.04010695    iris classif.svm.tuned            cv\n2:         2 11.51293 -11.51293     radial     NA 0.04961378    iris classif.svm.tuned            cv\n3:         3 11.51293 -11.51293     radial     NA 0.03030303    iris classif.svm.tuned            cv\n```\n:::\n:::\n\n\nNext, we want to compare the predictive performances estimated on the outer resampling to the inner resampling (`extract_inner_tuning_results(rr)`).\nSignificantly lower predictive performances on the outer resampling indicate that the models with the optimized hyperparameters overfit the data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrr$score()[, .(iteration, task_id, learner_id, resampling_id, classif.ce)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   iteration task_id        learner_id resampling_id classif.ce\n1:         1    iris classif.svm.tuned            cv       0.06\n2:         2    iris classif.svm.tuned            cv       0.04\n3:         3    iris classif.svm.tuned            cv       0.04\n```\n:::\n:::\n\n\nThe archives of the [`AutoTuner`](https://mlr3tuning.mlr-org.com/reference/AutoTuner.html)s allows us to inspect all evaluated hyperparameters configurations with the associated predictive performances.\n\n\n::: {.cell .column-page layout-align=\"center\"}\n\n```{.r .cell-code}\nextract_inner_tuning_archives(rr, unnest = NULL, exclude_columns = c(\"resample_result\", \"uhash\", \"x_domain\", \"timestamp\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     iteration      cost     gamma     kernel degree classif.ce runtime_learners batch_nr warnings errors task_id\n  1:         1  11.51293  11.51293 polynomial      2 0.17052882            0.019        1        0      0    iris\n  2:         1 -11.51293 -11.51293 polynomial      1 0.53921569            0.010        2        0      0    iris\n  3:         1 -11.51293  11.51293     radial     NA 0.62002377            0.011        3        0      0    iris\n  4:         1   0.00000   0.00000 polynomial      4 0.12091503            0.010        4        0      0    iris\n  5:         1   0.00000   0.00000     radial     NA 0.07040998            0.011        5        0      0    iris\n ---                                                                                                             \n104:         3  11.51293   0.00000 polynomial      4 0.14884135            0.011       32        0      0    iris\n105:         3 -11.51293  11.51293 polynomial      4 0.14884135            0.011       33        0      0    iris\n106:         3  11.51293 -11.51293     radial     NA 0.03030303            0.010       34        0      0    iris\n107:         3 -11.51293   0.00000 polynomial      2 0.71925134            0.010       35        0      0    iris\n108:         3   0.00000  11.51293 polynomial      2 0.09001783            0.012       36        0      0    iris\n            learner_id resampling_id\n  1: classif.svm.tuned            cv\n  2: classif.svm.tuned            cv\n  3: classif.svm.tuned            cv\n  4: classif.svm.tuned            cv\n  5: classif.svm.tuned            cv\n ---                                \n104: classif.svm.tuned            cv\n105: classif.svm.tuned            cv\n106: classif.svm.tuned            cv\n107: classif.svm.tuned            cv\n108: classif.svm.tuned            cv\n```\n:::\n:::\n\n\nThe aggregated performance of all outer resampling iterations is essentially the unbiased performance of an SVM with optimal hyperparameter found by grid search.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrr$aggregate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n0.04666667 \n```\n:::\n:::\n\n\nApplying nested resampling can be shortened by using the [`tune_nested()`](https://mlr3tuning.mlr-org.com/reference/tune_nested.html)-shortcut.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlearner = lrn(\"classif.svm\", type = \"C-classification\")\nlearner$param_set$values$cost = to_tune(p_dbl(1e-5, 1e5, logscale = TRUE))\nlearner$param_set$values$gamma = to_tune(p_dbl(1e-5, 1e5, logscale = TRUE))\nlearner$param_set$values$kernel = to_tune(c(\"polynomial\", \"radial\"))\nlearner$param_set$values$degree = to_tune(1, 4)\n\nrr = tune_nested(\n  method = \"grid_search\",\n  task = tsk(\"iris\"),\n  learner = learner,\n  inner_resampling = rsmp (\"cv\", folds = 3),\n  outer_resampling = rsmp(\"cv\", folds = 3),\n  measure = msr(\"classif.ce\"),\n  resolution = 3\n)\n```\n:::\n\n\n# Resources\n\nThe [mlr3book](https://mlr3book.mlr-org.com/) includes chapters on [tuning spaces](https://mlr3book.mlr-org.com/searchspace.html) and [hyperparameter tuning](https://mlr3book.mlr-org.com/tuning.html).\nThe [mlr3cheatsheets](https://cheatsheets.mlr-org.com/) contain frequently used commands and workflows of mlr3.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}